{"resource":"WAF","category":"basics","instruction":"What is WAF (Web Application Firewall) and how is it configured in Elchi?","output":"WAF (WEB APPLICATION FIREWALL):\n\n1) WHAT IS WAF:\n   - Protection layer against web attacks\n   - OWASP CRS (Core Rule Set) based security rules\n   - Works using Coraza engine (as Envoy Wasm filter)\n   - Blocks attacks like SQL injection, XSS, path traversal\n\n2) CONFIGURING WAF IN ELCHI:\n   a) Select 'WAF' tab from the left menu\n   b) WAF list page opens (existing profiles are displayed)\n   c) Click 'Create WAF' button in the top right corner\n   d) WAF creation page opens\n\n3) WAF SETTINGS:\n   - Name: WAF profile name (e.g., production-waf, staging-waf)\n   - Default Directives: Select default directive set (from dropdown)\n   - Directive Sets: Create different rule sets\n   - Metric Labels: Metric labels (for monitoring)\n   - Per Authority Directives: Domain-based custom rules\n\n4) USAGE SCENARIO:\n   - First create WAF profile (with directive sets)\n   - Then add as HTTP filter to listener (Wasm filter)\n   - WAF rules automatically activate\n\n5) IMPORTANT NOTES:\n   âš  Review CRS rules before creating WAF profile\n   âš  Choose paranoia level (1-4) carefully (high level increases false positives)\n   âš  Test in test environment first, then apply to production"}
{"resource":"WAF","category":"directive_sets","instruction":"What are Directive Sets in WAF and how are they created?","output":"DIRECTIVE SETS (RULE SETS):\n\n1) WHAT IS DIRECTIVE SET:\n   - Grouped collection of Coraza directives\n   - Each set can be used for different purposes (e.g., basic-protection, advanced-protection)\n   - Default directives: Base set applied to all requests\n   - Custom sets: Specific sets for certain domains or routes\n\n2) CREATING NEW DIRECTIVE SET:\n   a) Find 'Directive Sets Manager' card on WAF detail page\n   b) Type set name in 'New Set Name' input field (e.g., \"sql-protection\")\n   c) Click the blue '+' button next to it\n   d) New empty set is created\n   e) You can add directives to the set\n\n3) DIRECTIVE ADDING METHODS:\n   \n   METHOD 1 - Manual Adding:\n   a) Below the set card is 'New Directive' textarea\n   b) Write Coraza directive (e.g., \"SecRuleEngine On\")\n   c) Click 'Add Directive' button\n   \n   METHOD 2 - From CRS Rule Browser:\n   a) At the bottom of the page is 'CRS Rule Browser' card\n   b) Find rule using filters (ID, severity, phase, tag)\n   c) Click '+' button next to the rule\n   d) Automatically added to set\n   \n   METHOD 3 - CRS File Include:\n   a) View by file in CRS Rule Browser\n   b) Click 'Include File' button next to file\n   c) Entire file is added as Include directive\n\n4) DIRECTIVE ORDERING:\n   - Each directive has up/down arrow buttons next to it\n   - Order is important (Coraza directives are processed sequentially)\n   - Basic settings like SecRuleEngine should be at the top\n\n5) EDITING DIRECTIVE:\n   - Each directive line has 'Edit' (pencil) icon\n   - Click to open textarea, make changes\n   - Click 'Save' button or 'Cancel' to cancel\n\n6) DELETING DIRECTIVE:\n   - Each directive line has 'Delete' (trash) icon\n   - Click to delete that line\n\n7) DELETING SET:\n   - Set header has 'Delete Set' (red trash) icon\n   - Click to delete entire set\n   âš  Set selected as default directives cannot be deleted"}
{"resource":"WAF","category":"crs_browser","instruction":"How to use CRS Rule Browser and how to find rules?","output":"CRS RULE BROWSER (OWASP RULE BROWSER):\n\n1) WHAT IS CRS:\n   - OWASP Core Rule Set: Standard web security rules\n   - Detects attacks like SQL injection, XSS, RCE, LFI/RFI\n   - Each rule has ID, severity, phase, paranoia level properties\n\n2) OPENING RULE BROWSER:\n   a) At the bottom of WAF detail page is 'CRS Rule Browser' card\n   b) By default all rules are listed (grouped by file)\n   c) Filter panel at the top (under Filters heading)\n\n3) FILTERING OPTIONS:\n   \n   a) CRS Version:\n      - Select CRS version from dropdown (e.g., 4.14.0, 4.0.0)\n      - Each version has different rules\n   \n   b) Severity (Importance Level):\n      - CRITICAL: Most critical (e.g., SQL injection)\n      - ERROR: High risk\n      - WARNING: Medium risk\n      - NOTICE: Low risk\n      - Select from dropdown, clear for 'All'\n   \n   c) Phase (Processing Stage):\n      - Phase 1: Request Headers\n      - Phase 2: Request Body\n      - Phase 3: Response Headers\n      - Phase 4: Response Body\n      - Phase 5: Logging\n      - Select from dropdown\n   \n   d) Paranoia Level:\n      - Level 1: Basic protection (low false positive)\n      - Level 2: Medium protection\n      - Level 3: High protection\n      - Level 4: Maximum protection (high false positive)\n      - Select from dropdown\n   \n   e) Tags (Multiple Selection):\n      - Multi-select dropdown\n      - Filter by tags (e.g., attack-sqli, language-php)\n      - Multiple tags can be selected\n   \n   f) Rule ID:\n      - Search box\n      - Search by ID (e.g., 920100, 941)\n      - Automatically filtered\n   \n   g) Description:\n      - Search box\n      - Search in description and title\n      - Automatically filtered\n\n4) VIEWING RULES:\n   - Rules grouped by file (Collapse panels)\n   - Each file has rule count badge next to it\n   - Click file to open rules\n   - For each rule:\n     * ID and title\n     * Short description\n     * Type, Severity, Phase, Paranoia level tags\n     * Click 'Show Details' for:\n       - Extended description\n       - Rule logic explanation\n       - Full rule syntax (in Coraza format)\n       - Transformations\n       - References (links)\n\n5) ADDING RULE:\n   a) Find the rule you want to add (use filters)\n   b) There's a '+' button on the right side of the rule\n   c) Click the button\n   d) If there's only one directive set, it's automatically added\n   e) If there are multiple sets, modal opens, select set\n\n6) FILE-BASED ADDING:\n   a) There's an 'Include File' button next to file header\n   b) Click the button\n   c) Entire file is added as Include directive\n   d) Format: Include @owasp_crs/REQUEST-920-PROTOCOL-ENFORCEMENT.conf\n\n7) EXAMPLE USAGE:\n   Scenario: Add SQL injection protection\n   a) Select Severity: 'CRITICAL'\n   b) Select Tags: 'attack-sqli'\n   c) Rule list appears (e.g., 942100, 942110)\n   d) Click '+' button for desired rule\n   e) Automatically added to directive set"}
{"resource":"WAF","category":"default_directives","instruction":"What are Default Directives and how are they set?","output":"DEFAULT DIRECTIVES (DEFAULT DIRECTIVES):\n\n1) WHAT ARE DEFAULT DIRECTIVES:\n   - Base directive set applied to all requests\n   - Each WAF profile must have a default set\n   - WAF won't work if default set is not specified\n\n2) SETTING DEFAULT SET:\n   a) In 'WAF Configuration' card on WAF detail page\n   b) There's a 'Default Directives' dropdown\n   c) Select a directive set from dropdown\n   d) Selected set is applied to all requests\n\n3) DEFAULT SET CONTENT RECOMMENDATION:\n   Add at minimum:\n   ```\n   SecRuleEngine On\n   SecRequestBodyAccess On\n   SecResponseBodyAccess Off\n   SecRequestBodyLimit 13107200\n   SecRequestBodyNoFilesLimit 131072\n   SecRequestBodyLimitAction Reject\n   Include @owasp_crs/crs-setup.conf\n   Include @owasp_crs/REQUEST-900-EXCLUSION-RULES-BEFORE-CRS.conf\n   Include @owasp_crs/REQUEST-901-INITIALIZATION.conf\n   ```\n\n4) DEFAULT VS CUSTOM SETS:\n   - Default: Applied to all requests (basic protection)\n   - Custom sets: Specific to certain domains/routes\n   - Custom sets don't override default, they add on top\n\n5) MAKING CHANGES:\n   a) Select different set from default set dropdown\n   b) Or change content of existing default set:\n      - Find default set in Directive Sets Manager\n      - Add/remove/edit directives\n   c) Click 'Save' button\n\n6) IMPORTANT NOTES:\n   âš  Warning shown if trying to delete default set\n   âš  Default set must contain basic Coraza settings\n   âš  WAF remains passive if SecRuleEngine On is missing"}
{"resource":"WAF","category":"per_authority","instruction":"What are Per Authority Directives and how are they used?","output":"PER AUTHORITY DIRECTIVES (DOMAIN-BASED DIRECTIVES):\n\n1) WHAT IS PER AUTHORITY:\n   - Domain-based (authority) custom directive sets\n   - Different WAF rules for different domains\n   - Example use cases:\n     * api.example.com â†’ Strict API protection\n     * www.example.com â†’ Standard web protection\n     * internal.example.com â†’ Light protection\n\n2) ADDING NEW AUTHORITY:\n   a) Find 'Per Authority Directives' card on WAF detail page\n   b) Type domain in 'Domain' input field\n      - Full domain: api.example.com\n      - Wildcard: *.example.com\n      - With port: api.example.com:8080\n   c) Select a set from 'Directive Set' dropdown\n   d) Click blue '+' button next to it\n   e) Authority is added (appears in table)\n\n3) AUTHORITY LIST:\n   - Displayed in table format:\n     * Domain column\n     * Directive Set column\n     * Actions column (delete button)\n   - Each row is one domain mapping\n\n4) DELETING AUTHORITY:\n   - There's a red trash icon in 'Actions' column of table row\n   - Click to delete that authority mapping\n\n5) HOW IT WORKS:\n   - Request arrives, Host header is checked\n   - If Host is in per-authority list:\n     * That authority's directive set is applied\n     * Combined with default directives (not override, addition)\n   - If Host is not in list:\n     * Only default directives are applied\n\n6) EXAMPLE SCENARIO:\n   \n   Default Directives: \"basic-protection\"\n   \n   Per Authority:\n   - api.example.com â†’ \"api-strict\"\n   - admin.example.com â†’ \"admin-strict\"\n   - *.test.example.com â†’ \"test-relaxed\"\n   \n   Result:\n   - Request to api.example.com: basic-protection + api-strict\n   - Request to admin.example.com: basic-protection + admin-strict\n   - Request to app.test.example.com: basic-protection + test-relaxed\n   - Request to www.example.com: only basic-protection\n\n7) IMPORTANT NOTES:\n   âš  Domain requires exact match (not case-sensitive)\n   âš  Wildcard (*) can be used for subdomain\n   âš  Specifying port is optional (default: from request)"}
{"resource":"WAF","category":"metric_labels","instruction":"What are WAF Metric Labels and how are they configured?","output":"METRIC LABELS (METRIC LABELS):\n\n1) WHAT ARE METRIC LABELS:\n   - Custom labels added to WAF metrics\n   - Used for filtering in Prometheus/Grafana\n   - Used to categorize WAF activity\n   - In key-value pair format\n\n2) ADDING METRIC LABEL:\n   a) Find 'Metric Labels' card on WAF detail page\n   b) Type label name in 'Label Key' input field\n      - Example: environment, team, application\n   c) Type value in 'Label Value' input field\n      - Example: production, security-team, web-app\n   d) Click blue '+' button next to it\n   e) Label is added (appears in table)\n\n3) LABEL LIST:\n   - In table format:\n     * Key column\n     * Value column\n     * Actions column (delete button)\n   - Each row is one label\n\n4) DELETING LABEL:\n   - There's a red trash icon in 'Actions' column of table row\n   - Click to delete label\n\n5) USAGE SCENARIO:\n   \n   Example 1 - Environment based:\n   environment: production\n   datacenter: us-east-1\n   \n   Example 2 - Team based:\n   team: platform\n   owner: security-team\n   \n   Example 3 - Application based:\n   app: e-commerce\n   version: v2.5\n\n6) PROMETHEUS METRICS:\n   These labels are added to WAF metrics:\n   ```\n   waf_requests_total{environment=\"production\",team=\"platform\"}\n   waf_blocked_requests_total{environment=\"production\",team=\"platform\"}\n   waf_rule_matches_total{environment=\"production\",team=\"platform\"}\n   ```\n\n7) USAGE IN GRAFANA:\n   - Filter by label in dashboard:\n     * waf_requests_total{environment=\"production\"}\n     * waf_blocked_requests_total{team=\"security-team\"}\n   - Useful for distinguishing when multiple WAF profiles exist\n\n8) IMPORTANT NOTES:\n   âš  Label key must be unique (same key cannot be added twice)\n   âš  Label naming convention: lowercase, underscore (snake_case)\n   âš  Changing metric labels doesn't break metric history (continues with new labels)"}
{"resource":"WAF","category":"wasm_integration","instruction":"How do I assign WAF profile to listener (with Wasm filter)?","output":"ASSIGNING WAF TO LISTENER (WITH WASM FILTER):\n\n1) PREREQUISITES:\n   a) WAF profile must be created (from WAF tab)\n   b) At least one directive set must be defined\n   c) Default directives must be selected\n   d) HTTP Connection Manager (HCM) must exist in listener\n\n2) WASM FILTER ADDING STEPS:\n   \n   a) EXPAND LISTENER:\n      - In Resources â†’ Listener tab\n      - Click on relevant listener row (expand)\n   \n   b) GO TO HTTP CONNECTION MANAGER:\n      - There's a 'Filters' tab inside listener\n      - Find 'HTTP Connection Manager' card\n   \n   c) GO TO HTTP FILTERS TAB:\n      - Select 'Filters' label from left menu\n      - HTTP Filters section opens\n      - Click blue '+' button in 'HTTP Filters' card\n   \n   d) SELECT WASM FILTER:\n      - Filter selection window (drawer) opens\n      - Find 'Wasm' filter in list\n      - Click to select, drawer closes\n   \n   e) WASM FILTER CONFIGURATION:\n      - 'Wasm' card opens\n      - Horizontal tabs: name, config, vm_config\n      - Select 'name' tab\n      - Type filter name in Name field (e.g., \"waf-filter\")\n   \n   f) CONFIG SETTINGS:\n      - Select 'config' tab\n      - 'Config' card opens\n      - Horizontal tabs: name, vm_config, configuration\n      - Select 'name' tab\n      - Name: \"envoy.wasm.runtime.v8\" (default)\n   \n   g) CONFIGURATION (WAF PROFILE SELECTION):\n      - Select 'configuration' tab\n      - 'Configuration' card opens\n      - Select from '@type' dropdown: google.protobuf.StringValue\n      - 'value' field appears\n      - Value: Type WAF profile name (e.g., \"production-waf\")\n      - âš  This field references WAF profile\n   \n   h) VM_CONFIG (OPTIONAL):\n      - Select 'vm_config' tab\n      - Runtime: \"envoy.wasm.runtime.v8\"\n      - Code: Coraza Wasm binary path\n      - Usually auto-loaded\n\n3) SAVING:\n   a) After all fields are filled\n   b) Click 'Update' or 'Create' button in top right corner\n   c) Listener is saved\n   d) Job is created, snapshot tracking begins\n\n4) VERIFICATION:\n   - Go to listener detail\n   - 'Wasm' filter should appear in HTTP Filters list\n   - WAF profile name should appear in Configuration\n\n5) HOW IT WORKS:\n   - Request arrives â†’ Enters HCM filter chain\n   - Wasm filter runs â†’ Coraza engine loads WAF profile\n   - WAF rules are checked\n   - If rule violation: Returns 403 Forbidden (or writes to log)\n   - If clean: Request continues (to upstream)\n\n6) IMPORTANT NOTES:\n   âš  Configuration value must be exact WAF profile name (no typo)\n   âš  If WAF profile is deleted, listener may return 500 error\n   âš  Wasm filter is added as http_filters in HCM\n   âš  Filter order is important: WAF should generally be at top (before Router)"}
{"resource":"WAF","category":"testing","instruction":"How do I test WAF configuration?","output":"TESTING WAF CONFIGURATION:\n\n1) PRE-TEST PREPARATION:\n   a) WAF profile must be created and saved\n   b) WAF must be assigned with Wasm filter in listener\n   c) Service must be deployed (on elchi-client)\n   d) Listener must be active and running\n\n2) BASIC TEST (SecRuleEngine Check):\n   \n   Test 1 - Normal Request:\n   ```bash\n   curl -v http://your-listener-ip:port/\n   ```\n   Expected: 200 OK (or upstream response)\n   \n   Test 2 - WAF Trigger (SQL Injection):\n   ```bash\n   curl -v \"http://your-listener-ip:port/?id=1' OR '1'='1\"\n   ```\n   Expected: 403 Forbidden (WAF blocked)\n   \n   Test 3 - XSS Attempt:\n   ```bash\n   curl -v \"http://your-listener-ip:port/?name=<script>alert(1)</script>\"\n   ```\n   Expected: 403 Forbidden\n\n3) HEADER-BASED TEST:\n   ```bash\n   curl -v -H \"User-Agent: nikto\" http://your-listener-ip:port/\n   ```\n   Expected: 403 (if scanner blocking rule exists)\n\n4) POST BODY TEST:\n   ```bash\n   curl -v -X POST -d \"username=admin' OR '1'='1\" http://your-listener-ip:port/login\n   ```\n   Expected: 403 (SQL injection in body)\n\n5) LOG CHECK:\n   \n   a) In Elchi UI:\n      - Go to 'Logs' tab from left menu\n      - Filter service logs\n      - Search with \"coraza\" or \"waf\" keyword\n      - Blocked requests appear in log:\n         ```\n         [coraza] Rule 942100 matched: SQL Injection Attack\n         [coraza] Action: deny, status: 403\n         ```\n   \n   b) Client logs:\n      - Connect to elchi-client via SSH\n      - Check Envoy access log:\n        ```bash\n        tail -f /var/log/envoy/access.log\n        ```\n      - 403 response codes are WAF blocks\n\n6) METRICS CHECK:\n   \n   a) In Elchi UI:\n      - Go to 'Metrics' tab from left menu\n      - View WAF metrics:\n        * waf_requests_total: Total requests\n        * waf_blocked_requests_total: Blocked requests\n        * waf_rule_matches_total: Rule matches\n   \n   b) Prometheus query:\n      ```promql\n      rate(waf_blocked_requests_total[5m])\n      ```\n\n7) PER AUTHORITY TEST:\n   If per-authority directives exist:\n   ```bash\n   curl -v -H \"Host: api.example.com\" \"http://listener-ip:port/?test=sqli'\"\n   curl -v -H \"Host: www.example.com\" \"http://listener-ip:port/?test=sqli'\"\n   ```\n   Different domains are evaluated with different rules\n\n8) PARANOIA LEVEL TEST:\n   - Level 1: Blocks basic attacks\n   - Level 4: Aggressive, increases false positives\n   Test: Benign requests may also be blocked (at level 4)\n\n9) DEBUG MODE:\n   If WAF is not working as expected:\n   a) Add to directive set:\n      ```\n      SecDebugLog /var/log/coraza/debug.log\n      SecDebugLogLevel 9\n      ```\n   b) Check debug log on client:\n      ```bash\n      tail -f /var/log/coraza/debug.log\n      ```\n   c) Each rule match is logged in detail\n\n10) TROUBLESHOOTING:\n    \n    Problem: Not returning 403, WAF seems not working\n    Solution:\n    - Make sure SecRuleEngine On\n    - Check if correct WAF profile name in Wasm filter configuration\n    - Was service restarted (after deploy)\n    - Check Envoy error log\n    \n    Problem: False positive (normal request being blocked)\n    Solution:\n    - Lower paranoia level (4 â†’ 2)\n    - Disable specific rules (SecRuleRemoveById)\n    - Add exclusion rules (in REQUEST-900 file)\n    \n    Problem: Metrics not showing\n    Solution:\n    - Check if metric labels are defined correctly\n    - Check if Prometheus is scraping\n    - Check if metric exists at Envoy admin endpoint:\n      ```bash\n      curl http://listener-ip:admin-port/stats | grep waf\n      ```"}
{"resource":"WAF","category":"crs_versions","instruction":"What is the difference between CRS versions and how to change them?","output":"CRS VERSIONS:\n\n1) WHAT IS CRS VERSION:\n   - OWASP Core Rule Set version\n   - Each version contains different number of rules and features\n   - Example: 4.0.0, 4.1.0, 4.14.0\n   - Newer versions provide more protection\n\n2) VIEWING AVAILABLE VERSIONS:\n   a) On WAF detail page\n   b) Open 'CRS Rule Browser' card\n   c) There's 'CRS Version' dropdown in Filters section\n   d) Open dropdown, available versions are listed\n\n3) CHANGING VERSION:\n   a) Select different version from 'CRS Version' dropdown\n   b) Rule list refreshes (according to that version)\n   c) You can see rules in selected version\n   d) If you add by clicking '+' button, that version's rule is added\n\n4) VERSION DIFFERENCES:\n   \n   v4.0.0:\n   - First stable 4.x release\n   - ~1000 rules\n   - Basic OWASP Top 10 protection\n   \n   v4.1.0:\n   - Improved JSON/GraphQL protection\n   - New transformation functions\n   - Fewer false positives\n   \n   v4.14.0:\n   - Most recent version\n   - ~1200+ rules\n   - API gateway protection added\n   - gRPC support\n\n5) VERSION USAGE IN DIRECTIVE SET:\n   CRS version is determined by Include directive:\n   ```\n   # For v4.0.0:\n   Include @owasp_crs/4.0.0/crs-setup.conf\n   \n   # For v4.14.0:\n   Include @owasp_crs/4.14.0/crs-setup.conf\n   ```\n   \n   Rules added from Rule Browser automatically use selected version\n\n6) VERSION UPGRADE:\n   \n   Scenario: Migrating from v4.0.0 to v4.14.0\n   \n   a) Create new WAF profile in test environment:\n      - Name: \"production-waf-v4.14\"\n   b) Select v4.14.0 in CRS Rule Browser\n   c) Add rules to directive set\n   d) Test in test environment (assign to test listener)\n   e) Check for false positives\n   f) Apply to production if no issues\n\n7) IMPORTANT NOTES:\n   âš  Rule IDs may change between different versions\n   âš  Test in test environment before version upgrade\n   âš  Rules may not port one-to-one from old version to new version\n   âš  Include paths change according to version"}
{"resource":"WAF","category":"advanced","instruction":"How to customize WAF rules (custom rules)?","output":"CREATING CUSTOM WAF RULES:\n\n1) WHAT IS CUSTOM RULE:\n   - Your own rules outside of CRS rules\n   - Security rules for custom business logic\n   - Uses Coraza SecRule syntax\n\n2) WRITING CUSTOM RULE:\n   \n   a) MANUAL ADDING TO DIRECTIVE SET:\n      - Select a set in Directive Sets Manager\n      - Write custom rule in 'New Directive' textarea\n      - Click 'Add Directive' button\n   \n   b) EXAMPLE CUSTOM RULE 1 - IP Blocking:\n   ```\n   SecRule REMOTE_ADDR \"@ipMatch 192.168.1.100\" \\\n       \"id:1001,phase:1,deny,status:403,msg:'Blocked IP address'\"\n   ```\n   \n   c) EXAMPLE CUSTOM RULE 2 - Custom Header Check:\n   ```\n   SecRule REQUEST_HEADERS:X-API-Key \"!@rx ^[a-f0-9]{32}$\" \\\n       \"id:1002,phase:1,deny,status:401,msg:'Invalid API key format'\"\n   ```\n   \n   d) EXAMPLE CUSTOM RULE 3 - Rate Limiting (basic):\n   ```\n   SecRule REQUEST_URI \"@streq /api/login\" \\\n       \"id:1003,phase:1,pass,setvar:ip.login_attempts=+1,expirevar:ip.login_attempts=60\"\n   SecRule IP:login_attempts \"@gt 5\" \\\n       \"id:1004,phase:1,deny,status:429,msg:'Too many login attempts'\"\n   ```\n   \n   e) EXAMPLE CUSTOM RULE 4 - Custom Regex Pattern:\n   ```\n   SecRule ARGS \"@rx (?i)(exec|eval|system)\\s*\\(\" \\\n       \"id:1005,phase:2,deny,status:403,msg:'Code injection attempt',tag:'custom-rule'\"\n   ```\n\n3) RULE SYNTAX EXPLANATION:\n   \n   SecRule [VARIABLE] \"[OPERATOR] [PATTERN]\" \\\n       \"[ACTIONS]\"\n   \n   - VARIABLE: REQUEST_URI, ARGS, REQUEST_HEADERS, REMOTE_ADDR, etc.\n   - OPERATOR: @rx (regex), @streq (string equal), @ipMatch, @gt (greater than), etc.\n   - ACTIONS:\n     * id: Unique rule ID (1000-9999 range for custom)\n     * phase: 1-5 (request/response stage)\n     * deny: Block request\n     * pass: Allow request (for logging)\n     * status: HTTP status code\n     * msg: Log message\n     * tag: Tag (for filtering)\n\n4) RULE ID PLANNING:\n   - CRS rules: 900000-999999 range\n   - Custom rules: Use 1000-99999 range\n   - Categorize to avoid conflicts:\n     * 1000-1999: IP/geo rules\n     * 2000-2999: API rules\n     * 3000-3999: Business logic rules\n\n5) WRITING MULTI-LINE RULE:\n   \n   Use '\\' for line continuation in textarea:\n   ```\n   SecRule REQUEST_METHOD \"@streq POST\" \\\n       \"id:1006,phase:1,pass,nolog,chain\"\n       SecRule REQUEST_URI \"@beginsWith /api/payment\" \\\n           \"setvar:tx.payment_request=1\"\n   ```\n\n6) RULE TESTING:\n   a) Add custom rule\n   b) Save WAF profile\n   c) Assign to test listener (or in test environment)\n   d) Test with curl:\n      ```bash\n      # Rule 1001 test (IP block):\n      curl -v http://listener-ip:port/\n      \n      # Rule 1002 test (API key):\n      curl -v -H \"X-API-Key: invalid\" http://listener-ip:port/api/\n      \n      # Rule 1003-1004 test (rate limit):\n      for i in {1..6}; do curl -v http://listener-ip:port/api/login; done\n      ```\n   e) Check custom rule ID in logs\n\n7) VARIABLE USAGE:\n   \n   Defining custom variable:\n   ```\n   SecRule REQUEST_URI \"@streq /admin\" \\\n       \"id:1007,phase:1,pass,setvar:tx.is_admin_request=1\"\n   \n   SecRule TX:is_admin_request \"@eq 1\" \\\n       \"id:1008,phase:1,pass,msg:'Admin request detected'\"\n   ```\n\n8) EXCEPTION RULES (Rule Exclusion):\n   \n   Disable CRS rule for specific path:\n   ```\n   SecRule REQUEST_URI \"@beginsWith /api/upload\" \\\n       \"id:1009,phase:1,pass,ctl:ruleRemoveById=920100\"\n   ```\n   \n   Exclude specific parameter from rule:\n   ```\n   SecRuleUpdateTargetById 942100 \"!ARGS:customer_comment\"\n   ```\n\n9) DEBUGGING CUSTOM RULES:\n   \n   a) Add debug log:\n   ```\n   SecDebugLog /var/log/coraza/custom_rules.log\n   SecDebugLogLevel 5\n   ```\n   \n   b) Add log action to rule:\n   ```\n   SecRule ARGS \"@rx pattern\" \\\n       \"id:1010,phase:2,deny,status:403,msg:'Custom rule fired',log,auditlog\"\n   ```\n   \n   c) Check log on client:\n   ```bash\n   tail -f /var/log/coraza/custom_rules.log\n   ```\n\n10) BEST PRACTICES:\n    âœ… Use unique ID (don't conflict with CRS)\n    âœ… Write descriptive msg (for troubleshooting)\n    âœ… Add tag (for filtering)\n    âœ… Test in test environment (false positive check)\n    âœ… Choose phase carefully for performance (don't use unnecessary phase 2)\n    âš  Watch regex performance (catastrophic backtracking)\n    âš  Follow variable naming convention (tx., ip., etc.)\n    âš  Rule order is important (in chain usage)"}
{"resource":"WAF","category":"troubleshooting","instruction":"WAF is not working or showing unexpected behavior, how do I debug?","output":"WAF TROUBLESHOOTING AND DEBUG:\n\n1) BASIC CHECKS:\n   \n   a) WAF PROFILE CHECK:\n      - Check if profile exists in WAF tab\n      - Is default directives selected\n      - Is there at least one directive set\n   \n   b) WASM FILTER CHECK:\n      - Is 'Wasm' in HTTP filters list in listener detail\n      - Is configuration value correct WAF profile name\n      - No typo (production-waf != production-waf1)\n   \n   c) SERVICE STATUS:\n      - Is service deployed\n      - Is listener active (started)\n      - Is client running (Left menu â†’ Clients â†’ Status)\n\n2) PROBLEM: WAF NOT RETURNING 403 (SEEMS NOT WORKING):\n   \n   a) SecRuleEngine Check:\n      - Is \"SecRuleEngine On\" in default directive set\n      - If not, add:\n        ```\n        SecRuleEngine On\n        ```\n   \n   b) Wasm Filter Configuration:\n      - Configuration @type: google.protobuf.StringValue\n      - Value: Exactly WAF profile name\n      - Copy-paste WAF profile name from WAF list\n   \n   c) Coraza Binary:\n      - Is code path in Wasm vm_config correct\n      - Does Coraza .wasm file exist on client:\n        ```bash\n        ls -la /etc/envoy/wasm/coraza.wasm\n        ```\n   \n   d) Add Test Rule:\n      - Add simple test rule:\n        ```\n        SecRule ARGS \"@rx test123\" \\\n            \"id:9999,phase:2,deny,status:403,msg:'Test rule'\"\n        ```\n      - Test:\n        ```bash\n        curl \"http://listener-ip:port/?q=test123\"\n        ```\n      - If not returning 403, WAF is not working at all\n\n3) PROBLEM: FALSE POSITIVE (NORMAL REQUEST BEING BLOCKED):\n   \n   a) Find Which Rule Triggered in Log:\n      - Search with \"coraza\" filter in Logs tab\n      - Example log:\n        ```\n        Rule 942100 matched: SQL Injection\n        ```\n   \n   b) Examine That Rule:\n      - Search ID in CRS Rule Browser (942100)\n      - Read what rule does\n      - Verify if false positive\n   \n   c) Solution 1 - Disable Rule:\n      ```\n      SecRuleRemoveById 942100\n      ```\n   \n   d) Solution 2 - Exclude for Specific Path:\n      ```\n      SecRule REQUEST_URI \"@beginsWith /api/search\" \\\n          \"id:1100,phase:1,pass,ctl:ruleRemoveById=942100\"\n      ```\n   \n   e) Solution 3 - Exclude Specific Parameter:\n      ```\n      SecRuleUpdateTargetById 942100 \"!ARGS:search_query\"\n      ```\n   \n   f) Solution 4 - Lower Paranoia Level:\n      - If using Level 4, lower to Level 2:\n        ```\n        SecAction \"id:900000,phase:1,pass,setvar:tx.paranoia_level=2\"\n        ```\n\n4) PROBLEM: METRICS NOT SHOWING:\n   \n   a) Metric Labels Check:\n      - Are metric labels defined in WAF detail\n   \n   b) Prometheus Scrape:\n      - Does metric exist at Envoy admin endpoint:\n        ```bash\n        curl http://listener-ip:9901/stats | grep waf\n        ```\n      - If exists, check Prometheus scrape config\n   \n   c) Grafana Dashboard:\n      - Is query correct:\n        ```promql\n        rate(waf_requests_total{environment=\"production\"}[5m])\n        ```\n\n5) PROBLEM: WAF TOO SLOW (PERFORMANCE):\n   \n   a) Directive Set Optimization:\n      - Remove unnecessary rules\n      - Include only needed CRS files\n      - Selective Include instead of all files:\n        ```\n        # Bad:\n        Include @owasp_crs/*.conf\n        \n        # Good:\n        Include @owasp_crs/REQUEST-920-PROTOCOL-ENFORCEMENT.conf\n        Include @owasp_crs/REQUEST-942-APPLICATION-ATTACK-SQLI.conf\n        ```\n   \n   b) Phase Optimization:\n      - Turn off response body check if unnecessary:\n        ```\n        SecResponseBodyAccess Off\n        ```\n   \n   c) Body Limit:\n      - Lower request body limit:\n        ```\n        SecRequestBodyLimit 1048576  # 1MB\n        ```\n   \n   d) Paranoia Level:\n      - Level 4 too aggressive, Level 2 sufficient:\n        ```\n        SecAction \"id:900000,phase:1,pass,setvar:tx.paranoia_level=2\"\n        ```\n\n6) ACTIVATING DEBUG MODE:\n   \n   a) Add Debug Directive:\n      ```\n      SecDebugLog /var/log/coraza/debug.log\n      SecDebugLogLevel 9\n      SecAuditEngine RelevantOnly\n      SecAuditLog /var/log/coraza/audit.log\n      ```\n   \n   b) Check Log on Client:\n      ```bash\n      # Real-time debug log:\n      tail -f /var/log/coraza/debug.log\n      \n      # Audit log (detailed transaction log):\n      tail -f /var/log/coraza/audit.log\n      ```\n   \n   c) Log Analysis:\n      - Every rule evaluation is visible\n      - Variable values are visible\n      - Transformation results are visible\n\n7) ENVOY ERROR LOG CHECK:\n   \n   a) Envoy Log on Client:\n      ```bash\n      tail -f /var/log/envoy/envoy.log | grep -i wasm\n      tail -f /var/log/envoy/envoy.log | grep -i coraza\n      ```\n   \n   b) Typical Errors:\n      - \"wasm vm: failed to load module\": Coraza binary missing or corrupted\n      - \"configuration parse error\": WAF profile name wrong\n      - \"unknown filter config type\": @type wrong\n\n8) COMMON ISSUES:\n   \n   Issue: \"403 on every request, no request passes\"\n   Solution:\n   - Set SecRuleEngine DetectionOnly (temporary):\n     ```\n     SecRuleEngine DetectionOnly\n     ```\n   - See which rules trigger in logs\n   - Fine-tune those rules\n   \n   Issue: \"Per-authority directives not working\"\n   Solution:\n   - Check if Host header is correct:\n     ```bash\n     curl -v -H \"Host: api.example.com\" http://listener-ip:port/\n     ```\n   - Domain requires exact match (case-insensitive)\n   \n   Issue: \"CRS rules not updating\"\n   Solution:\n   - Save WAF profile (Save)\n   - Restart service\n   - Check if job completed (Jobs tab)\n\n9) VALIDATION TOOLS:\n   \n   a) Configuration Validation:\n      - Elchi has built-in validation\n      - Shows warning if syntax error when saving\n   \n   b) Manual Validation:\n      - Test with Coraza standalone:\n        ```bash\n        coraza -f /path/to/directives.conf -t\n        ```\n\n10) ESCALATION:\n    \n    If problem not resolved:\n    a) Collect all logs:\n       - WAF configuration (export)\n       - Envoy error log\n       - Coraza debug log\n       - Audit log\n    \n    b) Prepare minimal reproducible example:\n       - Simple WAF profile\n       - Simple listener config\n       - Test curl command\n    \n    c) Contact Elchi support or open GitHub issue"}
{"resource":"Version Management","category":"version_filtering","instruction":"How do I filter resources by Envoy version and view only specific versions?","output":"FILTERING RESOURCES BY VERSION:\n\nElchi supports multiple Envoy versions (e.g., v1.36.2, v1.37.0, v1.38.0), allowing you to manage configurations for different Envoy releases simultaneously.\n\n---\n\n**STEP 1: NAVIGATE TO RESOURCES PAGE**\n\n1) Click on any resource type from the left menu under **'RESOURCES'**:\n   - Listener\n   - Cluster\n   - Route\n   - Endpoint\n   - Secret\n   - Extension\n   - Filter\n\n2) The Resources page opens showing all resources of that type\n\n---\n\n**STEP 2: USE VERSION FILTER**\n\nAt the top of the page, you'll see a **Filter Bar** (light card with search inputs):\n\n**Column 1: Search by Name**\n- Text input with search icon\n- Enter resource name to filter\n\n**Column 2: Filter by Version** (this is what we need!)\n- **Dropdown selector** labeled \"Filter by version\"\n- Shows all available Envoy versions (e.g., v1.36.2, v1.37.0, v1.38.0)\n- Click to open dropdown\n\n**STEP 3: SELECT A VERSION**\n\n1) Click the **\"Filter by version\"** dropdown\n2) A list appears showing all available versions:\n   - v1.36.2\n   - v1.37.0\n   - v1.38.0\n   - (etc., depending on your Elchi setup)\n3) Click on a version (e.g., **v1.37.0**)\n4) The dropdown closes and shows selected version\n\n**STEP 4: APPLY THE FILTER**\n\n1) Click the **\"Search\"** button (blue button with search icon)\n2) The data table below refreshes\n3) Now showing only resources from the selected version\n\n**Visual Confirmation:**\n- In the data table, the **\"Version\"** column shows only one version (the one you filtered)\n- Resource count updates to show filtered results\n\n---\n\n**STEP 5: CLEAR THE FILTER (Optional)**\n\nTo view all versions again:\n\n1) Click the **\"x\" icon** inside the version dropdown (clears selection)\n2) Click the **\"Search\"** button again\n3) Or click the **\"Clear\"** button (with clear icon) to reset all filters\n\n---\n\n**VERSION COLUMN IN TABLE:**\n\nEach resource row in the table has a **Version** column showing a colored **tag**:\n- **v1.36.2**: Blue tag\n- **v1.37.0**: Green tag  \n- **v1.38.0**: Purple tag\n- (Colors vary based on version)\n\nThis helps visually distinguish resources from different versions.\n\n---\n\n**UNDERSTANDING VERSION CONSOLIDATION:**\n\n**For most resources (Cluster, Route, Endpoint, Secret, etc.):**\n- Resources with **same name** but **different versions** are **consolidated** into one row\n- A **\"version selection modal\"** appears when you click on such a resource\n- This prevents duplicate rows cluttering the table\n\n**For Listeners (special case):**\n- Listeners are **NOT consolidated**\n- Each version appears as a separate row\n- This is because listeners can be bulk-upgraded, so you need to see all versions\n- Checkbox selection is available for listeners to select multiple for upgrade\n\n---\n\n**COMMON USE CASES:**\n\n**Use Case 1: View only production version**\n- Filter by version: v1.37.0\n- Click Search\n- Now you see only resources running in production\n\n**Use Case 2: Check what exists in a new version**\n- Filter by version: v1.38.0 (newly installed version)\n- Click Search\n- See which resources have been created or upgraded to the new version\n\n**Use Case 3: Find resources that need upgrading**\n- Filter by version: v1.36.2 (old version)\n- Click Search\n- This shows all resources still on the old version\n- You can then plan upgrade strategy\n\n**Use Case 4: Compare versions**\n- Open two browser tabs\n- Tab 1: Filter by v1.36.2\n- Tab 2: Filter by v1.37.0\n- Compare which resources exist in each version\n\n---\n\n**AVAILABLE VERSIONS:**\n\nAvailable versions are configured in Elchi settings (typically in `APP_CONFIG.AVAILABLE_VERSIONS`).\n\nCommon version sets:\n- **Two versions**: v1.36.2, v1.37.0 (during migration)\n- **Three versions**: v1.36.2, v1.37.0, v1.38.0 (testing new release)\n- **Single version**: v1.37.0 (after full migration)\n\nYour Elchi administrator manages which versions are available.\n\n---\n\n**KEYBOARD SHORTCUTS:**\n\n- Type in search box â†’ Press **Enter** â†’ Auto-applies filter (same as clicking Search)\n- Click dropdown â†’ Type version number â†’ Auto-filters dropdown list\n\n---\n\n**TROUBLESHOOTING:**\n\n**Problem**: Version filter dropdown is empty\n- **Cause**: No versions configured in Elchi\n- **Solution**: Contact administrator to configure AVAILABLE_VERSIONS\n\n**Problem**: Filtering shows no results\n- **Cause**: No resources exist in that version\n- **Solution**: Normal if you just installed a new version. Create resources or upgrade existing ones.\n\n**Problem**: Can't clear version filter\n- **Cause**: Need to click \"x\" icon or \"Clear\" button\n- **Solution**: Click the small \"x\" inside the dropdown, then click \"Search\" again"}
{"resource":"Version Management","category":"version_selection_modal","instruction":"What is the version selection modal and when does it appear?","output":"VERSION SELECTION MODAL:\n\nWhen you click on a resource that exists in **multiple versions**, Elchi shows a **version selection modal** asking you to choose which version you want to open.\n\n---\n\n**WHEN IT APPEARS:**\n\nThe modal appears when:\n\n1. **You click on a resource name** in the data table (any resource except Listener)\n2. **That resource exists in 2+ versions** (e.g., \"backend-cluster\" exists in both v1.36.2 and v1.37.0)\n3. **You haven't filtered by version** (if you filter by version first, modal won't appear because only one version is shown)\n\n**Example Scenario:**\n- You have a cluster named \"api-backend\"\n- It exists in v1.36.2, v1.37.0, and v1.38.0\n- You click on \"api-backend\" in the Clusters table\n- **Version selection modal opens**\n\n---\n\n**WHAT THE MODAL LOOKS LIKE:**\n\n**Modal Header:**\n- Title: **\"Select Version\"**\n- Close button (X) in top-right corner\n\n**Modal Body:**\n\n**Description Text:**\n```\nResource backend-cluster has multiple versions. Please select one:\n```\n- Resource name is shown in **bold**\n\n**Version List:**\n- Bordered list showing all versions\n- Each version is a **clickable row**\n- Each row contains:\n  - **Version tag** (colored, e.g., blue \"v1.36.2\", green \"v1.37.0\")\n  - **Updated date** (e.g., \"Updated: 12/15/2024\")\n  - Shows when this version was last modified\n\n**Visual Interactions:**\n- Hover over a row â†’ Background turns light gray (#f5f5f5)\n- Cursor changes to pointer (hand icon)\n- Click anywhere on the row â†’ Selects that version\n\n**No Footer Buttons:**\n- Modal has no \"OK\" or \"Cancel\" buttons\n- Clicking on a version row automatically selects it and closes modal\n- Clicking outside modal or \"X\" button â†’ Cancels and closes modal\n\n---\n\n**STEP-BY-STEP USAGE:**\n\n**STEP 1: TRIGGER THE MODAL**\n\n1) Go to any resource page (e.g., 'Cluster')\n2) **Don't apply version filter** (or clear it if applied)\n3) Find a resource that exists in multiple versions\n4) Click on the **resource name** (blue link in Name column)\n5) Modal opens\n\n**STEP 2: REVIEW AVAILABLE VERSIONS**\n\n1) Modal shows: \"Resource **X** has multiple versions. Please select one:\"\n2) List displays all versions of this resource\n3) Check the **\"Updated\"** date to see which version is newest\n\n**STEP 3: SELECT A VERSION**\n\n1) **Hover** over the version you want to open\n   - Row background changes to gray\n2) **Click** on that row\n3) Modal closes immediately\n4) Resource edit page opens for the selected version\n\n**STEP 4: VIEW THE RESOURCE**\n\n- You're now viewing/editing the resource in the selected version\n- Version is shown at top of edit page\n- URL includes version parameter: `?version=v1.37.0`\n\n---\n\n**DIFFERENT ACTIONS TRIGGER DIFFERENT MODALS:**\n\nThe `action` prop determines the modal's purpose:\n\n**1. action='open'** (default - for viewing/editing)\n- Title: \"Select Version\"\n- Shows \"Updated\" date\n- Clicking a version â†’ Opens resource edit page\n\n**2. action='delete'**\n- Title: \"Select Version to Delete\"\n- Shows \"Updated\" date\n- Clicking a version â†’ Deletes that version of the resource (with confirmation)\n\n**3. action='duplicate'**\n- Title: \"Select Version to Duplicate\"\n- Shows \"Updated\" date\n- Clicking a version â†’ Opens create page with that version's data pre-filled\n\n**4. action='upgrade'**\n- Title: \"Select Version to Upgrade From\"\n- **Does NOT show \"Updated\" date** (because upgrade flow doesn't need it)\n- Clicking a version â†’ Opens upgrade workflow for that version\n\n**5. action='dependency'**\n- Title: \"Select Version for Dependency View\"\n- Shows dependencies for that version\n\n**6. action='routemap'**\n- Title: \"Select Version for Route Map\"\n- Opens route map visualization for that version\n\n---\n\n**VERSION TAG COLORS:**\n\nVersions are color-coded for easy identification:\n\n- **v1.36.2**: Blue tag\n- **v1.37.0**: Green tag\n- **v1.38.0**: Purple tag\n- **v1.39.0**: Orange tag\n- (Colors generated based on version number for consistency)\n\nFunction `getVersionAntdColor(version)` determines the color.\n\n---\n\n**AVOIDING THE MODAL:**\n\n**Method 1: Filter by Version First**\n\n1) Before clicking on resource, apply version filter at top of page\n2) Select specific version (e.g., v1.37.0)\n3) Click \"Search\"\n4) Now clicking on resources opens them directly (no modal)\n\n**Method 2: Use Version Column Link** (if available)\n\n- Some tables have clickable version tags in the Version column\n- Clicking the version tag directly opens that version\n- No modal appears\n\n---\n\n**COMMON USE CASES:**\n\n**Use Case 1: Editing Old Version**\n- You need to fix a bug in v1.36.2 while v1.37.0 is also running\n- Click on resource name\n- Modal appears showing both v1.36.2 and v1.37.0\n- Click on **v1.36.2** row\n- Edit the old version\n\n**Use Case 2: Comparing Versions**\n- Open resource in v1.36.2 (via modal)\n- Copy URL\n- Open new browser tab\n- Navigate to same resource\n- Select v1.37.0 from modal\n- Compare configurations side-by-side\n\n**Use Case 3: Deleting One Version**\n- You want to delete v1.36.2 version but keep v1.37.0\n- Click actions menu (â‹®) on resource row\n- Select \"Delete\"\n- Modal appears: \"Select Version to Delete\"\n- Click on **v1.36.2** row\n- Confirmation dialog appears\n- Confirm deletion\n- Only v1.36.2 is deleted, v1.37.0 remains\n\n**Use Case 4: Duplicating from Specific Version**\n- You want to create a new cluster based on v1.37.0 config\n- Click actions menu (â‹®)\n- Select \"Duplicate\"\n- Modal appears: \"Select Version to Duplicate\"\n- Click on **v1.37.0** row\n- Create page opens with v1.37.0 config pre-filled\n- Modify and save as new resource\n\n---\n\n**TECHNICAL DETAILS:**\n\nThe modal receives these props:\n\n```typescript\ninterface VersionSelectionModalProps {\n    visible: boolean;              // Controls modal open/close\n    onClose: () => void;           // Called when modal closes\n    onSelect: (version, id) => void; // Called when version is clicked\n    resourceName: string;          // Resource name to display\n    versions: VersionOption[];     // Array of available versions\n    title?: string;                // Modal title (default: \"Select Version\")\n    action?: string;               // Purpose: 'open' | 'delete' | 'duplicate' | 'upgrade' | etc.\n}\n```\n\n**VersionOption structure:**\n```typescript\n{\n    version: string;    // e.g., \"v1.37.0\"\n    id: string;         // MongoDB ObjectId of this version\n    created_at: string; // ISO timestamp\n    updated_at: string; // ISO timestamp\n}\n```\n\n---\n\n**TROUBLESHOOTING:**\n\n**Problem**: Modal appears even though I filtered by version\n- **Cause**: Filter wasn't applied (forgot to click \"Search\" button)\n- **Solution**: Clear filter, re-select version, click \"Search\"\n\n**Problem**: Modal shows only one version\n- **Cause**: Resource only exists in one version\n- **Solution**: Normal behavior. Modal will auto-close and open that version. Consider upgrading/duplicating to other versions.\n\n**Problem**: Can't close modal\n- **Cause**: Need to either select a version or click \"X\" / click outside\n- **Solution**: Click the \"X\" button in top-right or click on the gray area outside the modal\n\n**Problem**: \"Updated\" date is confusing\n- **Cause**: Shows last modification time, not version release date\n- **Solution**: Use the date to identify which version was most recently edited, not which Envoy version is newer"}
{"resource":"Version Management","category":"resource_creation_version","instruction":"When creating a new resource, how do I select which Envoy version to create it in?","output":"SELECTING VERSION DURING RESOURCE CREATION:\n\nWhen you create a new resource (Listener, Cluster, Route, etc.), Elchi asks you to select:\n1. **Which Envoy version** to create it in (e.g., v1.36.2, v1.37.0)\n2. **Which resource type** (only for resources with multiple types, like Secrets or TLS)\n\n---\n\n**STEP 1: NAVIGATE TO CREATE PAGE**\n\n1) Click on a resource type from left menu (e.g., 'Cluster')\n2) Click the **\"Add New\"** button at top-right\n3) A **modal appears** before the creation form\n\n---\n\n**STEP 2: UNDERSTAND THE VERSION SELECTION MODAL**\n\n**Modal Title:**\n```\nConfigure Resource Creation\n```\n\n**Modal Subtitle:**\n```\nSelect proxy version and resource type for your configuration\n```\n\n**Modal Content:**\n\nThe modal has two sections (cards with gray background):\n\n---\n\n**SECTION 1: VERSION SELECTION** (always shown)\n\n**Card Header:**\n```\nðŸš€ Version\n```\n\n**Dropdown:**\n- Large dropdown selector\n- Placeholder: \"Select Version\"\n- Shows all available Envoy versions:\n  - v1.36.2\n  - v1.37.0\n  - v1.38.0\n  - (etc.)\n\n**Auto-Selection:**\n- If only **one version** is available, it's **automatically selected**\n- Label shows: \"ðŸš€ Version (Pre-selected)\"\n- Dropdown is still editable but shows the single version\n\n**URL Pre-Selection:**\n- If URL contains `?version=v1.37.0`, that version is auto-selected\n- This happens when duplicating or upgrading resources\n\n---\n\n**SECTION 2: RESOURCE TYPE SELECTION** (only for some resources)\n\n**When it appears:**\n- Only shown for resources with **multiple types**\n- Example resources:\n  - **Secret**: Can be TLS Certificate, Validation Context, Session Tickets, or Generic Secret\n  - **TLS**: Can be Downstream TLS Context or Upstream TLS Context\n\n**Card Header:**\n```\nðŸ”§ [Resource Type Name]\n```\n\nExample for Secret:\n```\nðŸ”§ Secret Type\n```\n\n**Dropdown:**\n- Large dropdown selector\n- Placeholder: \"Select Secret Type\" (or similar)\n- Shows available types:\n  - TLS Certificate\n  - Validation Context\n  - Session Ticket Keys\n  - Generic Secret\n\n**Default Selection:**\n- First option is selected by default\n- Example: \"TLS Certificate\" for Secrets\n\n---\n\n**STEP 3: SELECT VERSION**\n\n1) Click the **Version dropdown**\n2) List of available versions appears\n3) Click on the version you want (e.g., **v1.37.0**)\n4) Dropdown closes and shows selected version\n\n**Decision Factors:**\n\n**Choose the version where:**\n- Your clients are currently running (for immediate use)\n- You're planning to deploy next (for preparation)\n- Your other related resources exist (for consistency)\n\n**Example:**\n- If your listeners are in v1.37.0, create clusters in v1.37.0\n- If you're testing v1.38.0, create resources there\n\n---\n\n**STEP 4: SELECT RESOURCE TYPE (if applicable)**\n\nIf the second section appears:\n\n1) Click the **Resource Type dropdown**\n2) Choose the appropriate type\n   - For Secrets: Usually \"TLS Certificate\" for HTTPS certs\n   - For TLS: \"Downstream TLS Context\" for client-facing HTTPS\n3) Dropdown shows selected type\n\n---\n\n**STEP 5: CONFIRM SELECTION**\n\n**Footer Buttons:**\n\nThe modal footer has two buttons:\n\n1. **\"Cancel\"** (left, text-only button)\n   - Closes modal\n   - Returns to resources list page\n   - No resource is created\n\n2. **\"OK\"** (right, text-only button)\n   - **Disabled** (gray) if version not selected\n   - **Enabled** (blue) when all required selections made\n   - Click to proceed to creation form\n\n**STEP 6: PROCEED TO CREATION FORM**\n\n1) Click **\"OK\"** button\n2) Modal closes\n3) **Resource creation form** appears\n4) Version is locked in (shown at top)\n5) Begin configuring the resource\n\n---\n\n**SPECIAL CASES:**\n\n**Case 1: Only One Version Available**\n\n- Version dropdown shows single version\n- It's auto-selected\n- Label says \"(Pre-selected)\"\n- If no resource type selection needed:\n  - Modal auto-submits\n  - Creation form opens immediately\n  - You skip manual selection\n\n**Case 2: Coming from Duplicate Action**\n\n- URL contains `?version=v1.37.0&duplicate=true`\n- Version is pre-selected (source version)\n- You can change it to duplicate to a different version\n- Resource type matches source\n- Click \"OK\" to proceed with duplication\n\n**Case 3: Coming from Upgrade Action**\n\n- URL contains `?version=v1.38.0&upgrade=true`\n- Version is pre-selected (target version for upgrade)\n- You can't easily change it (upgrade target is pre-determined)\n- Click \"OK\" to proceed\n\n---\n\n**RESOURCE TYPE EXAMPLES:**\n\n**For Secrets:**\n\nOptions in dropdown:\n1. **TLS Certificate** (default)\n   - For HTTPS certificates (cert + private key)\n   - Most common choice\n\n2. **Validation Context**\n   - For CA certificates (trusted root CAs)\n   - Used to validate client certificates (mTLS)\n\n3. **Session Ticket Keys**\n   - For TLS session ticket encryption\n   - Advanced use case\n\n4. **Generic Secret**\n   - For other secret types (auth tokens, API keys)\n   - Less common\n\n**For TLS:**\n\nOptions in dropdown:\n1. **Downstream TLS Context**\n   - For client-to-Envoy connections (HTTPS server)\n   - Listeners use this\n\n2. **Upstream TLS Context**\n   - For Envoy-to-backend connections (HTTPS client)\n   - Clusters use this\n\n---\n\n**VERSION CONSISTENCY BEST PRACTICES:**\n\n**Rule 1: Create dependencies in same version**\n- Listener (v1.37.0) â†’ Route (v1.37.0) â†’ Cluster (v1.37.0)\n- Don't mix versions in dependency chain\n\n**Rule 2: Upgrade all or nothing**\n- When upgrading to v1.38.0, upgrade entire stack\n- Listener + Route + Cluster + Endpoints\n- Use upgrade tool for automatic dependency handling\n\n**Rule 3: Test in new version first**\n- Create test resources in v1.38.0\n- Validate configuration\n- Then upgrade production resources\n\n---\n\n**MODAL BEHAVIOR:**\n\n**Modal cannot be closed by:**\n- Clicking outside (modal is centered with dark backdrop)\n- Pressing Escape key (not implemented)\n\n**Modal can be closed by:**\n- Clicking **\"Cancel\"** button\n- Clicking **\"X\"** button (if present - not shown in all cases)\n- Clicking **\"OK\"** button (proceeds to next step)\n\n**Closing behavior:**\n- When closed via Cancel: Returns to resources list\n- When closed via OK: Opens creation form\n\n---\n\n**FOOTER BUTTON STATES:**\n\n**\"OK\" button is DISABLED when:**\n- Version not selected\n- Resource type not selected (if type selection is required)\n- Button appears gray and is not clickable\n\n**\"OK\" button is ENABLED when:**\n- Version is selected\n- Resource type is selected (if required)\n- All required selections complete\n- Button appears blue and is clickable\n- Hover shows pointer cursor\n\n---\n\n**TROUBLESHOOTING:**\n\n**Problem**: \"OK\" button is disabled\n- **Cause**: Version or resource type not selected\n- **Solution**: Select version from dropdown, then select resource type if applicable\n\n**Problem**: Modal doesn't appear when clicking \"Add New\"\n- **Cause**: Only one version available and no resource type selection needed\n- **Solution**: Normal behavior, creation form opens directly with auto-selected version\n\n**Problem**: Want to change version after clicking \"OK\"\n- **Cause**: Version is locked once you proceed to creation form\n- **Solution**: Cancel creation, go back to resources list, click \"Add New\" again, select different version\n\n**Problem**: Don't know which version to choose\n- **Cause**: Multiple versions available, unsure which to use\n- **Solution**: \n  - Check which version your listeners are running (filter by version on Listeners page)\n  - Create resource in the same version as your active deployment\n  - If testing, create in newer version\n\n**Problem**: Wrong resource type was selected\n- **Cause**: Clicked wrong option in dropdown\n- **Solution**: Before clicking \"OK\", re-open dropdown and select correct type. After clicking \"OK\", must cancel and start over."}
{"resource":"Version Management","category":"bulk_listener_upgrade","instruction":"How do I upgrade multiple listeners from one Envoy version to another?","output":"BULK LISTENER UPGRADE:\n\nElchi provides a specialized tool for upgrading multiple listeners from one Envoy version to another (e.g., v1.36.2 â†’ v1.37.0) with automatic dependency handling.\n\n---\n\n**STEP 1: NAVIGATE TO LISTENERS PAGE**\n\n1) Click **'Listener'** from left menu under RESOURCES\n2) Listeners page opens\n\n---\n\n**STEP 2: FILTER BY SOURCE VERSION**\n\nFirst, identify which listeners to upgrade:\n\n1) Use the **\"Filter by version\"** dropdown at top\n2) Select the **source version** (version you're upgrading FROM)\n   - Example: Select **v1.36.2**\n3) Click **\"Search\"** button\n4) Table now shows only listeners in v1.36.2\n\n---\n\n**STEP 3: SELECT LISTENERS FOR UPGRADE**\n\n**Checkbox Column:**\n\nThe listeners table has a **checkbox column** (first column, left side):\n\n**Header Checkbox:**\n- Checkbox in table header row\n- Click to **select all listeners** on current page\n- Click again to **deselect all**\n\n**Row Checkboxes:**\n- Each listener row has its own checkbox\n- Click to select/deselect individual listeners\n- Selected rows are highlighted (light blue background)\n\n**STEP 3A: SELECT ALL** (easiest method)\n\n1) Click the **header checkbox**\n2) All listeners on current page are selected\n3) If you have multiple pages:\n   - Select all on page 1\n   - Navigate to page 2 (pagination at bottom)\n   - Select all on page 2\n   - Repeat for all pages\n\n**STEP 3B: SELECT SPECIFIC LISTENERS**\n\n1) Click checkboxes for specific listeners you want to upgrade\n2) Skip listeners you want to keep on old version\n3) Selected count appears in upgrade button\n\n**Selection Counter:**\n\nAs you select listeners, a button appears at **top-right** of the page:\n\n```\nðŸ”¼ Upgrade (5) from v1.36.2\n```\n\n- **\"5\"** = Number of selected listeners\n- **\"v1.36.2\"** = Source version (auto-detected from filtered version)\n\n---\n\n**STEP 4: OPEN UPGRADE MODAL**\n\n1) Click the **\"Upgrade (X) from vY.Y.Y\"** button\n2) **Listener Upgrade Modal** opens\n\n---\n\n**STEP 5: CONFIGURE UPGRADE IN MODAL**\n\n**Modal Title:**\n```\nUpgrade Listeners\n```\n\n**Modal Content Sections:**\n\n---\n\n**SECTION 1: SELECTED LISTENERS**\n\n**Label:**\n```\nSelected Listeners (5)\n```\n\n**Content:**\n- Gray box with rounded corners\n- Shows selected listener names as **tags**\n- Example:\n  ```\n  [api-gateway] [web-frontend] [internal-api] [admin-panel] [metrics-exporter]\n  ```\n- Scrollable if many listeners\n- Max height: 120px\n\n**Review:**\n- Verify this is the correct list of listeners\n- If wrong listeners selected, click \"Cancel\" and reselect\n\n---\n\n**SECTION 2: TARGET VERSION**\n\n**Label:**\n```\nTarget Version *\n```\n(asterisk indicates required field)\n\n**Dropdown:**\n- Shows only **higher versions** than current\n- Example: If current is v1.36.2, shows:\n  - v1.37.0\n  - v1.38.0 (Latest)\n- Latest version is labeled: \"v1.38.0 (Latest)\"\n\n**Selection:**\n1) Click dropdown\n2) Select target version (e.g., **v1.37.0**)\n3) Dropdown shows selected version\n\n**No Higher Versions?**\n\nIf no higher versions available:\n- Dropdown is empty\n- **Info alert** appears (blue box):\n  ```\n  â„¹ No higher versions available\n  Current version v1.36.2 is already the latest.\n  ```\n- \"Upgrade\" button is disabled\n- **Solution**: Your Elchi doesn't have newer Envoy versions installed. Contact administrator.\n\n---\n\n**SECTION 3: UPGRADE OPTIONS**\n\n**Label:**\n```\nUpgrade Options\n```\n\n**Checkbox 1: Auto-create missing resources**\n\n```\nâ˜‘ Auto-create missing resources\n```\n\n- **Default**: Checked (enabled)\n- **What it does**: Automatically creates dependencies that don't exist in target version\n- **Example**: \n  - Listener \"api-gateway\" (v1.36.2) references cluster \"backend-cluster\" (v1.36.2)\n  - You upgrade listener to v1.37.0\n  - \"backend-cluster\" doesn't exist in v1.37.0\n  - If checked: System automatically creates \"backend-cluster\" in v1.37.0 (copies from v1.36.2)\n  - If unchecked: Upgrade fails with error \"cluster 'backend-cluster' not found in v1.37.0\"\n\n**When to enable:**\n- **Always**, unless you want manual control\n- Saves time and prevents errors\n- Most common choice\n\n**When to disable:**\n- You want to manually review/create dependencies first\n- You have custom configurations that shouldn't be auto-copied\n- Testing/validation purposes\n\n---\n\n**Checkbox 2: Dry run (preview changes only)**\n\n```\nâ˜ Dry run (preview changes only)\n```\n\n- **Default**: Unchecked (disabled)\n- **What it does**: Runs upgrade in **preview mode** without actually modifying anything\n- **Creates**: RESOURCE_UPGRADE(DRY) job instead of RESOURCE_UPGRADE\n- **Result**: Shows what WOULD happen, but doesn't apply changes\n\n**When to enable:**\n- **First time upgrading**: Always do dry run first to preview\n- **Complex setups**: Many dependencies, want to see analysis\n- **Production systems**: Verify before committing\n\n**When to disable:**\n- After dry run looks good, ready to commit\n- Simple setups with few dependencies\n- Already tested in staging environment\n\n**Dry Run Workflow:**\n1. Enable \"Dry run\"\n2. Click \"Upgrade\"\n3. Job runs and shows analysis\n4. Review dependency analysis in job detail page\n5. If looks good, go back and run again WITHOUT dry run\n6. Real upgrade happens\n\n---\n\n**SECTION 4: INFO ALERT**\n\n**Blue information box** at bottom shows:\n\n```\nâ„¹ Upgrade Information\n\nâ€¢ Current version: v1.36.2\nâ€¢ Selected listeners will be upgraded to the target version\nâ€¢ Dependencies and related resources will be updated automatically\nâ€¢ Dry run mode: No changes will be applied  [only if dry run enabled]\n```\n\n---\n\n**STEP 6: CONFIRM AND START UPGRADE**\n\n**Footer Buttons:**\n\n1. **\"Cancel\"** (left, text-only)\n   - Closes modal\n   - No upgrade happens\n   - Returns to listeners page\n\n2. **\"Upgrade\"** (right, text-only)\n   - **Disabled** if target version not selected\n   - **Enabled** when target version is selected\n   - Click to proceed\n\n**STEP 6A: CLICK UPGRADE**\n\n1) Ensure target version is selected\n2) Click **\"Upgrade\"** button\n3) **Confirmation modal** appears (nested modal)\n\n---\n\n**STEP 7: CONFIRM UPGRADE (SECOND MODAL)**\n\n**Confirmation Modal Title:**\n```\nâš  Confirm Listener Upgrade\n```\n\n**Confirmation Modal Content:**\n\n**Line 1:**\n```\nUpgrading 5 listener(s) from [v1.36.2] to [v1.37.0]\n```\n- Version tags are colored (blue â†’ green)\n\n**Listener List Box:**\n- Gray scrollable box (max height: 150px)\n- Shows all selected listener names as tags\n- Same list as before, for final verification\n\n**Downtime Warning** (if NOT dry run):\n\n**Red alert box:**\n```\nâš  Downtime Warning\n\nThe above managed listeners will experience momentary downtime \nduring version change. Are you sure you want to proceed?\n```\n\n- **Only shown if dry run is DISABLED**\n- Warns about brief service interruption\n- Managed listeners need to be redeployed with new version\n- Downtime is typically 1-5 seconds (Envoy hot-reload)\n\n**No warning if dry run is ENABLED** (preview mode, no actual changes)\n\n---\n\n**STEP 8: FINAL CONFIRMATION**\n\n**Confirmation Modal Buttons:**\n\n1. **\"Cancel\"** (left)\n   - Aborts upgrade\n   - Returns to upgrade modal (first modal)\n\n2. **\"Yes, Upgrade\"** (right, red/danger button)\n   - Confirms upgrade\n   - Starts background job\n   - Button text changes to \"Upgrading...\" while processing\n\n**STEP 8A: CLICK \"YES, UPGRADE\"**\n\n1) Click the red **\"Yes, Upgrade\"** button\n2) Button shows \"Upgrading...\" with loading state\n3) API request is sent to backend: `POST /api/v3/resource/upgrade`\n4) Confirmation modal closes\n5) Upgrade modal closes\n6) **You're redirected to Job Detail page**\n\n---\n\n**STEP 9: MONITOR UPGRADE JOB**\n\nYou're automatically navigated to:\n```\n/jobs/{job_object_id}\n```\n\n**Job Type:**\n- **RESOURCE_UPGRADE** (if dry run disabled)\n- **RESOURCE_UPGRADE(DRY)** (if dry run enabled)\n\n**Job Detail Page Shows:**\n\n**A) UPGRADE ANALYSIS Card** (expand for details)\n\n**Overall Stats:**\n- **Total Dependencies**: 45\n- **Already Exist**: 38 (green)\n- **Need to Create**: 7 (orange)\n\n**Listener Details** (per-listener breakdown):\n\nFor each listener (e.g., \"api-gateway\"):\n- **Missing Resources** (orange boxes):\n  - [Cluster] backend-v2-cluster\n  - [Route] api-routes-v2\n  - [Secret] wildcard-tls-cert\n- **Existing Resources** (green boxes):\n  - [Cluster] auth-cluster\n  - [Endpoint] backend-endpoints\n\n**B) JOB STATUS Card**\n\n- Progress bar showing upgrade progress\n- Status: RUNNING â†’ COMPLETED / FAILED\n\n**C) CREATED RESOURCES Card** (after completion)\n\n- Shows all resources created during upgrade\n- Green boxes: Successfully created\n- Gray boxes: Skipped (already existed)\n\n---\n\n**STEP 10: VERIFY UPGRADE SUCCESS**\n\n**After job completes (status: COMPLETED):**\n\n1) Go back to 'Listener' page\n2) Filter by **new version** (e.g., v1.37.0)\n3) Click \"Search\"\n4) Verify all upgraded listeners appear\n5) Check listener names match the ones you selected\n\n**Check Dependencies:**\n\n1) Go to 'Cluster' page\n2) Filter by v1.37.0\n3) Verify clusters were auto-created\n4) Same for Routes, Secrets, etc.\n\n---\n\n**POST-UPGRADE DEPLOYMENT:**\n\n**If listeners are MANAGED (have services):**\n\nListeners won't automatically run in new version. You need to deploy:\n\n1) Go to 'Services' page under ADMINISTRATION\n2) Find services for upgraded listeners\n3) Services are still running v1.36.2 (old version)\n4) Update service to use new version:\n   - Edit service\n   - Change version to v1.37.0\n   - Save\n5) Deploy to clients:\n   - Click \"Reload\" or \"Restart\" button\n   - Snapshot is sent with new version\n\n**If listeners are UNMANAGED:**\n\n- No deployment needed\n- Configuration is ready in v1.37.0\n- Use as-is or create service later\n\n---\n\n**UPGRADE OPTIONS COMPARISON:**\n\n| Option | Auto-Create: ON | Auto-Create: OFF | Dry Run: ON | Dry Run: OFF |\n|--------|-----------------|------------------|-------------|-------------|\n| **Creates missing dependencies** | âœ… Yes | âŒ No | âš  Preview only | âœ… Yes |\n| **Modifies actual resources** | âœ… Yes | âœ… Yes | âŒ No (preview) | âœ… Yes |\n| **Requires manual dependency creation** | âŒ No | âœ… Yes | N/A | âŒ No |\n| **Safe for testing** | âš  Medium | âŒ No | âœ… Yes | âŒ No |\n| **Recommended for production** | âœ… Yes (after dry run) | âŒ No | âœ… Yes (first run) | âš  Yes (after dry run) |\n\n---\n\n**BEST PRACTICES:**\n\n**1. Always dry run first:**\n   ```\n   Step 1: Enable dry run â†’ Upgrade â†’ Review analysis\n   Step 2: Disable dry run â†’ Upgrade â†’ Real upgrade\n   ```\n\n**2. Upgrade in batches:**\n   - Don't upgrade all listeners at once\n   - Start with 1-2 test listeners\n   - Verify they work\n   - Then upgrade remaining listeners\n\n**3. Check dependencies first:**\n   - Before upgrading, review which clusters/routes are used\n   - Ensure critical resources exist or will be created\n   - Use dry run to see full dependency list\n\n**4. Plan downtime:**\n   - Managed listeners experience brief downtime\n   - Schedule upgrades during maintenance windows\n   - Notify stakeholders\n\n**5. Keep backups:**\n   - Old version (v1.36.2) listeners still exist\n   - Don't delete until new version is verified\n   - Easy rollback if issues occur\n\n---\n\n**TROUBLESHOOTING:**\n\n**Problem**: \"Upgrade\" button doesn't appear\n- **Cause**: No listeners selected\n- **Solution**: Select at least one listener using checkboxes\n\n**Problem**: \"No higher versions available\" alert\n- **Cause**: Current version is latest\n- **Solution**: Install newer Envoy version in Elchi or downgrade not supported\n\n**Problem**: Upgrade job fails with \"missing dependency\" error\n- **Cause**: \"Auto-create missing\" was disabled\n- **Solution**: Enable \"Auto-create missing\" and retry job\n\n**Problem**: Want to upgrade to v1.38.0 but only v1.37.0 shows\n- **Cause**: Can only upgrade to next higher version, not skip versions\n- **Solution**: Upgrade v1.36.2 â†’ v1.37.0 first, then v1.37.0 â†’ v1.38.0\n- **OR**: v1.38.0 is not installed in Elchi\n\n**Problem**: Upgraded listeners don't appear in new version\n- **Cause**: Job failed or is still running\n- **Solution**: Check job status on Jobs page, wait for completion or troubleshoot errors"}
{"resource":"Version Management","category":"duplicate_resource","instruction":"How do I duplicate a resource to create a copy in the same or different version?","output":"DUPLICATING RESOURCES:\n\nDuplicating creates a **copy** of an existing resource, allowing you to:\n- Create similar resources quickly (e.g., copy cluster configuration for new environment)\n- Copy resource to a different Envoy version\n- Use existing config as a template\n\n---\n\n**STEP 1: FIND THE RESOURCE TO DUPLICATE**\n\n1) Go to the resource page (e.g., 'Cluster', 'Listener', 'Route')\n2) Locate the resource you want to duplicate in the table\n\n---\n\n**STEP 2: OPEN ACTIONS MENU**\n\n**Method A: Via Three-Dot Menu** (most resources)\n\n1) Find the **three-dot menu (â‹®)** icon on the row (usually first column)\n2) Click on it\n3) Dropdown menu appears with actions:\n   - View\n   - Edit\n   - **Duplicate** â† this is what we need\n   - Delete\n   - (other actions depending on resource type)\n4) Click **\"Duplicate\"**\n\n**Method B: Via Action Column Buttons** (some resources)\n\n- Some resource tables have a \"Duplicate\" button directly visible\n- Click the **\"Duplicate\"** button (usually shows a copy icon)\n\n---\n\n**STEP 3: HANDLE VERSION SELECTION (if multiple versions exist)**\n\n**If resource exists in ONLY ONE version:**\n- Skip to Step 4 (creation page opens directly)\n\n**If resource exists in MULTIPLE versions:**\n\n**Version Selection Modal appears:**\n\n**Modal Title:**\n```\nSelect Version to Duplicate\n```\n\n**Modal Content:**\n```\nResource backend-cluster has multiple versions. Please select one:\n```\n\n**Version List:**\n- Shows all versions of this resource\n- Each row shows:\n  - **Version tag** (colored, e.g., blue v1.36.2, green v1.37.0)\n  - **Updated date** (when that version was last modified)\n- Click on the version you want to duplicate FROM\n\n**Selection:**\n1) Click on the **source version** (version you want to copy)\n   - Example: Click on **v1.37.0** row\n2) Modal closes\n3) Proceeds to Step 4\n\n---\n\n**STEP 4: CREATION PAGE OPENS WITH PRE-FILLED DATA**\n\nThe **resource creation page** opens, but unlike normal creation:\n\n**URL Format:**\n```\n/cluster/create?version=v1.37.0&duplicate=true\n```\n\n**Special Behaviors:**\n\n**1) Version Selection Modal:**\n- Opens first (if multiple versions available in Elchi)\n- Shows available versions\n- Source version (v1.37.0) is **pre-selected** but can be changed\n- You can choose to duplicate to:\n  - **Same version** (v1.37.0 â†’ v1.37.0): Creates copy in same version\n  - **Different version** (v1.37.0 â†’ v1.38.0): Creates copy in new version\n\n**2) Form is Pre-Filled:**\n- All fields contain values from source resource\n- Name field shows original name (e.g., \"backend-cluster\")\n- All configuration settings copied exactly\n- Tags, filters, settings, everything is duplicated\n\n---\n\n**STEP 5: MODIFY THE RESOURCE NAME**\n\n**IMPORTANT**: You **MUST change the name** before saving!\n\n**Why?**\n- Two resources in same version cannot have the same name\n- If you try to save with same name: Error \"Resource with this name already exists\"\n\n**How to rename:**\n\n1) Find the **\"Name\"** field (usually at top of form)\n2) Current value shows source name: \"backend-cluster\"\n3) Change to new name:\n   - **Option 1: Add suffix**: \"backend-cluster-v2\"\n   - **Option 2: Add environment**: \"backend-cluster-staging\"\n   - **Option 3: Descriptive name**: \"new-backend-cluster\"\n   - **Option 4: Incremental**: \"backend-cluster-2\"\n\n**Name Requirements:**\n- Must be unique within the same version\n- Allowed characters: letters, numbers, hyphens, underscores\n- No spaces\n- Case-sensitive\n\n---\n\n**STEP 6: MODIFY OTHER FIELDS (Optional)**\n\nYou can change any fields you want:\n\n**Common modifications when duplicating:**\n\n**For Clusters:**\n- Endpoints (point to different backend IPs)\n- Health check settings\n- Load balancer policy\n- TLS certificates\n\n**For Listeners:**\n- Port number (cannot have two listeners on same port)\n- Bind address\n- Filter chains\n- Route configuration\n\n**For Routes:**\n- Virtual hosts (domain names)\n- Route rules (path matching)\n- Cluster references\n\n**For Secrets:**\n- Certificate data (different domain cert)\n- Private key\n- Validation context\n\n---\n\n**STEP 7: SAVE THE DUPLICATED RESOURCE**\n\n1) After modifying name (and any other fields)\n2) Scroll to top of page\n3) Click **\"Create\"** button (or \"Update\" if in edit mode)\n4) Validation runs:\n   - Name uniqueness check\n   - Field validation\n   - Dependency checks\n5) If valid:\n   - Resource is created\n   - Success notification appears\n   - You're redirected to resource list page\n6) If invalid:\n   - Error messages appear\n   - Fix errors and try again\n\n---\n\n**DUPLICATION USE CASES:**\n\n**Use Case 1: Duplicate Within Same Version**\n\n**Scenario**: You have \"api-cluster\" in v1.37.0, need \"admin-cluster\" with similar config\n\n**Steps**:\n1. Duplicate \"api-cluster\"\n2. Select v1.37.0 from version modal (same version)\n3. Change name to \"admin-cluster\"\n4. Modify endpoints (point to admin backend IPs)\n5. Save\n\n**Result**: Two similar clusters in v1.37.0\n\n---\n\n**Use Case 2: Duplicate to Different Version**\n\n**Scenario**: You have \"backend-cluster\" in v1.36.2, want to create it in v1.37.0\n\n**Steps**:\n1. Duplicate \"backend-cluster\" from v1.36.2\n2. In version selection modal, select **v1.37.0** (different version)\n3. Keep same name \"backend-cluster\" (allowed since different version)\n4. Review config (may need adjustments for v1.37.0 compatibility)\n5. Save\n\n**Result**: Same resource exists in both versions\n\n**Alternative**: Use **Upgrade** instead of Duplicate for this use case (more appropriate)\n\n---\n\n**Use Case 3: Template-Based Creation**\n\n**Scenario**: You maintain a \"standard-cluster\" template, use it to create all new clusters\n\n**Steps**:\n1. Create \"standard-cluster\" with ideal configuration\n2. When need new cluster:\n   - Duplicate \"standard-cluster\"\n   - Rename to actual cluster name (e.g., \"payments-cluster\")\n   - Modify endpoints\n   - Save\n3. Repeat for each new cluster\n\n**Benefit**: Consistent configuration, faster creation\n\n---\n\n**Use Case 4: Environment Cloning**\n\n**Scenario**: Copy production listener to staging\n\n**Steps**:\n1. Duplicate \"prod-api-listener\" (v1.37.0)\n2. Rename to \"staging-api-listener\"\n3. Change port from 443 to 8443\n4. Update cluster references (point to staging clusters)\n5. Save\n\n**Result**: Staging environment mirrors production config\n\n---\n\n**DUPLICATE VS. UPGRADE:**\n\n**Use DUPLICATE when:**\n- Creating a **similar resource** with different name\n- Copying config as a **template**\n- Creating resource in **same version**\n- Manual process, one resource at a time\n\n**Use UPGRADE when:**\n- Moving resource to **newer Envoy version**\n- Upgrading **multiple resources** (bulk operation)\n- Automatic **dependency handling**\n- Preserving **same resource name** in new version\n\n**Comparison:**\n\n| Feature | Duplicate | Upgrade |\n|---------|-----------|----------|\n| **Name** | Must change (or different version) | Keeps same name |\n| **Dependencies** | Manual handling | Auto-creates dependencies |\n| **Bulk operation** | âŒ One at a time | âœ… Multiple resources |\n| **Version** | Any version | Only higher versions |\n| **Use case** | Template, similar resource | Version migration |\n\n---\n\n**TECHNICAL DETAILS:**\n\n**What happens behind the scenes:**\n\n1. **GET request** to fetch source resource:\n   ```\n   GET /api/v3/cluster/{id}?version=v1.37.0\n   ```\n\n2. **Response** contains full resource configuration\n\n3. **Creation form** is populated with this data\n\n4. **User modifies** name and other fields\n\n5. **POST request** to create new resource:\n   ```\n   POST /api/v3/cluster\n   {\n     \"name\": \"backend-cluster-v2\",\n     \"version\": \"v1.37.0\",\n     ... (all copied config)\n   }\n   ```\n\n6. **Validation** runs on server\n\n7. **New resource created** with new ID\n\n8. **Original resource** remains unchanged\n\n---\n\n**DUPLICATE BUTTON STATES:**\n\n**When Duplicate action is AVAILABLE:**\n- For all non-bootstrap resources\n- Listener, Cluster, Route, Endpoint, Secret, Filter, Extension\n\n**When Duplicate action is DISABLED:**\n- For Bootstrap (only one bootstrap allowed per version)\n- For resources with delete-only permissions\n\n---\n\n**TROUBLESHOOTING:**\n\n**Problem**: \"Duplicate\" option not in actions menu\n- **Cause**: Resource type doesn't support duplication (e.g., Bootstrap)\n- **Solution**: Manually create new resource and copy config\n\n**Problem**: Error \"Resource with this name already exists\"\n- **Cause**: Didn't change name, or chose same name in same version\n- **Solution**: Change name to something unique\n\n**Problem**: Duplicated resource has wrong version\n- **Cause**: Selected wrong version in version selection modal\n- **Solution**: Delete duplicated resource, start over, select correct version\n\n**Problem**: Dependencies are missing in duplicated resource\n- **Cause**: Duplicated to different version where dependencies don't exist\n- **Solution**: Either:\n  1. Create dependencies manually in target version first\n  2. Use Upgrade instead (auto-creates dependencies)\n  3. Update resource to use dependencies that exist in target version\n\n**Problem**: Want to duplicate many resources at once\n- **Cause**: Duplicate is manual, one-at-a-time\n- **Solution**: Use Upgrade for bulk operations, or write script using Elchi API\n\n**Problem**: Duplicated resource failed validation\n- **Cause**: Configuration incompatible with target version (e.g., v1.37.0 protobuf differences)\n- **Solution**: Review error messages, adjust fields to meet new version's requirements"}
{"resource":"Version Management","category":"version_comparison","instruction":"How can I compare resources between different Envoy versions?","output":"COMPARING RESOURCES BETWEEN VERSIONS:\n\nElchi doesn't have a built-in side-by-side version comparison tool, but you can manually compare using several methods.\n\n---\n\n**METHOD 1: DUAL BROWSER TABS (Recommended)**\n\n**STEP 1: OPEN RESOURCE IN FIRST VERSION**\n\n1) Go to resource page (e.g., 'Cluster')\n2) Filter by **first version** (e.g., v1.36.2)\n3) Click \"Search\"\n4) Click on resource name (e.g., \"backend-cluster\")\n5) Resource edit page opens in v1.36.2\n6) **Copy the URL** from address bar\n\n**STEP 2: OPEN NEW TAB FOR SECOND VERSION**\n\n1) Right-click on browser tab â†’ **\"Duplicate Tab\"**\n   - OR: **Cmd+T** (Mac) / **Ctrl+T** (Windows) to open new tab\n2) Navigate to same resource page (e.g., 'Cluster')\n3) Filter by **second version** (e.g., v1.37.0)\n4) Click \"Search\"\n5) Click on **same resource name** (\"backend-cluster\")\n6) Resource edit page opens in v1.37.0\n\n**STEP 3: ARRANGE TABS SIDE-BY-SIDE**\n\n**On Mac:**\n1. Click and hold first tab\n2. Drag it out of the window (becomes new window)\n3. Resize windows to 50% width each\n4. Place side-by-side\n\n**On Windows:**\n1. Same process, OR:\n2. **Windows Key + Left Arrow** (first window)\n3. **Windows Key + Right Arrow** (second window)\n4. Snap to sides\n\n**STEP 4: COMPARE CONFIGURATIONS**\n\nNow you can scroll through both versions simultaneously:\n\n**What to compare:**\n\n**Configuration Fields:**\n- Are all fields present in both versions?\n- Are values identical or different?\n- New fields in v1.37.0?\n- Deprecated fields in v1.36.2?\n\n**Dependencies:**\n- Cluster references same endpoints?\n- Route references same clusters?\n- Listener uses same routes?\n\n**Filters:**\n- HTTP filter chain differences?\n- Network filter changes?\n- Filter order changes?\n\n**TLS Settings:**\n- Certificate references\n- TLS versions\n- Cipher suites\n\n---\n\n**METHOD 2: EXPORT AND COMPARE (for advanced users)**\n\n**STEP 1: EXPORT FIRST VERSION**\n\n1) Open resource in v1.36.2\n2) Open browser **Developer Tools** (F12)\n3) Go to **\"Network\"** tab\n4) Click **\"Edit\"** button on resource (triggers API call)\n5) In Network tab, find the **GET request** for resource\n6) Right-click â†’ **\"Copy Response\"**\n7) Paste into text editor\n8) Save as `backend-cluster-v1.36.2.json`\n\n**STEP 2: EXPORT SECOND VERSION**\n\n1) Repeat same process for v1.37.0\n2) Save as `backend-cluster-v1.37.0.json`\n\n**STEP 3: USE DIFF TOOL**\n\n**Online tools:**\n- https://www.diffchecker.com/\n- https://text-compare.com/\n\n**Command line (Mac/Linux):**\n```bash\ndiff backend-cluster-v1.36.2.json backend-cluster-v1.37.0.json\n```\n\n**VS Code:**\n1. Open both files in VS Code\n2. Right-click first file â†’ **\"Select for Compare\"**\n3. Right-click second file â†’ **\"Compare with Selected\"**\n4. Diff view shows differences highlighted\n\n**STEP 4: ANALYZE DIFFERENCES**\n\nDiff tools show:\n- **Green lines**: Added in v1.37.0\n- **Red lines**: Removed from v1.36.2\n- **Yellow lines**: Modified values\n\n---\n\n**METHOD 3: VERSION FILTER TOGGLE**\n\n**STEP 1: FILTER BY FIRST VERSION**\n\n1) Go to resource page\n2) Filter by v1.36.2\n3) Click \"Search\"\n4) **Take screenshot** or **write down** resource details\n\n**STEP 2: SWITCH TO SECOND VERSION**\n\n1) Change filter to v1.37.0\n2) Click \"Search\"\n3) Compare visually with screenshot/notes\n\n**STEP 3: REPEAT FOR EACH RESOURCE**\n\n- Not ideal for detailed comparison\n- Good for quick checks (e.g., \"Does this resource exist in v1.37.0?\")\n\n---\n\n**METHOD 4: UPGRADE DRY RUN ANALYSIS**\n\n**STEP 1: RUN DRY RUN UPGRADE**\n\n1) Go to 'Listener' page\n2) Select listeners in v1.36.2\n3) Click **\"Upgrade\"** button\n4) Select target version: v1.37.0\n5) **Enable \"Dry run\"** checkbox\n6) Click \"Upgrade\"\n\n**STEP 2: REVIEW ANALYSIS**\n\nThe **RESOURCE_UPGRADE(DRY)** job shows:\n\n**Overall Stats:**\n- **Total Dependencies**: All resources needed\n- **Already Exist**: Resources already in v1.37.0 (same config or different)\n- **Need to Create**: Resources missing in v1.37.0\n\n**Per-Listener Details:**\n\n**Missing Resources** (orange boxes):\n- Lists resources that DON'T exist in v1.37.0\n- Implies these are different between versions\n\n**Existing Resources** (green boxes):\n- Lists resources that DO exist in v1.37.0\n- **NOTE**: \"Existing\" doesn't mean \"identical config\", just \"exists by name\"\n- Config may differ\n\n**STEP 3: MANUALLY CHECK DETAILS**\n\n- For resources in \"Already Exist\" list\n- Open each in both versions (Method 1 or 2)\n- Compare configurations manually\n\n**Limitation**: Dry run doesn't show actual config differences, only existence\n\n---\n\n**WHAT TO LOOK FOR WHEN COMPARING:**\n\n**1. Field Changes (Protobuf Schema)**\n\nEnvoy versions may have:\n- **New fields**: Added in v1.37.0, absent in v1.36.2\n- **Deprecated fields**: Present in v1.36.2, removed in v1.37.0\n- **Renamed fields**: Same concept, different name\n- **Type changes**: Field changed from string to enum, etc.\n\n**Example:**\n```\nv1.36.2: connect_timeout: \"5s\"\nv1.37.0: connect_timeout: { seconds: 5, nanos: 0 }  (protobuf Duration)\n```\n\n**2. Default Values**\n\n- v1.37.0 may have different defaults\n- Field absent in v1.36.2 (uses default)\n- Same field present in v1.37.0 (explicit value)\n\n**3. Dependency References**\n\n- Cluster names changed?\n- Route config names changed?\n- Secret names changed?\n- Check if references still valid\n\n**4. Filter Configurations**\n\n- HTTP filters added/removed?\n- Filter order changed?\n- Typed config differences?\n\n**5. Version-Specific Features**\n\n- New filter types in v1.37.0 (not available in v1.36.2)?\n- Deprecated filters in v1.36.2 (removed in v1.37.0)?\n- Enhanced features (e.g., better rate limiting)?\n\n---\n\n**COMMON DIFFERENCES BETWEEN VERSIONS:**\n\n**Envoy v1.36.2 â†’ v1.37.0 (example):**\n\n1. **Duration Format**:\n   - Old: String \"5s\"\n   - New: Object `{ seconds: 5 }`\n\n2. **New Filters**:\n   - New HTTP filters added\n   - Check if used\n\n3. **Deprecated Config**:\n   - Old cluster discovery type deprecated\n   - New discovery type recommended\n\n4. **Performance Improvements**:\n   - Same config, better performance\n   - No visible differences\n\n5. **Security Enhancements**:\n   - Stricter TLS validation\n   - May need config adjustments\n\n---\n\n**COMPARISON CHECKLIST:**\n\n**Before Upgrading from v1.36.2 to v1.37.0:**\n\n- [ ] List all listeners in v1.36.2\n- [ ] For each listener, check:\n  - [ ] Exists in v1.37.0?\n  - [ ] Config identical?\n  - [ ] Dependencies exist in v1.37.0?\n- [ ] List all clusters in v1.36.2\n- [ ] For each cluster, check:\n  - [ ] Exists in v1.37.0?\n  - [ ] Endpoints identical?\n  - [ ] Health checks identical?\n- [ ] List all routes in v1.36.2\n- [ ] For each route, check:\n  - [ ] Exists in v1.37.0?\n  - [ ] Virtual hosts identical?\n  - [ ] Cluster references valid?\n- [ ] List all secrets in v1.36.2\n- [ ] For each secret, check:\n  - [ ] Exists in v1.37.0?\n  - [ ] Certificates up-to-date?\n  - [ ] Still referenced by listeners?\n- [ ] Run dry run upgrade\n- [ ] Review analysis for missing resources\n- [ ] Create plan for migration\n\n---\n\n**AUTOMATED COMPARISON (API-based)**\n\n**For advanced users with programming skills:**\n\n**Script Outline** (Python example):\n\n```python\nimport requests\nimport json\n\n# Fetch resource from v1.36.2\nresponse_old = requests.get(\n    \"https://elchi.example.com/api/v3/cluster/backend-cluster?version=v1.36.2\",\n    headers={\"Authorization\": \"Bearer TOKEN\"}\n)\nresource_old = response_old.json()\n\n# Fetch resource from v1.37.0\nresponse_new = requests.get(\n    \"https://elchi.example.com/api/v3/cluster/backend-cluster?version=v1.37.0\",\n    headers={\"Authorization\": \"Bearer TOKEN\"}\n)\nresource_new = response_new.json()\n\n# Compare\nfrom deepdiff import DeepDiff\n\ndiff = DeepDiff(resource_old, resource_new, ignore_order=True)\nprint(json.dumps(diff, indent=2))\n```\n\n**Output shows**:\n- Added fields\n- Removed fields\n- Changed values\n- Type changes\n\n---\n\n**TROUBLESHOOTING:**\n\n**Problem**: Resource exists in v1.36.2 but not in v1.37.0\n- **Cause**: Not yet upgraded/created in new version\n- **Solution**: Use Upgrade tool or manually create\n\n**Problem**: Config looks identical but behaves differently\n- **Cause**: Envoy version differences (same config, different behavior)\n- **Solution**: Check Envoy v1.37.0 release notes for behavioral changes\n\n**Problem**: Too many resources to compare manually\n- **Cause**: Large deployment (100+ resources)\n- **Solution**: Use API-based automated comparison script\n\n**Problem**: Can't remember what changed\n- **Cause**: No change tracking\n- **Solution**: Use Audit Log page to view resource modification history"}
{"resource":"Listener","category":"version_management","instruction":"How can I filter listeners by version?","output":"VERSION FILTERING STEPS:\n\n1) Click on 'Listeners' tab from the left menu\n2) When the page opens, you'll see a filter area at the top (card-shaped)\n3) The filter area has 4 sections:\n   - Name search box (left side, wide area)\n   - Version filtering (dropdown menu)\n   - 'Search' button and 'Clear' button on the right\n4) Click on the 'Filter by version' dropdown menu\n5) The dropdown opens, showing available version list (e.g., v1.36.2, v1.37.0)\n6) Select the desired version (e.g., v1.36.2)\n7) Click the blue 'Search' button on the right side\n8) The table now shows only listeners in the selected version\n9) NOTE: Each version appears in a separate row (because consolidateVersions=false)"}
{"resource":"Listener","category":"version_management","instruction":"How do I upgrade a listener to a new Envoy version?","output":"UPGRADE STEPS:\n\n1) Go to the 'Listeners' page from the left menu\n2) Check the checkboxes next to the listeners you want to upgrade\n3) You can select multiple listeners (they must be from the same version)\n4) When listeners are selected, an 'Upgrade ({count}) from {version}' button appears at the top\n   - This button is shown with an upward arrow icon\n5) Click the 'Upgrade' button\n6) The upgrade modal window opens\n7) Inside the modal:\n   - Current version is displayed (e.g., v1.36.2)\n   - Dropdown menu for target version selection\n   - 'Include dependent resources' option (to include routes, clusters, filters, etc.)\n8) Select the target version from dropdown (e.g., v1.37.0)\n9) Check the dependent resources option (recommended)\n10) Click the 'Confirm' button\n11) An upgrade job is started in the background\n12) You can track the upgrade job status from the 'Jobs' page\n13) When upgrade completes, a copy of the listener is created in the new version"}
{"resource":"Listener","category":"version_management","instruction":"When I duplicate a listener, how is the version selected?","output":"DUPLICATE AND VERSION SELECTION:\n\n1) On the Listeners page, click the 'Actions' menu on the listener row\n2) Select the 'Duplicate' option\n3) You are redirected to the Create page\n4) FIRST, a version selection screen appears\n5) Cards showing available versions are listed\n6) Click on a version card:\n   - Version is selected and the form loads\n   - Data from the duplicated listener is automatically filled\n7) After duplicate data is loaded:\n   - Original name is kept (if upgrade) or cleared (if duplicate)\n   - All settings come pre-filled\n   - Form opens and is ready for editing\n8) Change the Name field (unique name required for duplicate)\n9) Edit other settings if desired\n10) Click the 'Create' button â†’ new listener is created"}
{"resource":"Listener","category":"managed_unmanaged","instruction":"What is a managed listener and how is it different from an unmanaged listener?","output":"MANAGED LISTENER:\n1) In the general settings card, you see a 'Managed' switch\n2) When Managed = Yes (Active):\n   - Listener IP address is not entered in the UI\n   - 'Managed by Service' green-blue tag appears in the address column\n   - IP is automatically assigned by the service (during service deployment)\n   - Bootstrap and service file are automatically created\n   - Start/stop/reload/restart operations are done through the service\n   - Can be deployed to clients (IP address automatic)\n3) Non-editable fields: address and name\n4) Address field becomes disabled\n\nUNMANAGED LISTENER:\n1) Managed = No (Inactive)\n2) Address fields are editable\n3) Socket Address â†’ IP is manually entered in the address input\n4) Only bootstrap file is generated\n5) No service is created\n6) User downloads bootstrap and manually starts Envoy\n7) No deploy operation\n\nUSAGE SCENARIOS:\n- Managed: Production, multi-client deployment, service mesh\n- Unmanaged: Development, testing, standalone proxy"}
{"resource":"Listener","category":"managed_unmanaged","instruction":"How do I create a managed listener?","output":"CREATING A MANAGED LISTENER:\n\n1) From left menu, click 'Listeners' â†’ 'Add New' button\n2) On version selection screen, select version (e.g., v1.36.2)\n3) General settings card opens\n4) Enter listener name in the Name input box (e.g., 'ingress-http')\n5) Version is auto-filled (non-editable)\n6) You'll see the 'Managed' switch\n7) Turn the Managed switch ON (Yes state)\n   - Switch background turns blue\n   - Border turns blue\n   - Text color becomes dark blue\n8) From the left menu, select the 'address' tag (usually auto-selected)\n9) On the right, the 'Address' card opens\n10) Activate the 'Socket Address' tag\n11) IMPORTANT: The 'address' input field appears DISABLED (because it's managed)\n12) You can only enter 'port_value' or 'named_port'\n13) Enter port value (e.g., 8080)\n14) Add filter chains, listener filters, etc. (normal flow)\n15) Click the 'Create' button\n16) Listener is saved in the background with managed=true\n17) Service is automatically created (with listener name)"}
{"resource":"Listener","category":"managed_unmanaged","instruction":"How do I enter an IP address for an unmanaged listener?","output":"UNMANAGED LISTENER IP ADDRESS INPUT:\n\n1) Create listener, leave the Managed switch OFF (No)\n2) From the left menu, select the 'address' tag\n3) 'Address' card â†’ activate the 'Socket Address' tag\n4) Horizontal tags appear inside the 'Socket Address' card\n5) Click on the 'address' tag (EDITABLE because it's UNMANAGED)\n6) String input field opens\n7) Enter IP address:\n   - Example: 0.0.0.0 (listen on all network interfaces)\n   - Example: 127.0.0.1 (localhost)\n   - Example: 192.168.1.10 (specific IP)\n8) Also activate the 'port_value' tag\n9) Enter port number (e.g., 8080, 443)\n10) Click the 'Create' button\n11) Bootstrap file is created with address and port\n12) No service is created (unmanaged)"}
{"resource":"Listener","category":"service_deployment","instruction":"How do I deploy a managed listener as a service?","output":"SERVICE DEPLOYMENT STEPS:\n\n1) Create and save managed listener (Create button)\n2) Background automatically creates service record (with listener name)\n3) Go to 'Services' section from left menu (Operations â†’ Services)\n4) New service appears in Services table:\n   - Name: listener name\n   - Status: 'Not Deployed' (gray tag, no clients yet)\n   - Version: listener version\n   - Deployed: 0 (client count)\n   - IP Addresses: -\n5) Click on service row â†’ service detail page opens\n6) In service detail:\n   - Service info card\n   - Deployment section\n   - Operations (Start/Stop/Reload/Restart buttons)\n7) Click 'Deploy to Client' button\n8) Client selection modal opens\n9) Select target client from elchi-client list\n10) Select IP assignment method:\n    - Auto: Client's IP is automatically determined\n    - Manual: Enter specific IP\n11) Click the 'Deploy' button\n12) In the background:\n    - Envoy binary is downloaded to client\n    - Bootstrap + config is created\n    - Service network settings (IP routing) are applied\n    - Envoy is started\n13) Status becomes 'Live' (green tag)"}
{"resource":"Listener","category":"service_deployment","instruction":"How do I start/stop/reload/restart a service?","output":"SERVICE OPERATIONS:\n\n1) Go to 'Services' page from left menu\n2) Click on the relevant service row (detail page opens)\n3) In the service detail page, there's an 'Operations' section\n4) Operation buttons:\n   - Start (Play icon, green color)\n   - Stop (Pause icon, red color)\n   - Reload (Refresh icon, blue color)\n   - Restart (Restart icon, orange color)\n\n5) START OPERATION:\n   - Starts stopped service\n   - Start command is sent to client\n   - Envoy process begins\n\n6) STOP OPERATION:\n   - Graceful shutdown (drain listener)\n   - Envoy process is stopped\n   - Status: Offline\n\n7) RELOAD OPERATION:\n   - Applies config changes (hot reload)\n   - Zero-downtime update\n   - New snapshot is taken, Envoy is refreshed\n\n8) RESTART OPERATION:\n   - Stop + Start (graceful restart)\n   - Drain â†’ stop â†’ start sequence\n\n9) A job is created for each operation\n10) You can track status from 'Jobs' page"}
{"resource":"Listener","category":"service_deployment","instruction":"How do I deploy a service to multiple clients?","output":"MULTI-CLIENT DEPLOYMENT:\n\n1) On service detail page, click 'Deploy to Client' button\n2) Select first client (e.g., client-1)\n3) IP Address: 10.0.1.5\n4) Click Deploy â†’ First deployment completes\n\n5) Click 'Deploy to Client' button again\n6) Select second client (e.g., client-2)\n7) IP Address: 10.0.1.6 (different IP)\n8) Deploy â†’ Second deployment completes\n\n9) In Services table:\n   - Deployed: 2 (blue gradient badge)\n   - IP Addresses: 10.0.1.5, +1 more (clickable link)\n\n10) Clicking '+1 more' link opens IP modal:\n    - Modal title: 'All IP Addresses'\n    - List: 10.0.1.5, 10.0.1.6\n\n11) Status tags:\n    - Live: All clients connected (green)\n    - Partial: Some clients connected (orange)\n    - Offline: No clients connected (red)\n\n12) A separate Envoy instance runs for each client\n13) Same config, different IPs (load balancing or multi-region)"}
{"resource":"Listener","category":"jobs_snapshot","instruction":"How do I track snapshot updates from Jobs after making a listener change?","output":"SNAPSHOT UPDATE TRACKING:\n\n1) Make a change to a listener (e.g., add filter, change timeout)\n2) Click the 'Update' button\n3) In the background:\n   - Change is saved\n   - All resources using the listener are analyzed\n   - A snapshot update job is created for each listener\n\n4) Go to 'Jobs' page from left menu\n5) New jobs appear in Jobs table:\n   - Job Type: 'Snapshot Update'\n   - Resource: 'Listener: {name}'\n   - Status: 'Running' (blue progress bar)\n   - Created: timestamp\n\n6) Click on job row â†’ Job detail page opens\n7) In job detail:\n   - Job information (ID, type, resource, version)\n   - Progress bar (percentage)\n   - Log output (real-time)\n   - Error messages (if any)\n\n8) What you'll see in logs:\n   - 'Analyzing resource dependencies...'\n   - 'Updating snapshot for listener: {name}'\n   - 'Route X is using this listener, updating...'\n   - 'Cluster Y is referenced, updating...'\n   - 'Snapshot update completed successfully'\n\n9) Status: 'Completed' (green check icon)\n10) Services are automatically refreshed (config update)"}
{"resource":"Listener","category":"jobs_snapshot","instruction":"If the same resource is used by multiple listeners, how are snapshots updated?","output":"SCENARIO: MULTI-LISTENER SNAPSHOT UPDATE\n\nEXAMPLE SITUATION:\n- There's a cluster named 'backend-api'\n- Listener-1 and Listener-2 use this cluster (via route config)\n\nWHEN CLUSTER IS CHANGED:\n1) Make a change on cluster detail page (e.g., add health check)\n2) Click the 'Update' button\n3) Background starts deep analysis:\n   - Which routes use the 'backend-api' cluster?\n   - Which listeners use these routes?\n   - Listener-1 and Listener-2 are identified\n\n4) A SEPARATE snapshot update job is created for each listener\n5) On Jobs page:\n   - Job 1: 'Snapshot Update - Listener-1' (Running)\n   - Job 2: 'Snapshot Update - Listener-2' (Running)\n\n6) Each job updates its own snapshot:\n   - Listener-1 snapshot: cluster config is refreshed\n   - Listener-2 snapshot: cluster config is refreshed\n\n7) Services are refreshed:\n   - Listener-1 service â†’ reload job\n   - Listener-2 service â†’ reload job\n\n8) All clients receive new config (zero-downtime)\n9) Job statuses become 'Completed'\n10) NOTE: Background job system manages concurrent updates"}
{"resource":"Listener","category":"ui_components","instruction":"What are the table columns on the Listeners page and what do they show?","output":"LISTENER TABLE COLUMNS:\n\n1) NAME COLUMN (wide area, 30%):\n   - Listener name is displayed\n   - If unique ID exists, separated by '-' (e.g., listener-a3b5c9)\n   - Shown in bold font\n\n2) PROTOCOL COLUMN (20%):\n   - Listener protocol is displayed\n   - Default: TCP\n   - Supported: TCP, UDP\n   - Automatically determined from address configuration\n\n3) ADDRESS COLUMN (20%):\n   - If MANAGED: Tag is displayed\n     * Text: 'Managed by Service'\n     * Green-blue color (#00c6fb)\n   - If UNMANAGED: IP address is displayed\n     * Taken from socket address field\n\n4) PORT COLUMN (20%):\n   - Port number is displayed\n   - Taken from socket address port value\n\n5) DELETE COLUMN (10%):\n   - Pink-colored dual-tone delete icon (#eb2f96)\n   - Small-sized button\n   - Icon positioned on the right\n   - Clicking initiates delete operation\n   - Click event is stopped to prevent row expansion\n\nTABLE FEATURES:\n- Small-sized table\n- Vertical scroll: 950px\n- No pagination (entire list visible)\n- Rows are clickable (cursor pointer)\n- Rows can be expanded by clicking\n- If no listeners: Inbox icon + 'No Listeners' message"}
{"resource":"Listener","category":"ui_components","instruction":"How does the left menu work when a listener is expanded?","output":"LISTENER DETAIL LEFT MENU:\n\n1) LEFT MENU STRUCTURE:\n   - Clickable tag list appears\n   - Each tag represents a section of the listener\n   - Active tags are shown with blue gradient background\n   - Inactive tags have white background, bordered\n   - Required tags are marked with blue dotted badge\n   - Non-editable tags: cursor becomes 'not-allowed', modification disabled\n\n2) TAG TYPES:\n   - address (required, non-editable if managed)\n   - name (required, non-editable)\n   - filter_chains\n   - listener_filters\n   - transport_socket\n   - stat_prefix\n   - other listener options\n\n3) TAG CLICKING:\n   - Click tag â†’ relevant card opens on the right\n   - Added/removed from selected tags list\n   - Related component is rendered (e.g., Filter Chains, Listener Filters cards)\n\n4) SCROLL FEATURE:\n   - Click tag â†’ automatically scrolls to relevant card\n   - Vertical alignment center icon (anchor icon)\n   - Smooth scroll animation, positioned in screen center\n   - Card highlight effect: shadow + scale enlargement (1.02)\n\n5) INFO BAR:\n   - Blue info circle icon with 'Config Info' button\n   - Clicking opens modal â†’ shows field documentation\n\n6) USAGE:\n   - Select desired section from left menu\n   - Form opens on the right\n   - Fill in fields\n   - Select another tag for another section\n   - After all sections are filled, click 'Create' or 'Update'"}
{"resource":"Listener","category":"ui_components","instruction":"What happens when I click the '+' button in the Filter Chains tab?","output":"ADDING A FILTER CHAIN:\n\n1) UI VIEW:\n   - Editable card-type tab component\n   - '+' icon appears in top right\n   - Tab labels: '{listenerName}-fc-{randomId}' (e.g., listener-a3b5c9-fc-d8e2f1)\n\n2) CLICKING '+' BUTTON:\n   a) Add new filter chain function executes\n   b) Random 6-digit alphanumeric ID is generated (a-z, 0-9)\n   c) New filter chain name is created: '{previousListenerName}-fc{randomId}'\n   d) New filter chain is added to Redux state\n   e) Last tab becomes active\n   f) Tab component renders new tab\n\n3) NEW TAB CONTENT:\n   - Horizontal tag bar: FilterChain tags\n   - Form and fields: name, transport_socket_connect_timeout\n   - Conditional sections:\n     * If 'filters' tag active: Network filters card\n     * If 'transport_socket' tag active: Transport socket card\n\n4) NAME FIELD:\n   - Disabled (disabled=true)\n   - Non-editable because automatically generated\n   - Placeholder: '(name)'\n\n5) USAGE:\n   - Add new filter chain with '+'\n   - Click tab to edit filter chain\n   - Configure filters, transport_socket, etc. in each filter chain\n   - Multiple filter chains possible (for different match criteria)"}
{"resource":"Listener","category":"field_details","instruction":"What's the difference between port_value and named_port in Socket Address?","output":"PORT SPECIFIER (SINGLE SELECTION FIELD):\n\n1) DEFINITION:\n   - port_specifier is single selection field (only one can be selected)\n   - Options: port_value or named_port\n   - Both cannot be active simultaneously\n\n2) UI DISPLAY:\n   - Two tags appear in horizontal tag bar:\n     * port_value tag\n     * named_port tag\n   - When one is active, the other is disabled with tooltip\n   - Tooltip title: 'You can select only one tag at a time from this group.'\n   - Tooltip content: List (port_value, named_port)\n   - Disabled tag: gray background\n\n3) PORT_VALUE:\n   - TYPE: Number (UInt32)\n   - Numeric port number\n   - Examples: 8080, 443, 9090, 3000\n   - Auto-generated field:\n     * Field path: 'port_specifier.port_value'\n     * Type: Number\n     * Placeholder: '(port value)'\n   - Input: Number input field\n\n4) NAMED_PORT:\n   - TYPE: String (Text)\n   - Port name (for Kubernetes service port name reference)\n   - Examples: 'http', 'https', 'grpc', 'mysql', 'http-web'\n   - Auto-generated field:\n     * Field path: 'port_specifier.named_port'\n     * Type: String\n     * Placeholder: '(named port)'\n   - Input: Text input field\n\n5) SINGLE SELECTION CONSTRAINT:\n   - When one is active, you cannot select the other\n   - Tooltip shows warning\n   - Tag style indicates which group it belongs to\n\n6) KUBERNETES USAGE:\n   - In Service YAML, port name: 'http-web'\n   - In Listener, named_port: 'http-web'\n   - Kubernetes service port is automatically injected"}
{"resource":"Listener","category":"field_details","instruction":"Why is the listener name sometimes disabled?","output":"NAME FIELD DISABLING LOGIC:\n\n1) DISABLING CONDITIONS:\n   a) NOT IN CREATE MODE:\n      * Not on new creation page\n      * In edit/update mode\n   AND\n   b) NAME IS FROZEN:\n      * Name exists in frozen names list\n      * Existing listeners are frozen on initial load\n\n2) FROZEN NAMES LOGIC:\n   - Listener count at initial load is recorded\n   - Existing listener names are listed\n   - Names of listeners from initial load are frozen (index < initial count)\n   - Frozen names list is updated\n\n3) EXAMPLES:\n   \n   SCENARIO 1 - Initial load:\n   - 3 listeners exist (index 0, 1, 2)\n   - Initial count = 3\n   - Frozen names = [name0, name1, name2]\n   - These 3 listeners have disabled name in edit mode\n\n   SCENARIO 2 - New addition:\n   - 4th listener added with '+' (index 3)\n   - index 3 >= initial count (3)\n   - Not added to frozen names\n   - Name remains editable\n\n   SCENARIO 3 - Create mode:\n   - On new creation page: '/listeners/create'\n   - Condition becomes false\n   - Name is always editable\n\n4) AFTER DELETION:\n   - In delete operation:\n     * If index is less than initial count\n     * Initial count is decreased by 1\n   - Initial count is updated, freezing logic is updated\n\n5) WHY THIS RULE:\n   - Changing existing listener names is dangerous\n   - Services and other resources depend on this name\n   - If name changes, connections break\n   - You can only name NEW listeners"}
{"resource":"Listener","category":"field_details","instruction":"What is stat_prefix used for and how do I set it?","output":"STAT_PREFIX FIELD:\n\n1) ENVOY USAGE:\n   - Used as prefix in Envoy metrics\n   - Metric format: listener.{stat_prefix}.{metric_name}\n   - Example metrics:\n     * listener.ingress_http.downstream_cx_total\n     * listener.ingress_http.downstream_cx_active\n     * listener.ingress_http.downstream_rq_total\n\n2) UI LOCATION:\n   - 'Stat Prefix' tag in left menu\n   - Listed in single option fields\n\n3) UI FLOW:\n   a) Click 'Stat Prefix' tag from left menu\n   b) Tag turns blue (selected)\n   c) 'Single Options' card opens on the right\n   d) Input field labeled 'Stat Prefix' appears inside card\n\n4) FIELD STRUCTURE:\n   - Field path: 'stat_prefix'\n   - Type: String (Text)\n   - Placeholder: '(stat prefix)'\n   - Usually 6 columns wide (responsive layout)\n\n5) EXAMPLE VALUES:\n   - 'ingress_http': HTTP ingress traffic\n   - 'egress_443': HTTPS egress traffic\n   - 'internal_grpc': Internal gRPC communication\n   - 'admin_api': Admin API listener\n\n6) METRIC QUERIES:\n   - Prometheus: listener.ingress_http.*\n   - Filtering: Metrics can be grouped by stat_prefix\n   - Dashboard: Panels based on prefix\n\n7) BEST PRACTICES:\n   - Meaningful naming: ingress/egress + protocol\n   - Unique prefix: Each listener should be different\n   - Short names: Optimize metric storage"}
{"resource":"Listener","category":"advanced","instruction":"How does the Template modal work for listeners?","output":"TEMPLATE MODAL:\n\n1) TEMPLATE BUTTON:\n   - In general settings card\n   - File icon\n   - 'Template' button text\n   - Clicking opens template modal\n\n2) MODAL OPENS:\n   - Template modal window is rendered\n   - Parameters:\n     * Visible: show template state\n     * Close function\n     * Resource type (e.g., 'envoy.config.listener.v3.Listener')\n     * Version\n     * Current listener data\n     * JSON conversion function\n     * Create mode: boolean (create vs edit)\n\n3) MODAL CONTENT:\n   - Template list (fetched from backend)\n   - Filtering: by resource type and version\n   - Each template:\n     * Name\n     * Description\n     * Tags\n     * Creation date\n   - 'Apply Template' button\n   - 'Save as Template' button (save current config as template)\n\n4) APPLYING TEMPLATE:\n   a) Select template\n   b) Click 'Apply' button\n   c) Template data is fetched from backend\n   d) Set to Redux state\n   e) UI form is filled with template data\n   f) Modal closes\n\n5) SAVING AS TEMPLATE:\n   a) Current config is filled\n   b) Click 'Save as Template'\n   c) Template metadata modal opens:\n      * Name input\n      * Description text area\n      * Tags (multi-select)\n   d) Click 'Save' button\n   e) Sent to backend:\n      * Resource type, version, config (via JSON)\n      * Metadata (name, description, tags)\n   f) Template is saved to database\n   g) Other users can see this template\n\n6) USAGE SCENARIO:\n   - Share standard listener settings company-wide\n   - Best practice templates\n   - Quick deployment (production-ready config with one click)"}
{"resource":"Listener","category":"filters","instruction":"What is the difference between network filter and listener filter?","output":"FILTER LEVELS:\n\n1) LISTENER FILTER (Connection level):\n   - Location: Listener â†’ listener_filters field\n   - Runtime: During TCP connection establishment\n   - Executes when first packets arrive\n   - Protocol detection, TLS inspection\n   - Categories:\n     * envoy.filters.listener\n     * envoy.filters.udp_listener\n   - Examples:\n     * TLS Inspector: SNI extraction\n     * HTTP Inspector: HTTP/1.1 vs HTTP/2 detection\n     * Original Dst: Original destination for transparent proxy\n     * Proxy Protocol: HAProxy proxy protocol parsing\n\n2) NETWORK FILTER (Stream level):\n   - Location: Listener â†’ filter_chains[].filters\n   - Runtime: After connection established, in data stream\n   - L4 (TCP/UDP) or L7 (HTTP) processing\n   - Category: envoy.filters.network\n   - Examples:\n     * HttpConnectionManager: HTTP routing, filters\n     * TcpProxy: TCP proxying\n     * RateLimit: Rate limiting\n     * Rbac: Network-level RBAC\n\n3) HTTP FILTER (Request/Response level):\n   - Location: HttpConnectionManager â†’ http_filters\n   - Runtime: HTTP request/response processing\n   - L7 HTTP-specific\n   - Category: envoy.filters.http\n   - Examples:\n     * Router: HTTP routing\n     * Cors: CORS policy\n     * Rbac: HTTP-level RBAC\n     * Wasm: WebAssembly filter (WAF)\n\n4) EXECUTION ORDER:\n   Packet arrives â†’\n   Listener Filters (TLS inspection, protocol detection) â†’\n   Connection established â†’\n   Network Filters (HCM, TCP Proxy) â†’\n   HTTP Filters (Router, CORS, RBAC) â†’\n   Upstream cluster\n\n5) HOW TO ACCESS IN UI:\n   - Listener Filters: Expand listener â†’ click 'Listener Filters' tab from left menu\n   - Network Filters: Expand listener â†’ 'Filter Chains' tab â†’ click 'filters' tag\n   - HTTP Filters: Inside HttpConnectionManager card in 'http_filters' section"}
{"resource":"Listener","category":"filters","instruction":"How to add TLS Inspector listener filter and what does it do?","output":"TLS INSPECTOR FILTER:\n\n1) PURPOSE:\n   - Extracts SNI (Server Name Indication) during TLS handshake\n   - Detects ALPN (Application-Layer Protocol Negotiation)\n   - Used for filter chain matching (SNI-based routing)\n\n2) ADDING STEPS:\n   a) Expand the listener (click row)\n   b) Select 'Listener Filters' tab from left menu\n   c) 'Listener Filters' card opens on the right\n   d) Click blue '+' button at top-left of the card\n   e) Filter selection window opens:\n      * Title: 'Listener Filters'\n      * Category: envoy.filters.listener + envoy.filters.udp_listener\n   f) Type 'tls' in search box (search starts after 300ms delay)\n   g) List filters, 'TLS Inspector' appears\n   h) Select 'TLS Inspector' filter\n   i) Filter addition process runs\n   j) Configuration created and saved\n   k) Added to Redux state\n\n3) TABLE VIEW:\n   - Name: 'TLS Inspector'\n   - Type: 'TlsInspector'\n   - Delete button\n   - Drag-and-drop handle (for priority ordering)\n\n4) CONFIGURATION:\n   - TLS Inspector configuration usually empty (default settings)\n   - Just activating it is enough\n\n5) USE CASE SCENARIO:\n   - Multi-domain routing (SNI-based):\n     * api.example.com â†’ filter chain 1\n     * web.example.com â†’ filter chain 2\n   - ALPN negotiation:\n     * h2 (HTTP/2) â†’ filter chain A\n     * http/1.1 â†’ filter chain B\n   - TLS version detection\n\n6) FILTER CHAIN MATCHING:\n   - filter_chain_match.server_names: ['api.example.com']\n   - TLS Inspector extracts this SNI\n   - Envoy selects correct filter chain"}
{"resource":"Listener","category":"filters","instruction":"How to add HTTP Connection Manager (HCM) network filter?","output":"HTTP CONNECTION MANAGER FILTER:\n\n1) LOCATION:\n   - Listener â†’ Filter Chains â†’ Filters (network filters)\n\n2) ADDING STEPS:\n   a) Expand listener (click row)\n   b) Select 'Filter Chains' tab\n   c) Select filter chain tab (or add new '+')\n   d) Activate 'filters' tag within the tab\n   e) 'Filters' card â†’ click blue '+' button at top-left\n   f) Filter selection window opens (title: 'Network Filters')\n   g) Search: type 'http'\n   h) Select 'HttpConnectionManager' filter\n   i) Filter addition process runs\n   j) Configuration created and saved\n\n3) TABLE VIEW:\n   - Name: 'HttpConnectionManager'\n   - Type: 'HttpConnectionManager'\n   - Change priority with drag-and-drop\n\n4) HCM CONFIGURATION (detail editing):\n   NOTE: Currently no expansion in table, configuration detail editing may be a separate feature\n   Basic fields:\n   a) stat_prefix (required): 'ingress_http'\n   b) route_config or rds (required):\n      * route_config: Inline route configuration\n      * rds: Route Discovery Service\n   c) http_filters (required):\n      * Router filter (last, required)\n      * Other HTTP filters (CORS, RBAC, Wasm, etc.)\n   d) Other fields:\n      * max_request_headers_kb: 60 (header size limit)\n      * request_timeout: '0s' (no timeout)\n      * idle_timeout: '1h'\n      * stream_idle_timeout: '5m'\n      * access_log: Array of access log configurations\n\n5) ADDING HTTP FILTERS (inside HCM):\n   - When HCM configuration is expanded\n   - 'http_filters' section\n   - Add HTTP filter with '+':\n     * Cors\n     * Rbac\n     * Wasm (for WAF)\n     * Router (always last, required)\n\n6) ROUTE CONFIGURATION:\n   - Inline route configuration:\n     * virtual_hosts array\n     * domains, routes\n   - RDS (dynamic routing):\n     * route_config_name: 'my_routes'\n     * config_source: ads or api"}
{"resource":"Listener","category":"filters","instruction":"Why is filter priority important and how to change it?","output":"FILTER PRIORITY:\n\n1) IMPORTANCE:\n   - Filters run sequentially (pipeline)\n   - Changing order changes behavior\n   - Example:\n     * Rate Limit â†’ RBAC â†’ Router (correct)\n     * RBAC â†’ Rate Limit â†’ Router (RBAC first, unnecessary rate limit check)\n   - Critical for performance and security\n\n2) CHANGING LISTENER FILTERS PRIORITY:\n   a) Drag table row (drag-and-drop feature)\n   b) When dragging ends:\n      * Old index and new index calculated\n      * Array order changed (with array splice)\n   c) Each filter's configuration decoded\n   d) Priority value set as index\n   e) Configuration re-encoded\n   f) Redux state updated\n   g) Table re-rendered, new order visible\n\n3) CHANGING NETWORK FILTERS PRIORITY:\n   - Same drag-and-drop logic\n   - Only vertical dragging (up-down)\n\n4) VISUAL FEEDBACK:\n   - Row shadow during dragging\n   - Drop zone highlighted\n   - Smooth animation\n\n5) EXAMPLE ORDERINGS:\n   \n   LISTENER FILTERS:\n   1) TLS Inspector (SNI extraction)\n   2) HTTP Inspector (protocol detection)\n   3) Original Dst (transparent proxy)\n\n   NETWORK FILTERS:\n   1) Rate Limit (early rejection)\n   2) External Auth (authentication)\n   3) RBAC (authorization)\n   4) HttpConnectionManager (routing)\n\n   HTTP FILTERS (inside HCM):\n   1) CORS (preflight handling)\n   2) JWT Auth (authentication)\n   3) RBAC (authorization)\n   4) Wasm/WAF (security)\n   5) Router (MUST be last)\n\n6) USAGE:\n   - Hold and drag filter row\n   - Drop at desired position\n   - Order automatically saved"}
{"resource":"Listener","category":"filters","instruction":"How does search work in filter drawer and what categories are shown?","output":"FILTER SELECTION WINDOW SEARCH:\n\n1) WINDOW FEATURES:\n   - Open/closed state\n   - Close function\n   - Filter list (from API)\n   - Currently added filters (for duplicate check)\n   - Filter addition callback function\n   - Title ('Network Filters', 'Listener Filters')\n   - Search function (debounced)\n\n2) SEARCH LOGIC:\n   a) Enter keyword in input field (e.g., 'rbac', 'http', 'tls')\n   b) Change event triggered\n   c) Search starts after 300ms delay\n      * Optimized with lodash debounce\n      * Prevents unnecessary API calls\n   d) Search query saved to state\n   e) API call triggered:\n      * Query key: 'custom_network_filters_{searchKeyword}'\n      * Path: 'custom/resource_list_search?collection=filters&category={category}&version={version}&project={project}&search={searchKeyword}'\n      * Active: true\n   f) Backend searches (filter name, description, gtype)\n   g) Filter list updated\n   h) List filtered and displayed\n\n3) CATEGORIES:\n   \n   LISTENER FILTERS:\n   - Category 1: envoy.filters.listener\n   - Category 2: envoy.filters.udp_listener\n   - Two categories merged\n   - Allowed categories: ['envoy.filters.listener', 'envoy.filters.udp_listener']\n   - Table data source filtered:\n     * Filter category checked\n     * Is it in allowed categories?\n\n   NETWORK FILTERS:\n   - Category: envoy.filters.network\n   - Only network filters\n\n4) LIST VIEW:\n   - Each filter item:\n     * Icon (based on filter type)\n     * Name\n     * Description\n     * Gtype (type URL)\n     * Tags (category, version)\n   - Disabled filters:\n     * Duplicate check with existing filters\n     * Already added filters may be shown as disabled\n\n5) SELECTING FILTER:\n   - Click filter item\n   - Filter addition callback runs\n   - Filter addition helper function:\n     * Create configuration (type_url, value)\n     * Base64 encode\n     * Add to Redux\n   - Window closes\n\n6) USAGE TIPS:\n   - Search box: Quick find by filter name\n   - 300ms delay: Doesn't search continuously while typing\n   - Category filtering: Only appropriate filters shown"}
{"resource":"Listener","category":"filters","instruction":"Why is typed config value base64 encoded?","output":"TYPED CONFIG ENCODING:\n\n1) WHY BASE64:\n   - Envoy uses protobuf Any type (generic message container)\n   - Any.value field is binary data (bytes)\n   - Binary-safe format needed for JSON serialization\n   - Base64 binary â†’ string conversion\n   - Redux must be serializable (JSON.stringify compatible)\n\n2) ENCODING PROCESS (during filter addition):\n   ```\n   Filter configuration:\n   {\n     name: 'my-rbac-filter',\n     gtype: 'envoy.extensions.filters.network.rbac.v3.RBAC',\n     category: 'envoy.filters.network',\n     priority: 0,\n     // ... filter-specific fields\n   }\n   \n   Convert to JSON string:\n   const jsonString = JSON.stringify(filterConfig);\n   \n   Base64 encode:\n   const base64Value = btoa(jsonString);\n   \n   Create typed config:\n   const typed_config = {\n     type_url: 'type.googleapis.com/envoy.extensions.filters.network.rbac.v3.RBAC',\n     value: base64Value\n   };\n   ```\n\n3) DECODING PROCESS (for UI display):\n   ```\n   Get base64 value:\n   const base64Value = typed_config.value;\n   \n   Base64 decode:\n   const jsonString = atob(base64Value);\n   \n   JSON parse:\n   const filterConfig = JSON.parse(jsonString);\n   \n   filterConfig is now JavaScript object\n   Use in UI: filterConfig.name, filterConfig.gtype\n   ```\n\n4) PRIORITY UPDATE (during drag-and-drop):\n   ```\n   When dragging ends:\n   newFiltersArray.map((item, index) => {\n     if (item.typed_config?.value) {\n       try {\n         // Decode\n         const decodedValue = JSON.parse(atob(item.typed_config.value));\n         \n         // Update priority\n         decodedValue.priority = index;\n         \n         // Re-encode\n         item.typed_config.value = btoa(JSON.stringify(decodedValue));\n       } catch (error) {\n         console.error('Base64 decode/encode error:', error);\n       }\n     }\n     \n     return item;\n   });\n   ```\n\n5) API COMMUNICATION:\n   - When sending to backend:\n     * Base64 decoded\n     * Protobuf Any message serialized\n     * Envoy configuration created\n   - When receiving from backend:\n     * Protobuf Any deserialized\n     * JSON serialized\n     * Base64 encoded\n     * Sent to UI\n\n6) ADVANTAGES:\n   - JSON-safe (no special character, binary data issues)\n   - Redux serializable (Redux Toolkit requirement)\n   - Network transfer safe\n   - API/Storage compatible\n\n7) USER IMPACT:\n   - User doesn't see base64\n   - Automatic encode/decode in background\n   - Normal values shown in UI forms\n   - Transparent operation"}
{"resource":"Cluster","category":"cluster_types","instruction":"What is cluster type and what types of clusters are there?","output":"CLUSTER TYPES:\n\n1) WHAT IS CLUSTER TYPE:\n   - Determines how Envoy discovers upstream endpoints\n   - Defined with discovery type field\n   - Each type uses different endpoint discovery mechanism\n\n2) CLUSTER TYPES:\n\n   a) STATIC:\n      - Endpoints configured statically\n      - Manual IP:port list in load assignment\n      - No dynamic discovery\n      - Use case: Fixed IP services, test environments\n\n   b) STRICT_DNS:\n      - Performs DNS resolution (A/AAAA record)\n      - DNS returns separate IP for each endpoint\n      - Periodic refresh with DNS TTL\n      - Use case: DNS-based services\n\n   c) LOGICAL_DNS:\n      - Performs DNS resolution but single logical endpoint\n      - DNS resolved again for each connection\n      - Works with round-robin DNS\n      - Use case: CDN, cloud services\n\n   d) EDS (Endpoint Discovery Service):\n      - Dynamic endpoint discovery via xDS protocol\n      - Endpoints received from management server\n      - Real-time updates\n      - Use case: Kubernetes, service mesh, dynamic environments\n\n   e) ORIGINAL_DST:\n      - For transparent proxy\n      - Uses original destination IP\n      - Together with Listener Original Dst filter\n      - Use case: Transparent proxy scenarios\n\n3) CLUSTER TYPE SELECTION IN UI:\n   a) Go to cluster create/edit page\n   b) Select 'type' tag from left menu\n   c) 'Single Options' card opens\n   d) 'Type' dropdown menu appears\n   e) Options: STATIC, STRICT_DNS, LOGICAL_DNS, EDS, ORIGINAL_DST\n   f) Select desired type\n   g) Related fields activated based on type:\n      * STATIC/STRICT_DNS/LOGICAL_DNS â†’ load_assignment tag\n      * EDS â†’ eds_cluster_config tag\n\n4) REQUIRED CONFIGURATION BY TYPE:\n   - STATIC: load_assignment.endpoints (IP:port list)\n   - STRICT_DNS: load_assignment.endpoints (DNS hostname)\n   - LOGICAL_DNS: load_assignment.endpoints (DNS hostname)\n   - EDS: eds_cluster_config.service_name (endpoint resource name)\n   - ORIGINAL_DST: Original Dst filter in Listener"}
{"resource":"Cluster","category":"cluster_types","instruction":"How to create a STATIC cluster?","output":"CREATING STATIC CLUSTER:\n\n1) Click 'Clusters' from left menu â†’ 'Add New' button\n2) Select version in version selection screen (e.g., v1.36.2)\n3) In general settings card:\n   - Name: Enter cluster name (e.g., 'backend-api')\n   - Version: Auto-filled\n4) Select 'type' tag from left menu\n5) In 'Single Options' card, 'Type' dropdown â†’ select STATIC\n6) Select 'load_assignment' tag from left menu\n7) 'Load Assignment' card opens\n8) In horizontal tag bar:\n   - Activate 'cluster_name' tag\n   - Enter cluster name (usually same as main cluster name)\n9) Activate 'endpoints' tag\n10) 'Endpoints' card opens\n11) Click blue '+' button (add new endpoint)\n12) Endpoint tab opens (label: 'LbEndpoint: 0')\n13) From horizontal tags, select 'endpoint'\n14) Under 'Endpoint', select 'address' tag\n15) Under 'Address', select 'socket_address' tag\n16) Socket Address fields:\n    - address: Enter IP address (e.g., 192.168.1.100)\n    - port_value: Enter port (e.g., 8080)\n17) For multiple endpoints, add new endpoint with '+'\n18) Configure address and port for each endpoint\n19) Press 'Create' button\n\nEXAMPLE SCENARIO:\n- 3 backend servers: 192.168.1.100:8080, 192.168.1.101:8080, 192.168.1.102:8080\n- Add separate endpoint for each\n- Envoy performs load balancing (default: round-robin)"}
{"resource":"Cluster","category":"cluster_types","instruction":"How to create an EDS cluster and connect it with endpoint resource?","output":"CREATING EDS CLUSTER:\n\n1) FIRST CREATE ENDPOINT RESOURCE:\n   a) Go to 'Endpoints' page from left menu\n   b) Click 'Add New' button\n   c) Select version\n   d) Enter endpoint name (e.g., 'backend-api-endpoints')\n   e) Fill endpoints configuration (addresses, ports)\n   f) Save endpoint resource with 'Create'\n\n2) NOW CREATE EDS CLUSTER:\n   a) Go to 'Clusters' page â†’ 'Add New'\n   b) Select version\n   c) Enter cluster name (e.g., 'backend-api')\n   d) Select 'type' tag from left menu\n   e) 'Type' dropdown â†’ select EDS\n   f) Select 'eds_cluster_config' tag from left menu\n   g) 'EDS Cluster Config' card opens\n   h) 'service_name' dropdown appears\n   i) Click dropdown or search (300ms debounce)\n   j) Previously created endpoint resource appears: 'backend-api-endpoints'\n   k) Select: 'backend-api-endpoints'\n   l) EDS config automatically created:\n      * service_name: 'backend-api-endpoints'\n      * config_source: ADS (default)\n   m) Press 'Create' button\n\n3) EDS CLUSTER ADVANTAGES:\n   - Endpoints updated dynamically\n   - Change endpoint resource â†’ cluster automatically updated\n   - Integrated with Kubernetes discovery\n   - Zero-downtime endpoint addition/removal\n\n4) ENDPOINT RESOURCE UPDATE:\n   a) Go to 'Endpoints' page\n   b) Click 'backend-api-endpoints' row\n   c) Add or remove new endpoint\n   d) Press 'Update' button\n   e) Snapshot update job starts\n   f) All EDS clusters automatically receive new endpoints\n   g) Services reloaded (without interruption)\n\n5) BATCH ENDPOINT CREATION WITH DISCOVERY MODAL:\n   a) On endpoint create/edit page\n   b) 'Discovery' button appears in general settings card\n   c) Click 'Discovery' button\n   d) Discovery modal window opens\n   e) Select Kubernetes clusters\n   f) Select Service/Deployment\n   g) Pod IPs automatically added as endpoints\n   h) Press 'Save' button\n   i) Endpoint resource filled with discovery"}
{"resource":"Cluster","category":"health_checks","instruction":"How to add health check to cluster?","output":"ADDING HEALTH CHECK:\n\n1) Go to cluster create/edit page\n2) Select 'health_checks' tag from left menu\n3) 'Health Checks' card opens\n4) Tab structure at top of card (editable-card type)\n5) Click '+' icon at top-right\n6) New health check tab created (label: 'HC: 0', 'HC: 1' etc.)\n7) Click health check tab\n8) Horizontal tag bar appears\n\n9) REQUIRED FIELDS (4 total):\n   a) timeout: Health check timeout duration (e.g., '5s')\n   b) interval: Health check interval (e.g., '10s')\n   c) unhealthy_threshold: Failed attempts to mark unhealthy (e.g., 3)\n   d) healthy_threshold: Successful attempts to mark healthy (e.g., 2)\n   \n   Activate these 4 tags and enter values\n\n10) SELECT HEALTH CHECK TYPE (Only 1 required):\n    3 options appear in horizontal tags:\n    - http_health_check\n    - tcp_health_check\n    - grpc_health_check\n    \n    NOTE: Can only select one (onlyOneTag constraint)\n    When one active, others disabled with tooltip balloon\n\n11) HTTP HEALTH CHECK:\n    a) Select 'http_health_check' tag\n    b) 'HTTP Health Check' card opens\n    c) Fields:\n       * host: Host header (e.g., 'api.example.com')\n       * path: Health check path (e.g., '/health')\n       * request_headers_to_add: Extra headers (optional)\n    d) Path required, others optional\n\n12) TCP HEALTH CHECK:\n    a) Select 'tcp_health_check' tag\n    b) 'TCP Health Check' card opens\n    c) Fields:\n       * send: Data to send (base64 or text)\n       * receive: Expected response (array)\n    d) Usually left empty (just TCP connection check)\n\n13) GRPC HEALTH CHECK:\n    a) Select 'grpc_health_check' tag\n    b) 'GRPC Health Check' card opens\n    c) Fields:\n       * service_name: gRPC service name (optional)\n       * authority: Authority header (optional)\n\n14) EXAMPLE HTTP HEALTH CHECK:\n    - timeout: '3s'\n    - interval: '10s'\n    - unhealthy_threshold: 3\n    - healthy_threshold: 2\n    - http_health_check.path: '/healthz'\n    - http_health_check.host: 'backend.local'\n\n15) MULTIPLE HEALTH CHECKS:\n    - Can add new health check with '+'\n    - Each health check can be different type\n    - E.g., HC:0 HTTP /health, HC:1 TCP port check"}
{"resource":"Cluster","category":"health_checks","instruction":"What happens when health check fails?","output":"HEALTH CHECK FAILURE SCENARIO:\n\n1) HEALTH CHECK MECHANISM:\n   - Envoy sends periodic health checks to each endpoint\n   - Repeats at interval duration (e.g., every 10s)\n   - Waits for response within timeout duration (e.g., 3s)\n\n2) UNHEALTHY THRESHOLD:\n   - If unhealthy_threshold: 3\n   - 3 consecutive failed health checks\n   - Endpoint marked as UNHEALTHY\n\n3) UNHEALTHY ENDPOINT BEHAVIOR:\n   - Envoy does NOT send NEW traffic to this endpoint\n   - Removed from load balancing\n   - Existing connections drained (graceful shutdown)\n   - Health check continues (for recovery)\n\n4) HEALTHY THRESHOLD (RECOVERY):\n   - If healthy_threshold: 2\n   - 2 consecutive successful health checks\n   - Endpoint becomes HEALTHY again\n   - Re-added to load balancing\n   - Starts receiving new traffic\n\n5) IF ALL ENDPOINTS UNHEALTHY:\n   - Cluster enters PANIC threshold\n   - Default panic threshold: 50%\n   - Envoy sends traffic to all endpoints (degraded mode)\n   - Better than sending no traffic at all\n\n6) METRICS:\n   - cluster.{cluster_name}.health_check.success: Successful health check count\n   - cluster.{cluster_name}.health_check.failure: Failed health check count\n   - cluster.{cluster_name}.membership_healthy: Healthy endpoint count\n   - cluster.{cluster_name}.membership_total: Total endpoint count\n\n7) VIEWING IN UI:\n   - Go to Metrics page\n   - Select cluster\n   - View health check metrics\n   - Chart: Healthy vs Unhealthy endpoint count (over time)\n\n8) EXAMPLE SCENARIO:\n   - 3 endpoints: A, B, C\n   - unhealthy_threshold: 3, healthy_threshold: 2\n   - t=0: A, B, C â†’ HEALTHY (receiving traffic)\n   - t=10s: B health check fail (1st time)\n   - t=20s: B health check fail (2nd time)\n   - t=30s: B health check fail (3rd time) â†’ B UNHEALTHY\n   - t=30s-onwards: Only A and C receiving traffic\n   - t=40s: B health check success (1st time)\n   - t=50s: B health check success (2nd time) â†’ B HEALTHY\n   - t=50s-onwards: A, B, C receiving traffic again"}
{"resource":"Cluster","category":"load_assignment","instruction":"What is load assignment and how to configure it in static cluster?","output":"LOAD ASSIGNMENT:\n\n1) WHAT IS LOAD ASSIGNMENT:\n   - Configuration defining cluster endpoints\n   - Specifies which IP:ports to send traffic to\n   - Envoy's ClusterLoadAssignment resource\n\n2) USAGE IN STATIC/DNS CLUSTERS:\n   - If cluster type: STATIC, STRICT_DNS, LOGICAL_DNS\n   - load_assignment field REQUIRED\n   - Endpoints manually defined\n\n3) LOAD ASSIGNMENT STRUCTURE IN UI:\n   a) Select 'load_assignment' tag on cluster page\n   b) 'Load Assignment' card opens\n   c) Horizontal tags inside card:\n      * cluster_name: Cluster name (required)\n      * endpoints: Endpoint list (required)\n      * policy: Load balancing policy (optional)\n\n4) CLUSTER_NAME FIELD:\n   a) Activate 'cluster_name' tag\n   b) Input field appears\n   c) Enter cluster name (usually same as main cluster)\n   d) E.g., 'backend-api'\n\n5) ADDING ENDPOINTS:\n   a) Activate 'endpoints' tag\n   b) 'Endpoints' card opens\n   c) Tab structure (editable-card type)\n   d) Each tab is a LocalityLbEndpoints\n   e) Add new locality with '+' at top-right\n   f) Tab label: 'Locality: 0', 'Locality: 1' etc.\n\n6) LB_ENDPOINTS INSIDE LOCALITY:\n   a) Click locality tab\n   b) 'lb_endpoints' tag appears and activate it\n   c) 'Lb Endpoints' card opens\n   d) Tab structure again\n   e) Each tab is a LbEndpoint (one endpoint)\n   f) Add new endpoint with '+'\n   g) Tab label: 'LbEndpoint: 0', 'LbEndpoint: 1' etc.\n\n7) ENDPOINT CONFIGURATION:\n   a) Click LbEndpoint tab\n   b) Horizontal tags:\n      * endpoint: Endpoint address (required)\n      * health_status: Health status (optional)\n      * load_balancing_weight: Weight (optional)\n   c) Select 'endpoint' tag\n   d) Under 'Endpoint', select 'address' tag\n   e) Under 'Address', select 'socket_address' tag\n   f) Socket Address:\n      * address: IP address (e.g., '192.168.1.100')\n      * port_value: Port (e.g., 8080)\n\n8) EXAMPLE CONFIGURATION:\n   cluster_name: 'backend-api'\n   endpoints:\n     - locality: 0\n       lb_endpoints:\n         - endpoint:\n             address:\n               socket_address:\n                 address: '192.168.1.100'\n                 port_value: 8080\n         - endpoint:\n             address:\n               socket_address:\n                 address: '192.168.1.101'\n                 port_value: 8080\n         - endpoint:\n             address:\n               socket_address:\n                 address: '192.168.1.102'\n                 port_value: 8080\n\n9) LOAD BALANCING WEIGHT:\n   - If load_balancing_weight tag activated\n   - Enter number (e.g., 100, 50)\n   - Higher value â†’ more traffic\n   - E.g., Endpoint A weight=100, B weight=50 â†’ A receives 2x traffic of B"}
{"resource":"Cluster","category":"load_assignment","instruction":"How to add/remove endpoints and what happens?","output":"ADDING/REMOVING ENDPOINTS:\n\n1) ADDING ENDPOINT TO EXISTING CLUSTER:\n   a) Click cluster row on 'Clusters' page (edit page)\n   b) Select 'load_assignment' tag from left menu\n   c) 'Load Assignment' card â†’ select 'endpoints' tag\n   d) Select locality tab (if exists) or add new\n   e) Select 'lb_endpoints' tag\n   f) Click '+' icon at top-right\n   g) New LbEndpoint tab created\n   h) Fill endpoint configuration (address, port)\n   i) Press 'Update' button\n\n2) REMOVING ENDPOINT:\n   a) Go to LbEndpoint tab\n   b) Click 'x' (delete) icon on tab\n   c) Tab closes, endpoint removed\n   d) Press 'Update' button\n\n3) PROCESS AFTER UPDATE:\n   a) Cluster configuration sent to backend\n   b) Backend finds all resources using this cluster\n   c) Creates snapshot update job for each resource\n   d) Can be tracked from 'Jobs' page:\n      * Job Type: 'Snapshot Update'\n      * Resource: 'Cluster: backend-api'\n   e) Snapshot updated (includes new endpoints)\n   f) Services reloaded (without interruption)\n\n4) WHEN NEW ENDPOINT ADDED:\n   - Envoy learns new endpoint\n   - Health check starts (if configured)\n   - After healthy_threshold successful checks\n   - Endpoint becomes HEALTHY\n   - Added to load balancing\n   - Starts receiving traffic\n\n5) WHEN ENDPOINT REMOVED:\n   - Envoy removes endpoint from load balancing\n   - Existing connections drained (graceful shutdown)\n   - No new connections accepted\n   - Completely removed after drain_timeout\n\n6) ENDPOINT UPDATE IN EDS CLUSTER:\n   - If EDS cluster, load_assignment does NOT exist\n   - Update endpoint resource:\n     a) Go to 'Endpoints' page\n     b) Click relevant endpoint resource\n     c) Add/remove endpoint\n     d) Press 'Update' button\n   - All EDS clusters automatically updated\n   - Cleaner and centralized management\n\n7) ZERO-DOWNTIME UPDATE:\n   - Envoy uses hot reload\n   - Existing connections continue without interruption\n   - New connections use new endpoints\n   - User notices nothing\n\n8) EXAMPLE SCENARIO - ADDED NEW BACKEND:\n   - Initial: 2 endpoints (A: 192.168.1.100, B: 192.168.1.101)\n   - New server: C: 192.168.1.102\n   - Add endpoint to cluster (above steps)\n   - Press update button\n   - Health check 20s (2 success * 10s interval)\n   - After 20s, C starts receiving traffic\n   - Load balancing: round-robin among A, B, C"}
{"resource":"Cluster","category":"outlier_detection","instruction":"What is outlier detection and how to configure it?","output":"OUTLIER DETECTION (ANOMALOUS ENDPOINT DETECTION):\n\n1) WHAT IS OUTLIER DETECTION:\n   - Automatically detects poorly performing endpoints\n   - Different from health check: Based on real traffic\n   - Counts failed requests (5xx errors, timeout etc.)\n   - Temporarily disables bad endpoints\n\n2) HEALTH CHECK VS OUTLIER DETECTION:\n   - Health check: Active probe (GET /health)\n   - Outlier detection: Passive observation (real traffic analysis)\n   - Both can be used together (recommended)\n\n3) CONFIGURATION IN UI:\n   a) Select 'outlier_detection' tag from left menu on cluster page\n   b) 'Outlier Detection' card opens\n   c) Horizontal tag bar appears\n   d) Basic fields:\n      * consecutive_5xx: Consecutive 5xx error count (e.g., 5)\n      * interval: Analysis interval (e.g., '10s')\n      * base_ejection_time: Initial ejection duration (e.g., '30s')\n      * max_ejection_percent: Maximum percentage of endpoints that can be ejected (e.g., 50)\n      * consecutive_gateway_failure: Consecutive gateway failure count (e.g., 5)\n\n4) BASIC CONFIGURATION STEPS:\n   a) Activate 'consecutive_5xx' tag\n   b) Enter number (e.g., 5)\n   c) Activate 'interval' tag\n   d) Enter duration (e.g., '10s')\n   e) Activate 'base_ejection_time' tag\n   f) Enter duration (e.g., '30s')\n   g) Activate 'max_ejection_percent' tag\n   h) Enter percentage (e.g., 50)\n\n5) WORKING PRINCIPLE:\n   - interval: Analyzed every 10s\n   - consecutive_5xx: 5: If an endpoint returns 5 consecutive 5xx\n   - Endpoint EJECTED (temporarily disabled)\n   - base_ejection_time: No traffic for 30s\n   - After 30s, included again\n   - If returns 5xx again, ejection time doubles (30s â†’ 60s â†’ 120s)\n\n6) MAX EJECTION PERCENT:\n   - max_ejection_percent: 50\n   - Maximum 50% of endpoints can be ejected\n   - E.g., 4 endpoints exist, max 2 can be ejected\n   - Prevents entire cluster from going down\n   - Similar logic to panic mode\n\n7) EXAMPLE SCENARIO:\n   - 3 backends: A, B, C\n   - consecutive_5xx: 5, interval: 10s, base_ejection_time: 30s\n   - Application error started in B endpoint\n   - t=0-50s: B returned 5 consecutive 5xx\n   - t=50s: B EJECTED (removed from load balancing)\n   - t=50-80s: Only A and C receiving traffic\n   - t=80s: B included again (30s ended)\n   - If B recovered: Continues normal operation\n   - If B still returning errors: Ejected again (this time 60s)\n\n8) METRICS:\n   - cluster.{cluster_name}.outlier_detection.ejections_active: Active ejection count\n   - cluster.{cluster_name}.outlier_detection.ejections_total: Total ejection count\n   - cluster.{cluster_name}.outlier_detection.ejections_consecutive_5xx: Ejections due to 5xx\n\n9) BEST PRACTICES:\n   - consecutive_5xx: 5 (not too low, avoid false positives)\n   - interval: 10s (not too short, avoid overhead)\n   - base_ejection_time: 30s (not too long, recovery not delayed)\n   - max_ejection_percent: 50 (entire cluster won't go down)\n   - Use together with health check"}
{"resource":"Cluster","category":"tls","instruction":"How to add upstream TLS to cluster?","output":"UPSTREAM TLS CONFIGURATION:\n\n1) WHAT IS UPSTREAM TLS:\n   - TLS on Envoy â†’ Upstream (backend) connection\n   - Different from downstream TLS (client â†’ Envoy)\n   - Required if backend is HTTPS\n   - Also used for client certificate (mTLS)\n\n2) ADDING TLS IN UI:\n   a) Select 'transport_socket' tag from left menu on cluster page\n   b) 'Transport Socket' card opens\n   c) In horizontal tag bar:\n      * name: Transport socket name\n      * typed_config: TLS configuration\n   d) Activate 'typed_config' tag\n\n3) TLS CONTEXT SELECTION:\n   a) Dropdown menu appears in 'Typed Config' card\n   b) 'Type' dropdown â†’ select 'UpstreamTlsContext'\n   c) Upstream TLS configuration opens\n\n4) BASIC TLS CONFIGURATION (SERVER VERIFICATION ONLY):\n   a) Select 'common_tls_context' tag\n   b) Select 'validation_context' tag\n   c) Select 'trusted_ca' tag\n   d) Upload CA certificate:\n      * filename: CA file path (e.g., '/etc/ssl/certs/ca.pem')\n      * inline_string: CA content (base64 or PEM)\n   e) Select 'sni' tag (optional but recommended)\n   f) Enter SNI hostname (e.g., 'backend.example.com')\n\n5) MTLS (MUTUAL TLS - CLIENT CERTIFICATE):\n   a) Under 'common_tls_context', select 'tls_certificates' tag\n   b) Add certificate with '+'\n   c) Certificate tab opens\n   d) Select 'certificate_chain' tag:\n      * filename: Client certificate file (e.g., '/etc/ssl/client-cert.pem')\n      * inline_string: Certificate content (PEM)\n   e) Select 'private_key' tag:\n      * filename: Private key file (e.g., '/etc/ssl/client-key.pem')\n      * inline_string: Key content (PEM)\n\n6) CERTIFICATE MANAGEMENT WITH SECRET RESOURCE:\n   a) First create secret from 'Secrets' page\n   b) Secret type: TlsCertificate\n   c) Upload certificate and key\n   d) Secret name: 'client-tls-secret'\n   e) In cluster TLS configuration:\n      * Use tls_certificate_sds_secret_configs\n      * Reference secret name: 'client-tls-secret'\n   f) Certificate management becomes centralized\n   g) Certificate rotation easy\n\n7) ALPN CONFIGURATION (FOR HTTP/2):\n   a) Under 'common_tls_context', select 'alpn_protocols' tag\n   b) Add ALPN with '+'\n   c) String input: 'h2' (HTTP/2)\n   d) Optional: Also add 'http/1.1'\n\n8) EXAMPLE HTTPS BACKEND CONFIGURATION:\n   - Cluster name: 'api-https'\n   - Type: STRICT_DNS\n   - Load assignment: api.example.com:443\n   - Transport socket:\n     * UpstreamTlsContext\n     * sni: 'api.example.com'\n     * validation_context:\n       - trusted_ca: '/etc/ssl/certs/ca-bundle.crt'\n   - ALPN: ['h2', 'http/1.1']\n\n9) MTLS EXAMPLE (CLIENT CERTIFICATE REQUIRED):\n   - Backend requires mTLS\n   - Certificate and key ready\n   - Transport socket:\n     * UpstreamTlsContext\n     * common_tls_context:\n       - tls_certificates:\n         * certificate_chain: inline_string (PEM)\n         * private_key: inline_string (PEM)\n       - validation_context:\n         * trusted_ca: inline_string (CA PEM)\n     * sni: 'backend.internal'\n\n10) TLS VERIFICATION:\n    - Create cluster and deploy service\n    - Go to Logs page\n    - Look at TLS handshake logs\n    - Success: 'TLS handshake complete'\n    - Error: 'TLS error: certificate verify failed'"}
{"resource":"Cluster","category":"advanced","instruction":"What are cluster connect_timeout and other timeout settings?","output":"CLUSTER TIMEOUT SETTINGS:\n\n1) CONNECT_TIMEOUT:\n   - Maximum duration to establish upstream connection\n   - TCP handshake + TLS handshake (if exists)\n   - UI: Select 'connect_timeout' tag from left menu\n   - Enter duration in 'Single Options' card (e.g., '5s')\n   - Default: Usually 5s sufficient\n   - Too low: False positives (network latency)\n   - Too high: Slow failover\n\n2) TIMEOUT TYPES:\n\n   a) connect_timeout:\n      - Connection establishment\n      - E.g., '5s'\n      - Required field\n\n   b) idle_timeout (HTTP connection pool):\n      - How long idle connection stays open\n      - E.g., '60s'\n      - Important for connection reuse\n\n   c) max_connection_duration:\n      - Maximum lifetime for a connection\n      - E.g., '3600s' (1 hour)\n      - Memory leak prevention\n\n3) TIMEOUT CONFIGURATION IN UI:\n   a) Select relevant timeout tag from left menu\n   b) 'Single Options' card opens\n   c) Enter value in duration input field\n   d) Format: '{number}{unit}'\n      * s: seconds (e.g., '5s')\n      * m: minutes (e.g., '1m')\n      * h: hours (e.g., '1h')\n      * ms: milliseconds (e.g., '500ms')\n\n4) EXAMPLE CONFIGURATION:\n   - connect_timeout: '5s' (backend connection)\n   - idle_timeout: '60s' (connection pool)\n   - max_connection_duration: '3600s' (1 hour max lifetime)\n\n5) TIMEOUT ERRORS:\n   - If connect_timeout exceeded:\n     * Upstream connection error\n     * Retried if retry policy exists\n     * Otherwise: 503 Service Unavailable\n   - Metric: cluster.{cluster_name}.upstream_cx_connect_timeout\n\n6) WITH RETRY POLICY:\n   - Retry policy defined in route\n   - Retry triggered when connect_timeout exceeded\n   - Tries different endpoint (if available)\n   - E.g., 3 backends, one timeout â†’ automatically tries another\n\n7) BEST PRACTICES:\n   - connect_timeout: 5s (for most backends)\n   - connect_timeout: 10s (for remote region backends)\n   - idle_timeout: 60s for HTTP/1.1, longer for HTTP/2\n   - max_connection_duration: 1 hour (memory leak prevention)"}
{"resource":"Cluster","category":"discovery","instruction":"How to auto-populate cluster endpoints with Kubernetes discovery?","output":"KUBERNETES DISCOVERY INTEGRATION:\n\n1) WHAT IS IT:\n   - Automatically adds Kubernetes Pod IPs as endpoints\n   - Manual IP entry unnecessary\n   - Pod dies/recreated â†’ endpoint automatically updated\n   - Critical for service mesh\n\n2) BEFORE: KUBERNETES DISCOVERY CONFIGURATION\n   a) Go to Settings â†’ Discovery page\n   b) Click 'Add Kubernetes Cluster' button\n   c) Kubernetes information:\n      * Cluster name: 'prod-k8s'\n      * API Server: 'https://k8s.example.com:6443'\n      * Token or kubeconfig\n   d) 'Test Connection' â†’ success\n   e) Press 'Save' button\n   f) Discovery starts running in backend\n\n3) DISCOVERY WITH ENDPOINT RESOURCE:\n   a) Go to 'Endpoints' page â†’ 'Add New'\n   b) Select version\n   c) Enter endpoint name (e.g., 'backend-pods')\n   d) 'Discovery' button appears in general settings card\n   e) Click 'Discovery' button\n\n4) DISCOVERY MODAL:\n   a) Modal window opens\n   b) Left side: Kubernetes cluster list\n   c) Select cluster: 'prod-k8s'\n   d) Select namespace: 'default'\n   e) Select resource type:\n      * Service (ClusterIP, LoadBalancer)\n      * Deployment (Pod IPs)\n      * StatefulSet (Pod IPs)\n   f) Service/Deployment list loads\n   g) Select desired: 'backend-deployment'\n   h) Select port: 8080 (container port)\n   i) Preview shown:\n      * Pod IP: 10.244.1.10:8080\n      * Pod IP: 10.244.1.11:8080\n      * Pod IP: 10.244.1.12:8080\n   j) Press 'Apply' button\n\n5) WHEN DISCOVERY SAVED:\n   a) Modal closes\n   b) Discovery info saved to Redux\n   c) 'load_assignment.endpoints' auto-populated\n   d) Separate LbEndpoint created for each Pod IP\n   e) Press 'Create' or 'Update' button\n\n6) AUTOMATIC UPDATE:\n   - Backend discovery job runs periodically (e.g., every 30s)\n   - Queries Kubernetes API\n   - New Pod added? â†’ Adds to endpoint\n   - Pod deleted? â†’ Removes from endpoint\n   - Endpoint resource updated\n   - Snapshot update job starts\n   - EDS clusters automatically receive new endpoints\n\n7) TOGETHER WITH EDS CLUSTER:\n   a) Endpoint resource: 'backend-pods' (filled with discovery)\n   b) Create cluster: 'backend-cluster'\n   c) Type: EDS\n   d) eds_cluster_config.service_name: 'backend-pods'\n   e) Cluster automatically uses Pod IPs from endpoint\n   f) Pod scale up/down â†’ cluster automatically updated\n\n8) EXAMPLE SCENARIO - KUBERNETES DEPLOYMENT:\n   - In Kubernetes: backend-deployment (3 replicas)\n   - Pod IPs: 10.244.1.10, 10.244.1.11, 10.244.1.12\n   - In Elchi:\n     * Endpoint resource: 'backend-pods'\n     * Discovery: prod-k8s / default / backend-deployment / port 8080\n     * Endpoint auto-populated with 3 IPs\n   - Cluster:\n     * Type: EDS\n     * service_name: 'backend-pods'\n   - In Kubernetes scale: 3 â†’ 5 replicas\n   - Within 30s:\n     * Discovery detects new 2 Pod IPs\n     * Endpoint resource updated (5 IPs)\n     * Cluster automatically works with 5 endpoints\n\n9) TRACKING DISCOVERY STATUS:\n   - 'Discovery Sync' jobs visible on Jobs page\n   - Each sync:\n     * Kubernetes API queried\n     * X Pods detected\n     * Endpoint resource updated\n   - Log output:\n     * 'Discovered 5 pods for backend-deployment'\n     * 'Added 2 new endpoints'\n     * 'Removed 0 endpoints'\n\n10) BEST PRACTICES:\n    - Separate endpoint resource for each Kubernetes deployment\n    - Use EDS cluster type (together with discovery)\n    - Discovery sync interval: 30s (not too frequent, API overhead)\n    - Add health check (verify Pod is healthy)"}
{"resource":"Route","category":"route_basics","instruction":"What is Route Configuration and how to create it?","output":"ROUTE CONFIGURATION:\n\n1) WHAT IS ROUTE CONFIGURATION:\n   - Defines Envoy's HTTP routing rules\n   - Determines which cluster to route incoming requests to\n   - Contains virtual hosts\n   - Domain matching, path matching, header matching etc.\n\n2) ROUTE CREATION STEPS:\n   a) Click 'Route' from left menu â†’ 'Add New' button\n   b) Select version in version selection screen (e.g., v1.36.2)\n   c) General settings card opens\n   d) Enter route name in Name input box (e.g., 'api-routes')\n   e) Version auto-filled (not editable)\n\n3) LEFT MENU TAGS:\n   - name: Route configuration name (required)\n   - virtual_hosts: Virtual host list (required)\n   - vhds: Virtual Host Discovery Service (optional)\n   - request_headers_to_add: Add header for all routes\n   - response_headers_to_add: Response header for all routes\n   - request_headers_to_remove: Remove header\n   - response_headers_to_remove: Remove response header\n\n4) ADDING VIRTUAL HOSTS:\n   a) Select 'virtual_hosts' tag from left menu\n   b) 'Virtual Hosts' card opens\n   c) Array icon (blue array icon) appears\n   d) Click icon â†’ Drawer (side panel) opens\n   e) Drawer title: 'HTTP Route Components'\n   f) Virtual host configuration inside drawer\n\n5) ROUTE CONFIGURATION USAGE PLACES:\n   - In HttpConnectionManager filter:\n     * route_config: Inline route (static)\n     * rds: Route Discovery Service (dynamic)\n   - Listener â†’ Filter Chains â†’ HCM â†’ route_config\n\n6) STATIC VS RDS:\n   - **STATIC (Inline Route Config)**:\n     * Route configuration defined inside listener\n     * Requires listener update for changes\n     * Suitable for test and development\n   \n   - **RDS (Route Discovery Service)**:\n     * Route configuration as separate resource\n     * Route can be updated without changing listener\n     * Recommended for production\n     * Zero-downtime route changes\n\n7) USAGE WITH RDS:\n   - Create route resource: 'api-routes'\n   - In listener HCM configuration:\n     * rds.route_config_name: 'api-routes'\n     * rds.config_source: ads\n   - Route change:\n     * Update route resource\n     * Snapshot update job starts\n     * Listener automatically receives new route\n     * Zero-downtime update"}
{"resource":"Route","category":"virtual_hosts","instruction":"What is Virtual Host and how to configure it?","output":"VIRTUAL HOST CONFIGURATION:\n\n1) WHAT IS VIRTUAL HOST:\n   - Basic unit of HTTP routing\n   - Provides domain-based routing\n   - Each virtual host serves different domain\n   - Contains routes list (path matching)\n\n2) OPENING VIRTUAL HOST DRAWER:\n   a) Select 'virtual_hosts' tag on route page\n   b) Click blue array icon in 'Virtual Hosts' card\n   c) Drawer (side panel) opens from right\n   d) Drawer width: 1400px (large)\n   e) Drawer title: 'HTTP Route Components'\n\n3) VIRTUAL HOST MANAGEMENT IN DRAWER:\n   a) Virtual host list (array structure)\n   b) For each virtual host:\n      * Tab structure (editable-card type)\n      * Tab label: 'VH: 0', 'VH: 1' etc.\n      * Add new virtual host with '+'\n      * Delete virtual host with 'x'\n   c) 'Close' button at bottom (close drawer)\n\n4) VIRTUAL HOST BASIC FIELDS:\n   a) **name**: Virtual host name (optional but recommended)\n      - E.g., 'api-domain', 'web-domain'\n   \n   b) **domains**: Domain list (required)\n      - Exact match: 'api.example.com'\n      - Wildcard suffix: '*.example.com'\n      - Wildcard prefix: 'api.*'\n      - Catch-all: '*'\n      - Including port: 'api.example.com:8080'\n   \n   c) **routes**: Route list (required)\n      - Path matching rules\n      - Cluster routing\n      - Each route is an endpoint pattern\n\n5) DOMAIN MATCHING RULES:\n   - **Exact match**: 'api.example.com'\n     * Only exact match\n   \n   - **Suffix wildcard**: '*.example.com'\n     * api.example.com âœ…\n     * web.example.com âœ…\n     * example.com âŒ\n   \n   - **Prefix wildcard**: 'api.*'\n     * api.example.com âœ…\n     * api.test.com âœ…\n   \n   - **Port specific**: 'api.example.com:8080'\n     * Only requests to port 8080\n   \n   - **Catch-all**: '*'\n     * All domains (fallback)\n\n6) EXAMPLE VIRTUAL HOST CONFIGURATION:\n   ```\n   Virtual Host 0:\n   - name: 'api-vhost'\n   - domains: ['api.example.com', 'api.test.com']\n   - routes:\n     * Route 0: /v1/* â†’ backend-api cluster\n     * Route 1: /v2/* â†’ backend-api-v2 cluster\n     * Route 2: /health â†’ health-check cluster\n   \n   Virtual Host 1:\n   - name: 'web-vhost'\n   - domains: ['www.example.com', 'example.com']\n   - routes:\n     * Route 0: / â†’ frontend cluster\n     * Route 1: /api/* â†’ backend-api cluster\n   ```\n\n7) VIRTUAL HOST PRIORITY:\n   - Envoy domain matching order:\n     1) Exact match (highest priority)\n     2) Suffix wildcard (*.example.com)\n     3) Prefix wildcard (api.*)\n     4) Catch-all (*) (lowest priority)\n   - First matching virtual host used\n\n8) MULTIPLE VIRTUAL HOSTS IN DRAWER:\n   - Add new virtual host with '+'\n   - Each virtual host different domain set\n   - E.g.:\n     * VH 0: api.example.com â†’ API routes\n     * VH 1: www.example.com â†’ Web routes\n     * VH 2: admin.example.com â†’ Admin routes\n     * VH 3: * â†’ Fallback (404 cluster)"}
{"resource":"Route","category":"route_matching","instruction":"How to do path matching in route?","output":"ROUTE PATH MATCHING:\n\n1) WHAT IS ROUTE:\n   - Routing rule inside virtual host\n   - Routes incoming HTTP request to cluster based on path\n   - Match field: Path, header, query param matching\n   - Route action: Cluster routing, redirect, direct response\n\n2) ADDING ROUTE:\n   a) Select virtual host in virtual host drawer\n   b) Select 'routes' tag from left menu\n   c) 'Routes' card opens\n   d) Click blue '+' button\n   e) New route tab created: 'Route: 0', 'Route: 1' etc.\n\n3) ROUTE MATCH TYPES (Single selection - onlyOneTag):\n   \n   a) **prefix**: Path prefix matching\n      - E.g., '/api' â†’ matches /api, /api/, /api/users, /api/v1/users\n      - Most common usage\n   \n   b) **path**: Exact path matching\n      - E.g., '/health' â†’ Only /health matches\n      - /health/ doesn't match\n   \n   c) **safe_regex**: Regex matching\n      - E.g., '^/api/v[0-9]+/.*'\n      - /api/v1/users âœ…\n      - /api/v2/orders âœ…\n      - /api/users âŒ\n   \n   d) **connect_matcher**: For HTTP CONNECT method\n      - Tunnel establishment requests\n\n4) PATH MATCHING UI STEPS:\n   a) Horizontal tags appear in route tab\n   b) Select 'match' tag\n   c) 'Match' card opens\n   d) Horizontal tags: prefix, path, safe_regex, connect_matcher\n   e) Select one (only 1 can be active)\n   f) Input field opens for selected type\n   g) Enter path pattern\n\n5) ROUTE ACTION (Routing):\n   Select action type in route tab:\n   \n   a) **route**: Route to cluster (most common)\n      - Select 'route' tag\n      - Select 'cluster' sub-tag\n      - Enter cluster name (e.g., 'backend-api')\n   \n   b) **redirect**: HTTP redirect\n      - Select 'redirect' tag\n      - path_redirect, host_redirect, response_code\n   \n   c) **direct_response**: Direct HTTP response\n      - Select 'direct_response' tag\n      - status: HTTP status code (e.g., 404)\n      - body: Response body\n\n6) EXAMPLE ROUTE PATTERNS:\n   ```\n   Route 0: API v1\n   - match.prefix: '/api/v1/'\n   - route.cluster: 'backend-api-v1'\n   \n   Route 1: API v2\n   - match.prefix: '/api/v2/'\n   - route.cluster: 'backend-api-v2'\n   \n   Route 2: Health check\n   - match.path: '/health'\n   - route.cluster: 'health-check'\n   \n   Route 3: Admin endpoints (regex)\n   - match.safe_regex.regex: '^/admin/.*'\n   - route.cluster: 'admin-cluster'\n   \n   Route 4: Static files\n   - match.prefix: '/static/'\n   - route.cluster: 'cdn-cluster'\n   \n   Route 5: 404 fallback\n   - match.prefix: '/'\n   - direct_response.status: 404\n   - direct_response.body: 'Not Found'\n   ```\n\n7) ROUTE PRIORITY:\n   - Routes tried top to bottom in order\n   - First matching route used\n   - Ordering important:\n     * Route 0: /api/v1/users (specific)\n     * Route 1: /api/ (general)\n     * Route 2: / (catch-all)\n   - Specific routes should be on top\n\n8) CHANGING ROUTE ORDER:\n   - Cannot reorder route tabs with drag-and-drop\n   - To change order:\n     * Delete and re-add\n     * Or: Export all routes, reorder, import"}
{"resource":"Route","category":"advanced_routing","instruction":"How to do header and query parameter matching?","output":"ADVANCED ROUTE MATCHING:\n\n1) HEADER MATCHING:\n   - Route selection based on HTTP headers\n   - Same path different header â†’ different cluster\n   - Use case: API versioning, A/B testing, canary deployment\n\n2) HEADER MATCHING STEPS:\n   a) Select 'match' tag in route tab\n   b) Select 'headers' tag in 'Match' card\n   c) Click blue '+' button\n   d) Header matcher tab created\n   e) Configure header matcher:\n      * name: Header name (e.g., 'x-api-version')\n      * Select match type:\n        - exact_match: Exact match ('v2')\n        - prefix_match: Prefix ('v2')\n        - suffix_match: Suffix ('.beta')\n        - safe_regex_match: Regex ('^v[0-9]+')\n        - present_match: Check if header exists\n        - range_match: Numeric range\n\n3) HEADER MATCHING EXAMPLES:\n   ```\n   Route 0: API v2 (header-based)\n   - match.prefix: '/api/'\n   - match.headers[0]:\n     * name: 'x-api-version'\n     * exact_match: 'v2'\n   - route.cluster: 'backend-api-v2'\n   \n   Route 1: Canary deployment (10%)\n   - match.prefix: '/api/'\n   - match.headers[0]:\n     * name: 'x-canary'\n     * exact_match: 'true'\n   - route.cluster: 'backend-api-canary'\n   \n   Route 2: Mobile client\n   - match.prefix: '/'\n   - match.headers[0]:\n     * name: 'user-agent'\n     * safe_regex_match: '.*Mobile.*'\n   - route.cluster: 'mobile-backend'\n   ```\n\n4) QUERY PARAMETER MATCHING:\n   - Routing based on URL query string\n   - E.g., /api/users?version=v2\n\n5) QUERY PARAM MATCHING STEPS:\n   a) Select 'query_parameters' tag under route 'match'\n   b) Add query param matcher with blue '+'\n   c) Configure query parameter:\n      * name: Param name (e.g., 'version')\n      * Match type:\n        - string_match.exact: Exact match\n        - string_match.prefix: Prefix\n        - string_match.safe_regex: Regex\n        - present_match: Check if param exists\n\n6) QUERY PARAM EXAMPLES:\n   ```\n   Route 0: Beta version\n   - match.prefix: '/api/'\n   - match.query_parameters[0]:\n     * name: 'version'\n     * string_match.exact: 'beta'\n   - route.cluster: 'backend-beta'\n   \n   Route 1: Debug mode\n   - match.prefix: '/api/'\n   - match.query_parameters[0]:\n     * name: 'debug'\n     * present_match: true\n   - route.cluster: 'backend-debug'\n   ```\n\n7) MULTIPLE MATCHERS (AND LOGIC):\n   - Multiple matchers in same route:\n     * Path: /api/users\n     * Header: x-api-version=v2\n     * Query: debug=true\n   - ALL must match (AND logic)\n   - For very specific routing\n\n8) MATCHER PRIORITY:\n   - Routes tried top to bottom\n   - Specific matchers on top:\n     1) Path + Header + Query (most specific)\n     2) Path + Header\n     3) Path + Query\n     4) Path only\n     5) Catch-all\n\n9) A/B TESTING SCENARIO:\n   ```\n   Route 0: A/B Test - Group A (50%)\n   - match.prefix: '/'\n   - match.headers[0]:\n     * name: 'x-ab-group'\n     * exact_match: 'A'\n   - route.cluster: 'backend-version-a'\n   \n   Route 1: A/B Test - Group B (50%)\n   - match.prefix: '/'\n   - match.headers[0]:\n     * name: 'x-ab-group'\n     * exact_match: 'B'\n   - route.cluster: 'backend-version-b'\n   \n   Route 2: Default (no header)\n   - match.prefix: '/'\n   - route.cluster: 'backend-version-a'\n   ```"}
{"resource":"Route","category":"retry_policy","instruction":"How to configure retry policy in route?","output":"RETRY POLICY CONFIGURATION:\n\n1) WHAT IS RETRY POLICY:\n   - Automatically retry failed requests\n   - For transient errors (5xx, timeout, connection failure)\n   - Used together with circuit breaker\n   - Increases resilience\n\n2) ADDING RETRY POLICY:\n   a) Select 'route' tag in route tab (route action)\n   b) Select 'retry_policy' tag under 'Route' card\n   c) 'Retry Policy' card opens\n   d) Horizontal tags appear\n\n3) RETRY POLICY BASIC FIELDS:\n   \n   a) **retry_on**: Which errors to retry on (required)\n      - Options (multi-select):\n        * 5xx: All 5xx errors\n        * gateway-error: 502, 503, 504\n        * reset: Connection reset\n        * connect-failure: Connection failed\n        * refused-stream: Stream refused\n        * retriable-4xx: Some 4xx errors (429)\n        * retriable-status-codes: Custom status codes\n      - E.g., '5xx,gateway-error,reset'\n   \n   b) **num_retries**: Maximum retry count\n      - E.g., 3 (total 4 attempts: 1 original + 3 retry)\n   \n   c) **per_try_timeout**: Timeout for each attempt\n      - E.g., '3s'\n      - Independent from original timeout\n   \n   d) **retry_host_predicate**: Retry to different host\n      - previous-hosts: Don't retry same host\n      - Try new endpoint\n\n4) CONFIGURATION STEPS IN UI:\n   a) Select 'retry_on' tag\n   b) String input: '5xx,gateway-error,connect-failure'\n   c) Select 'num_retries' tag\n   d) Number input: 3\n   e) Select 'per_try_timeout' tag\n   f) Duration input: '3s'\n\n5) RETRY BACKOFF (DELAY):\n   - Select 'retry_back_off' tag\n   - base_interval: Initial retry delay (e.g., '100ms')\n   - max_interval: Maximum delay (e.g., '1s')\n   - Exponential backoff: 100ms â†’ 200ms â†’ 400ms â†’ 800ms â†’ 1s\n\n6) EXAMPLE RETRY POLICY:\n   ```\n   Retry Policy:\n   - retry_on: '5xx,gateway-error,connect-failure'\n   - num_retries: 3\n   - per_try_timeout: '2s'\n   - retry_back_off:\n     * base_interval: '100ms'\n     * max_interval: '1s'\n   ```\n\n7) RETRY SCENARIO:\n   - Request 1: backend-api â†’ 503 (unhealthy)\n   - Wait 100ms\n   - Request 2: backend-api (different endpoint) â†’ timeout (2s)\n   - Wait 200ms\n   - Request 3: backend-api (another endpoint) â†’ 200 OK âœ…\n   - Total time: ~4.3s (100ms + 2s + 200ms + request time)\n\n8) RETRY HOST PREDICATE:\n   - Select 'retry_host_predicate' tag\n   - Dropdown: 'envoy.retry_host_predicates.previous_hosts'\n   - Don't retry to same endpoint\n   - Try different endpoint with load balancing\n\n9) RETRY BUDGET:\n   - Select 'retry_budget' tag (optional)\n   - budget_percent: Maximum retry percentage (e.g., 20%)\n   - E.g., 100 requests â†’ max 20 retries\n   - Works like circuit breaker\n\n10) BEST PRACTICES:\n    - retry_on: '5xx,gateway-error,connect-failure' (common)\n    - num_retries: 2-3 (not too many)\n    - per_try_timeout: 1/3 of original timeout\n    - retry_back_off: Use exponential backoff\n    - retry_budget: 20-30% (prevent retry storm)\n    - Retry for idempotent requests (GET, PUT)\n    - Careful with non-idempotent (POST)"}
{"resource":"Route","category":"timeout","instruction":"How to configure route timeout settings?","output":"ROUTE TIMEOUT CONFIGURATION:\n\n1) ROUTE TIMEOUT TYPES:\n   \n   a) **timeout**: Total request timeout\n      - Upstream roundtrip + processing + return\n      - Default: 15s\n   \n   b) **idle_timeout**: Idle timeout\n      - When no data flow in stream\n   \n   c) **per_try_timeout**: For each retry attempt\n      - Together with retry policy\n\n2) ADDING TIMEOUT STEPS:\n   a) Select 'route' tag in route tab\n   b) Select 'timeout' tag under 'Route' card\n   c) Duration input field opens\n   d) Enter duration (e.g., '30s', '1m', '500ms')\n\n3) TIMEOUT FORMAT:\n   - Format: '{number}{unit}'\n   - Units:\n     * ms: milliseconds (e.g., '500ms')\n     * s: seconds (e.g., '30s')\n     * m: minutes (e.g., '5m')\n     * h: hours (e.g., '1h')\n   - Infinite: '0s' (no timeout, not recommended)\n\n4) EXAMPLE TIMEOUT CONFIGURATIONS:\n   ```\n   Route 0: API endpoint (normal)\n   - match.prefix: '/api/'\n   - route.cluster: 'backend-api'\n   - route.timeout: '30s'\n   \n   Route 1: Long-running operation\n   - match.prefix: '/api/export'\n   - route.cluster: 'backend-export'\n   - route.timeout: '5m'\n   \n   Route 2: Health check (fast)\n   - match.path: '/health'\n   - route.cluster: 'health'\n   - route.timeout: '3s'\n   ```\n\n5) IDLE TIMEOUT:\n   - Select 'idle_timeout' tag\n   - Duration input: '1m'\n   - Use case: WebSocket, streaming, long-polling\n   - Close connection if no data flow\n\n6) MAX STREAM DURATION:\n   - Select 'max_stream_duration' tag\n   - Maximum stream lifetime\n   - For WebSocket, gRPC streaming\n   - E.g., '1h' (force close after 1 hour)\n\n7) TIMEOUT HIERARCHY:\n   ```\n   Most specific â†’ Most general:\n   1) Route timeout (route level)\n   2) Virtual host timeout (virtual host level)\n   3) HCM request_timeout (listener level)\n   4) Cluster connect_timeout (cluster level)\n   ```\n   - If route timeout exists, use it\n   - Otherwise use higher level timeout\n\n8) TIMEOUT + RETRY RELATIONSHIP:\n   ```\n   Route timeout: 10s\n   Retry policy:\n   - num_retries: 3\n   - per_try_timeout: 3s\n   \n   Total time:\n   - First try: 3s (timeout)\n   - Retry 1: 3s (timeout)\n   - Retry 2: 3s (timeout)\n   - Retry 3: 3s (success)\n   - Total: 12s â†’ Route timeout (10s) exceeded âŒ\n   ```\n   - Route timeout > (num_retries + 1) * per_try_timeout\n\n9) TIMEOUT ERROR BEHAVIOR:\n   - When timeout exceeded:\n     * Upstream connection closed\n     * 504 Gateway Timeout returned to client\n     * Metric: route.{route_name}.upstream_rq_timeout incremented\n   - If retry policy exists:\n     * Retried (retry_on: 'retriable-4xx')\n\n10) BEST PRACTICES:\n    - API endpoints: 30s\n    - Health check: 3-5s\n    - Database query: 10s\n    - Long-running job: 5m (or use webhook)\n    - WebSocket/streaming: Use idle_timeout\n    - Route timeout > Cluster connect_timeout\n    - Route timeout > Per try timeout * num_retries"}
{"resource":"Route","category":"header_manipulation","instruction":"How to add or remove request/response headers in route?","output":"HEADER MANIPULATION:\n\n1) WHAT IS HEADER MANIPULATION:\n   - Add, remove, modify HTTP headers\n   - Request header: Client â†’ Envoy â†’ Upstream\n   - Response header: Upstream â†’ Envoy â†’ Client\n   - Use case: Authentication, tracing, security, debugging\n\n2) ADDING REQUEST HEADER:\n   a) Select 'route' tag in route tab\n   b) Select 'request_headers_to_add' tag under 'Route' card\n   c) Click blue '+' button\n   d) Header tab created\n   e) Configure header:\n      * header.key: Header name (e.g., 'x-forwarded-proto')\n      * header.value: Header value (e.g., 'https')\n      * append: Append to existing header? (true/false)\n\n3) REQUEST HEADER EXAMPLES:\n   ```\n   Header 0: Forwarded Proto\n   - header.key: 'x-forwarded-proto'\n   - header.value: 'https'\n   - append: false\n   \n   Header 1: Request ID\n   - header.key: 'x-request-id'\n   - header.value: '%REQ(x-request-id)%' (copy from request)\n   - append: false\n   \n   Header 2: Cluster name\n   - header.key: 'x-envoy-upstream-cluster'\n   - header.value: '%UPSTREAM_CLUSTER%'\n   - append: false\n   ```\n\n4) ADDING RESPONSE HEADER:\n   a) Select 'response_headers_to_add' tag under route 'route'\n   b) Add header with blue '+'\n   c) Configure header:\n      * header.key: 'x-custom-header'\n      * header.value: 'custom-value'\n      * append: false\n\n5) RESPONSE HEADER EXAMPLES:\n   ```\n   Header 0: Server info\n   - header.key: 'x-powered-by'\n   - header.value: 'Envoy/1.36.2'\n   \n   Header 1: CORS header\n   - header.key: 'access-control-allow-origin'\n   - header.value: '*'\n   \n   Header 2: Cache control\n   - header.key: 'cache-control'\n   - header.value: 'no-cache, no-store'\n   ```\n\n6) REMOVING REQUEST HEADER:\n   a) Select 'request_headers_to_remove' tag under route 'route'\n   b) String array input appears\n   c) Add header name with '+'\n   d) E.g., 'authorization', 'cookie', 'x-internal-header'\n\n7) REMOVING RESPONSE HEADER:\n   a) Select 'response_headers_to_remove' tag under route 'route'\n   b) String array input\n   c) Add header names to remove\n   d) E.g., 'server', 'x-powered-by' (for security)\n\n8) GLOBAL HEADER MANIPULATION (Route Config Level):\n   - In route configuration left menu:\n     * request_headers_to_add: For all routes\n     * response_headers_to_add: For all routes\n     * request_headers_to_remove: For all routes\n     * response_headers_to_remove: For all routes\n   - Virtual host and route level can override these\n\n9) DYNAMIC VALUES (Envoy Variables):\n   ```\n   Supported variables:\n   - %DOWNSTREAM_REMOTE_ADDRESS%: Client IP\n   - %REQ(header-name)%: Request header value\n   - %RESP(header-name)%: Response header value\n   - %START_TIME%: Request start time\n   - %UPSTREAM_CLUSTER%: Target cluster name\n   - %PROTOCOL%: HTTP/1.1, HTTP/2, etc.\n   \n   Example:\n   - header.key: 'x-client-ip'\n   - header.value: '%DOWNSTREAM_REMOTE_ADDRESS%'\n   ```\n\n10) HEADER HIERARCHY:\n    ```\n    Priority order:\n    1) Route level (highest)\n    2) Virtual host level\n    3) Route configuration level (global)\n    4) HCM level (listener)\n    ```\n\n11) SECURITY HEADERS EXAMPLE:\n    ```\n    Response headers to add:\n    - x-content-type-options: 'nosniff'\n    - x-frame-options: 'DENY'\n    - x-xss-protection: '1; mode=block'\n    - strict-transport-security: 'max-age=31536000'\n    \n    Response headers to remove:\n    - server (hide server info)\n    - x-powered-by (hide framework info)\n    ```"}
{"resource":"Route","category":"redirect_rewrite","instruction":"How to do redirect and URL rewrite in route?","output":"REDIRECT AND REWRITE:\n\n1) REDIRECT VS REWRITE:\n   - **Redirect**: Returns 301/302 to client, client goes to new URL\n   - **Rewrite**: Envoy sends different path to upstream, client unaware\n\n2) REDIRECT CONFIGURATION:\n   a) Select 'redirect' tag in route tab (instead of route action)\n   b) 'Redirect' card opens\n   c) Redirect fields:\n      * path_redirect: New path\n      * host_redirect: New host\n      * scheme_redirect: http â†’ https\n      * port_redirect: New port\n      * response_code: 301, 302, 303, 307, 308\n\n3) REDIRECT EXAMPLES:\n   ```\n   Redirect 0: HTTP â†’ HTTPS\n   - match.prefix: '/'\n   - redirect:\n     * scheme_redirect: 'https'\n     * response_code: 301 (permanent)\n   \n   Redirect 1: Old API â†’ New API\n   - match.prefix: '/api/v1/'\n   - redirect:\n     * path_redirect: '/api/v2/'\n     * response_code: 301\n   \n   Redirect 2: Domain change\n   - match.prefix: '/'\n   - redirect:\n     * host_redirect: 'new-domain.com'\n     * response_code: 301\n   \n   Redirect 3: Add www\n   - match.prefix: '/'\n   - redirect:\n     * host_redirect: 'www.example.com'\n     * response_code: 301\n   ```\n\n4) REDIRECT RESPONSE CODES:\n   - **301**: Permanent redirect (browser caches)\n   - **302**: Temporary redirect (default)\n   - **303**: See Other (POST â†’ GET redirect)\n   - **307**: Temporary redirect (method preserved)\n   - **308**: Permanent redirect (method preserved)\n\n5) PREFIX REWRITE:\n   - Change URL path before going to upstream\n   - Client unaware, only upstream sees different path\n   \n   a) Select 'prefix_rewrite' tag under route 'route'\n   b) String input: New prefix\n   c) Example:\n      * match.prefix: '/api/'\n      * prefix_rewrite: '/v2/api/'\n      * Client: /api/users\n      * Upstream: /v2/api/users\n\n6) REGEX REWRITE:\n   - Change path with regex\n   - More flexible pattern matching\n   \n   a) Select 'regex_rewrite' tag under route 'route'\n   b) Fields:\n      * pattern.regex: Regex pattern\n      * substitution: New path template\n   c) Example:\n      * pattern.regex: '^/api/v1/(.*)'\n      * substitution: '/v2/\\\\1'\n      * /api/v1/users â†’ /v2/users\n\n7) HOST REWRITE:\n   - Change host header before going to upstream\n   \n   a) Select 'host_rewrite_literal' tag\n   b) String input: New host\n   c) E.g., 'internal-backend.local'\n   \n   OR\n   \n   d) Select 'auto_host_rewrite' tag\n   e) Boolean: true\n   f) Use upstream cluster address as host\n\n8) REWRITE EXAMPLES:\n   ```\n   Route 0: API versioning\n   - match.prefix: '/api/'\n   - route:\n     * cluster: 'backend-api-v2'\n     * prefix_rewrite: '/v2/'\n   Client sees: /api/users\n   Backend receives: /v2/users\n   \n   Route 1: Legacy compatibility\n   - match.prefix: '/old-api/'\n   - route:\n     * cluster: 'new-api'\n     * prefix_rewrite: '/api/v3/'\n   Client sees: /old-api/orders\n   Backend receives: /api/v3/orders\n   \n   Route 2: Internal routing\n   - match.prefix: '/public/'\n   - route:\n     * cluster: 'internal-cluster'\n     * prefix_rewrite: '/internal/'\n     * host_rewrite_literal: 'internal.local'\n   ```\n\n9) REDIRECT + REWRITE TOGETHER:\n   ```\n   Virtual Host: old-domain.com\n   Route 0: Domain + HTTPS redirect\n   - match.prefix: '/'\n   - redirect:\n     * scheme_redirect: 'https'\n     * host_redirect: 'new-domain.com'\n     * response_code: 301\n   \n   Virtual Host: new-domain.com\n   Route 0: API rewrite\n   - match.prefix: '/api/'\n   - route:\n     * cluster: 'backend'\n     * prefix_rewrite: '/v2/api/'\n   ```\n\n10) BEST PRACTICES:\n    - HTTP â†’ HTTPS: Use 301 redirect\n    - API versioning: Use prefix_rewrite (client unaware)\n    - Domain migration: 301 redirect (SEO)\n    - Regex rewrite: Use carefully (performance)\n    - Host rewrite: For internal domains\n    - Test: Don't create redirect loop!"}
{"resource":"Route","category":"weighted_clusters","instruction":"How to do traffic distribution with weighted clusters?","output":"WEIGHTED CLUSTERS:\n\n1) WHAT IS WEIGHTED CLUSTER:\n   - Distribute traffic to multiple clusters by percentage\n   - Use case: Canary deployment, A/B testing, blue-green deployment\n   - E.g., 90% production, 10% canary\n\n2) WEIGHTED CLUSTER CONFIGURATION:\n   a) Select 'route' tag in route tab\n   b) Select 'weighted_clusters' tag under 'Route' card\n   c) 'Weighted Clusters' card opens\n   d) Click blue '+' button\n   e) Cluster tab created\n\n3) CLUSTER WEIGHT FIELDS:\n   a) **name**: Cluster name (required)\n      - E.g., 'backend-v1', 'backend-v2-canary'\n   \n   b) **weight**: Weight (required)\n      - Number (e.g., 90, 10)\n      - Percentage calculated based on total weight\n      - E.g., weight=90 + weight=10 = 100 â†’ 90% and 10%\n   \n   c) **request_headers_to_add**: Header specific to this cluster\n   d) **response_headers_to_add**: Response header\n\n4) WEIGHTED CLUSTER ADDING STEPS:\n   a) Cluster 0 tab:\n      * name: 'backend-production'\n      * weight: 90\n   \n   b) Add new cluster with '+'\n   \n   c) Cluster 1 tab:\n      * name: 'backend-canary'\n      * weight: 10\n   \n   d) Total weight: 100 (90% + 10%)\n\n5) CANARY DEPLOYMENT EXAMPLE:\n   ```\n   Route: API endpoint\n   - match.prefix: '/api/'\n   - route.weighted_clusters:\n     * Cluster 0:\n       - name: 'backend-v1'\n       - weight: 95 (95% production)\n     * Cluster 1:\n       - name: 'backend-v2-canary'\n       - weight: 5 (5% canary test)\n   \n   For 100 requests:\n   - 95 requests â†’ backend-v1\n   - 5 requests â†’ backend-v2-canary\n   ```\n\n6) A/B TESTING EXAMPLE:\n   ```\n   Route: Homepage\n   - match.path: '/'\n   - route.weighted_clusters:\n     * Cluster 0:\n       - name: 'frontend-version-a'\n       - weight: 50 (50% version A)\n       - response_headers_to_add:\n         * x-ab-version: 'A'\n     * Cluster 1:\n       - name: 'frontend-version-b'\n       - weight: 50 (50% version B)\n       - response_headers_to_add:\n         * x-ab-version: 'B'\n   ```\n\n7) BLUE-GREEN DEPLOYMENT:\n   ```\n   Stage 1: All traffic to blue\n   - blue: weight=100\n   - green: weight=0\n   \n   Stage 2: Shift 10% to green\n   - blue: weight=90\n   - green: weight=10\n   \n   Stage 3: 50%-50%\n   - blue: weight=50\n   - green: weight=50\n   \n   Stage 4: All traffic to green\n   - blue: weight=0\n   - green: weight=100\n   \n   If rollback needed:\n   - green: weight=0 (quick rollback)\n   - blue: weight=100\n   ```\n\n8) WEIGHT CALCULATION:\n   ```\n   Total weight = Sum of all weights\n   Cluster percentage = (cluster weight / total weight) * 100\n   \n   Example:\n   - Cluster A: weight=30\n   - Cluster B: weight=60\n   - Cluster C: weight=10\n   Total: 100\n   \n   Percentages:\n   - A: (30/100) * 100 = 30%\n   - B: (60/100) * 100 = 60%\n   - C: (10/100) * 100 = 10%\n   ```\n\n9) CLUSTER-SPECIFIC HEADERS:\n   - Add different header for each cluster\n   - For tracking and debugging\n   ```\n   Cluster 0 (production):\n   - response_headers_to_add:\n     * x-backend-version: 'v1.0'\n     * x-cluster-name: 'production'\n   \n   Cluster 1 (canary):\n   - response_headers_to_add:\n     * x-backend-version: 'v2.0-beta'\n     * x-cluster-name: 'canary'\n   ```\n\n10) CHANGING WEIGHT STEPS:\n    a) Open route resource (edit mode)\n    b) Go to relevant route tab\n    c) Open cluster tabs under weighted_clusters\n    d) Change weight values:\n       * Cluster 0: 95 â†’ 85 (increase canary)\n       * Cluster 1: 5 â†’ 15\n    e) Press 'Update' button\n    f) Snapshot update job starts\n    g) Listener receives new weights (zero-downtime)\n    h) New requests routed with new distribution\n\n11) METRICS:\n    ```\n    Separate metrics for each cluster:\n    - cluster.backend-v1.upstream_rq_total\n    - cluster.backend-v2-canary.upstream_rq_total\n    \n    Compare canary performance:\n    - cluster.backend-v1.upstream_rq_time (latency)\n    - cluster.backend-v2-canary.upstream_rq_time\n    \n    Error rate:\n    - cluster.backend-v1.upstream_rq_5xx\n    - cluster.backend-v2-canary.upstream_rq_5xx\n    ```"}
{"resource":"Route","category":"cors","instruction":"How to configure CORS at route level?","output":"ROUTE CORS CONFIGURATION:\n\n1) WHAT IS CORS:\n   - Cross-Origin Resource Sharing\n   - Browser security mechanism\n   - Required for API calls from different domain\n   - Preflight request (OPTIONS) and CORS headers\n\n2) ADDING CORS STEPS:\n   a) Select 'route' tag in route tab\n   b) Select 'cors' tag under 'Route' card\n   c) 'CORS' card opens\n   d) Horizontal tags appear\n\n3) CORS BASIC FIELDS:\n   \n   a) **allow_origin_string_match**: Allowed origins (required)\n      - Add origin pattern with '+'\n      - Pattern types:\n        * exact: 'https://app.example.com'\n        * prefix: 'https://'\n        * suffix: '.example.com'\n        * safe_regex: '.*\\\\.example\\\\.com'\n      - Wildcard: '*' (all origins, not secure)\n   \n   b) **allow_methods**: Allowed HTTP methods\n      - String array: 'GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'\n   \n   c) **allow_headers**: Allowed request headers\n      - String array: 'content-type', 'authorization', 'x-api-key'\n   \n   d) **expose_headers**: Response headers to expose to client\n      - String array: 'x-request-id', 'x-ratelimit-remaining'\n   \n   e) **allow_credentials**: Allow sending credentials\n      - Boolean: true/false\n      - For cookie, authorization header\n   \n   f) **max_age**: Preflight cache duration\n      - Duration: '86400s' (24 hours)\n\n4) CORS UI CONFIGURATION:\n   a) Select 'allow_origin_string_match' tag\n   b) Add origin pattern with '+'\n   c) Select pattern type: exact, prefix, suffix, safe_regex\n   d) Enter value: 'https://app.example.com'\n   \n   e) Select 'allow_methods' tag\n   f) Add method with '+': 'GET', 'POST', 'OPTIONS'\n   \n   g) Select 'allow_headers' tag\n   h) Add header with '+': 'content-type', 'authorization'\n   \n   i) Select 'expose_headers' tag\n   j) Add expose header with '+': 'x-request-id'\n   \n   k) Select 'allow_credentials' tag\n   l) Boolean toggle: true\n   \n   m) Select 'max_age' tag\n   n) Duration input: '86400s'\n\n5) SIMPLE CORS EXAMPLE:\n   ```\n   CORS:\n   - allow_origin_string_match:\n     * Pattern 0:\n       - exact: 'https://app.example.com'\n   - allow_methods: ['GET', 'POST', 'OPTIONS']\n   - allow_headers: ['content-type', 'authorization']\n   - allow_credentials: true\n   - max_age: '86400s'\n   ```\n\n6) MULTIPLE ORIGIN EXAMPLE:\n   ```\n   CORS:\n   - allow_origin_string_match:\n     * Pattern 0:\n       - exact: 'https://app.example.com'\n     * Pattern 1:\n       - exact: 'https://admin.example.com'\n     * Pattern 2:\n       - suffix: '.test.example.com'\n   - allow_methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS']\n   - allow_headers: ['*']\n   - expose_headers: ['x-request-id', 'x-ratelimit-remaining']\n   - allow_credentials: true\n   ```\n\n7) WILDCARD ORIGIN (DEVELOPMENT):\n   ```\n   For development environment:\n   - allow_origin_string_match:\n     * Pattern 0:\n       - safe_regex:\n         * regex: '.*'\n   - allow_methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS']\n   - allow_headers: ['*']\n   - allow_credentials: false (cannot use true with wildcard)\n   ```\n\n8) PRODUCTION CORS:\n   ```\n   Secure production settings:\n   - allow_origin_string_match:\n     * Pattern 0: exact: 'https://app.example.com'\n     * Pattern 1: exact: 'https://www.example.com'\n   - allow_methods: ['GET', 'POST', 'PUT', 'DELETE']\n   - allow_headers:\n     * 'content-type'\n     * 'authorization'\n     * 'x-api-key'\n   - expose_headers:\n     * 'x-request-id'\n     * 'x-ratelimit-remaining'\n     * 'x-ratelimit-reset'\n   - allow_credentials: true\n   - max_age: '86400s' (24 hour cache)\n   ```\n\n9) CORS PREFLIGHT:\n   - Browser automatically sends OPTIONS request\n   - Envoy checks CORS policy\n   - If allowed:\n     * Returns 204 No Content\n     * Adds CORS headers:\n       - access-control-allow-origin\n       - access-control-allow-methods\n       - access-control-allow-headers\n       - access-control-max-age\n   - Then actual request (GET, POST etc.)\n\n10) CORS DEBUGGING:\n    - CORS error in browser console:\n      * \"No 'Access-Control-Allow-Origin' header\"\n      * Add allow_origin_string_match\n    \n    - \"Method not allowed\":\n      * Add to allow_methods\n    \n    - \"Header not allowed\":\n      * Add to allow_headers\n    \n    - \"Credentials not allowed\":\n      * allow_credentials: true\n    \n    - Go to Logs page:\n      * View OPTIONS requests\n      * Check CORS headers"}
{"resource":"Endpoint","category":"basics","instruction":"What is an Endpoint resource in Envoy and how do I create one in Elchi?","output":"ENDPOINT RESOURCE OVERVIEW:\n\n**What is an Endpoint (ClusterLoadAssignment)?**\n- Defines the actual backend servers (IP:port) for a cluster\n- Specifies where Envoy should forward traffic\n- Includes health status, weight, and locality information\n- Used by EDS (Endpoint Discovery Service) clusters\n\n**Relationship to Cluster:**\n```\nCluster (defines HOW to connect)\n  â†“\nEndpoint (defines WHERE to connect)\n  â†“\nBackend Servers (actual applications)\n```\n\n---\n\n**CREATING AN ENDPOINT:**\n\n**STEP 1: NAVIGATE TO ENDPOINTS**\n\n1) Click 'Endpoint' from the left menu under 'RESOURCES'\n2) The Endpoints page opens showing existing endpoint configurations\n\n**STEP 2: CREATE NEW ENDPOINT**\n\n1) Click the blue '+' button at the top\n2) The endpoint creation page opens\n3) You'll see the left anchor menu with available fields\n\n---\n\n**STEP 3: SET CLUSTER NAME (REQUIRED)**\n\n1) Click 'cluster_name' from the left anchor menu\n2) Enter the name of the cluster this endpoint belongs to\n   - **IMPORTANT**: Must match an existing EDS cluster name\n   - Example: \"backend-api-cluster\"\n3) This links the endpoint to the cluster\n\n**Note:** cluster_name cannot be changed after creation (unchangeable field)\n\n---\n\n**STEP 4: CONFIGURE ENDPOINTS**\n\n1) Click 'endpoints' from the left anchor menu\n2) The Endpoints card appears with tabs\n3) Each tab represents a **locality** (group of endpoints in same region/zone)\n\n**Initial State:**\n- One tab: \"Endpoint: 0\"\n- Click the '+' icon to add more localities\n\n---\n\n**STEP 5: CONFIGURE LOCALITY (OPTIONAL)**\n\nFor each endpoint tab:\n\n1) Click 'locality' from horizontal tags\n2) The Locality card appears\n3) Configure geographic location:\n\n**Fields:**\n- **region**: Geographic region (e.g., \"us-east\")\n- **zone**: Availability zone (e.g., \"us-east-1a\")\n- **sub_zone**: Sub-zone (e.g., \"subnet-1\")\n\n**Use Case:**\n- Locality-aware load balancing\n- Route traffic to nearest endpoints\n- Failover to other regions if local endpoints down\n\n**Example:**\n```\nLocality 1:\n  region: \"us-east\"\n  zone: \"us-east-1a\"\n  \nLocality 2:\n  region: \"us-west\"\n  zone: \"us-west-2a\"\n```\n\n---\n\n**STEP 6: ADD LB ENDPOINTS (BACKEND SERVERS)**\n\n1) Click 'lb_endpoints' from horizontal tags\n2) A drawer/modal opens on the right\n3) This is where you add actual backend server addresses\n\n**In the LB Endpoints drawer:**\n\n1) Click the blue '+' button to add an endpoint\n2) A new endpoint entry appears\n3) Click 'endpoint' tag to expand\n4) Click 'address' â†’ 'socket_address'\n\n**Configure Socket Address:**\n- **address**: IP address or hostname\n  - Example: \"10.0.1.5\" or \"backend-1.example.com\"\n- **port_value**: Port number\n  - Example: 8080, 3000, 9000\n\n**Example Endpoint:**\n```\naddress: \"10.0.1.5\"\nport_value: 8080\n```\n\n**Add Multiple Endpoints:**\n- Click '+' button again for each backend server\n- Example:\n  - Endpoint 1: 10.0.1.5:8080\n  - Endpoint 2: 10.0.1.6:8080\n  - Endpoint 3: 10.0.1.7:8080\n\n---\n\n**STEP 7: CONFIGURE ENDPOINT HEALTH (OPTIONAL)**\n\nFor each lb_endpoint:\n\n1) Click 'health_status' tag\n2) Select from dropdown:\n   - **UNKNOWN**: Health status not determined yet (default)\n   - **HEALTHY**: Endpoint is healthy and serving traffic\n   - **UNHEALTHY**: Endpoint is down, no traffic sent\n   - **DRAINING**: Endpoint being removed, only existing connections\n   - **TIMEOUT**: Health check timed out\n   - **DEGRADED**: Partially healthy, reduced traffic\n\n**When to Set Manually:**\n- Development/testing (force healthy/unhealthy)\n- Manual traffic control\n- **Production**: Let health checks determine status automatically\n\n---\n\n**STEP 8: CONFIGURE LOAD BALANCING WEIGHT (OPTIONAL)**\n\nFor each lb_endpoint:\n\n1) Click 'load_balancing_weight' tag\n2) Enter a weight value (default: 1)\n\n**How Weight Works:**\n- Higher weight = more traffic\n- Example with 3 endpoints:\n  - Endpoint 1: weight 1 (gets 1/4 of traffic)\n  - Endpoint 2: weight 1 (gets 1/4 of traffic)\n  - Endpoint 3: weight 2 (gets 2/4 = 50% of traffic)\n\n**Use Cases:**\n- Canary deployments (new version gets 10% traffic)\n- Weighted load balancing (bigger servers get more traffic)\n- Gradual traffic migration\n\n---\n\n**STEP 9: SAVE ENDPOINT CONFIGURATION**\n\n1) Close the lb_endpoints drawer (X button or click outside)\n2) Click 'Create' button at the top of the page\n3) The endpoint is saved\n\n---\n\n**STEP 10: LINK TO EDS CLUSTER**\n\nFor the endpoint to work:\n\n1) Navigate to 'Cluster' from left menu\n2) Open your cluster (or create one)\n3) Set **type** to **EDS** (Endpoint Discovery Service)\n4) Set **eds_cluster_config**:\n   - **service_name**: Must match the endpoint's cluster_name\n   - Example: \"backend-api-cluster\"\n5) Save the cluster\n\nNow Envoy will:\n1) Connect to Elchi's EDS server\n2) Request endpoints for \"backend-api-cluster\"\n3) Receive the endpoint configuration you created\n4) Load balance traffic to 10.0.1.5:8080, 10.0.1.6:8080, 10.0.1.7:8080\n\n---\n\n**COMPLETE EXAMPLE:**\n\n**Endpoint Configuration:**\n```\ncluster_name: \"backend-api-cluster\"\nendpoints:\n  - locality:\n      region: \"us-east\"\n      zone: \"us-east-1a\"\n    lb_endpoints:\n      - endpoint:\n          address:\n            socket_address:\n              address: \"10.0.1.5\"\n              port_value: 8080\n        health_status: HEALTHY\n        load_balancing_weight: 1\n      - endpoint:\n          address:\n            socket_address:\n              address: \"10.0.1.6\"\n              port_value: 8080\n        health_status: HEALTHY\n        load_balancing_weight: 1\n```\n\n**Cluster Configuration:**\n```\nname: \"backend-api-cluster\"\ntype: EDS\neds_cluster_config:\n  service_name: \"backend-api-cluster\"\n```\n\n---\n\n**TESTING:**\n\nAfter deployment:\n\n```bash\n# Check endpoint is loaded in Envoy\ncurl localhost:9901/clusters | grep backend-api-cluster\n```\n\nOutput:\n```\nbackend-api-cluster::10.0.1.5:8080::health_flags::healthy\nbackend-api-cluster::10.0.1.6:8080::health_flags::healthy\n```\n\nMake requests:\n```bash\ncurl http://your-envoy-ip/api\n```\n\nTraffic is load balanced to 10.0.1.5 and 10.0.1.6.\n\n---\n\n**KEY CONCEPTS:**\n\nâœ… **cluster_name** must match EDS cluster's service_name\nâœ… **Locality** is optional but useful for geo-aware load balancing\nâœ… **lb_endpoints** are the actual backend IPs/ports\nâœ… **health_status** can be manual or automatic (via health checks)\nâœ… **load_balancing_weight** controls traffic distribution"}
{"resource":"Endpoint","category":"discovery","instruction":"How does automatic endpoint discovery work with Kubernetes integration?","output":"AUTOMATIC ENDPOINT DISCOVERY WITH KUBERNETES:\n\n**What is Kubernetes Discovery?**\n- Elchi can automatically discover Kubernetes Services, Deployments, StatefulSets\n- Automatically populates Endpoint configurations\n- No manual IP address management needed\n- Endpoints update automatically when pods scale up/down\n\n---\n\n**ARCHITECTURE:**\n\n```\nKubernetes Cluster\n  â†“ (watches)\nElchi Discovery Service\n  â†“ (creates/updates)\nEndpoint Resources\n  â†“ (EDS protocol)\nEnvoy Instances\n  â†“ (load balance to)\nKubernetes Pods\n```\n\n---\n\n**STEP 1: CONFIGURE KUBERNETES DISCOVERY**\n\n1) Navigate to 'Discovery' from the left menu under 'INFRASTRUCTURE'\n2) Click the blue '+' button\n3) Configure Kubernetes connection:\n\n**Fields:**\n- **name**: Discovery configuration name (e.g., \"k8s-prod-cluster\")\n- **kubeconfig**: Kubernetes configuration\n  - **Option A**: Upload kubeconfig file\n  - **Option B**: Use in-cluster config (if Elchi runs in K8s)\n- **namespace**: Target namespace\n  - Specific namespace: \"production\"\n  - All namespaces: \"\" (empty)\n- **resource_type**: What to discover\n  - Service\n  - Deployment\n  - StatefulSet\n\n4) Save the discovery configuration\n\n---\n\n**STEP 2: DISCOVERY AUTO-CREATES ENDPOINTS**\n\nOnce discovery is active:\n\n1) Elchi watches Kubernetes API\n2) Discovers Services/Deployments/StatefulSets\n3) **Automatically creates Endpoint resources**\n4) Populates lb_endpoints with pod IPs\n\n**Example:**\n\nKubernetes Service:\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: backend-api\n  namespace: production\nspec:\n  selector:\n    app: backend\n  ports:\n    - port: 8080\n      targetPort: 8080\n```\n\nPods:\n```\nbackend-api-pod-1: 10.244.0.5:8080\nbackend-api-pod-2: 10.244.0.6:8080\nbackend-api-pod-3: 10.244.0.7:8080\n```\n\nElchi Auto-Creates Endpoint:\n```\ncluster_name: \"production.backend-api\"\nendpoints:\n  - lb_endpoints:\n      - endpoint:\n          address:\n            socket_address:\n              address: \"10.244.0.5\"\n              port_value: 8080\n      - endpoint:\n          address:\n            socket_address:\n              address: \"10.244.0.6\"\n              port_value: 8080\n      - endpoint:\n          address:\n            socket_address:\n              address: \"10.244.0.7\"\n              port_value: 8080\n```\n\n---\n\n**STEP 3: VIEWING AUTO-DISCOVERED ENDPOINTS**\n\n1) Navigate to 'Endpoint' from left menu\n2) You'll see endpoints with auto-generated names\n3) Naming convention:\n   - **Service**: `<namespace>.<service-name>`\n   - **Deployment**: `<namespace>.<deployment-name>`\n   - **StatefulSet**: `<namespace>.<statefulset-name>`\n\n**Examples:**\n- `production.backend-api`\n- `staging.frontend`\n- `default.redis-cluster`\n\n---\n\n**STEP 4: WARNING - DO NOT MANUALLY EDIT**\n\nWhen you open an auto-discovered endpoint:\n\n**You'll see an info alert:**\n```\nAutomatic Discovery Enabled\n\n1 cluster(s) configured for automatic discovery.\nPlease do not manually edit Lb Endpoints and Locality configurations - \nthey will be automatically populated from the discovered services.\n```\n\n**Why?**\n- Manual changes will be overwritten\n- Discovery sync happens every 30-60 seconds\n- Next sync will restore auto-discovered values\n\n**What you CAN do:**\n- View the endpoints (read-only)\n- Monitor health status\n- Check which pods are included\n\n---\n\n**STEP 5: LINK CLUSTER TO AUTO-DISCOVERED ENDPOINTS**\n\n1) Create or edit a Cluster\n2) Set **type** to **EDS**\n3) Set **eds_cluster_config.service_name**:\n   - Use the auto-generated name: `production.backend-api`\n4) Save cluster\n\nEnvoy will:\n1) Request endpoints for `production.backend-api`\n2) Get the auto-discovered pod IPs\n3) Load balance to them\n4) **Automatically update** when pods change\n\n---\n\n**AUTOMATIC UPDATES:**\n\n**Scenario 1: Deployment Scales Up**\n\nKubernetes:\n```bash\nkubectl scale deployment backend-api --replicas=5\n```\n\nWhat happens:\n1) New pods created: 10.244.0.8, 10.244.0.9\n2) Elchi discovery detects new pods (within 30-60 seconds)\n3) Updates Endpoint resource (adds new IPs)\n4) Pushes update to Envoy via EDS\n5) Envoy adds new endpoints to load balancer\n6) **Zero downtime** - traffic starts flowing to new pods\n\n**Scenario 2: Pod Crashes**\n\nKubernetes:\n```\nPod 10.244.0.6 crashes\nKubernetes creates replacement: 10.244.0.10\n```\n\nWhat happens:\n1) Elchi discovery detects change\n2) Removes 10.244.0.6 from endpoint\n3) Adds 10.244.0.10 to endpoint\n4) Pushes update to Envoy\n5) Envoy stops sending traffic to .6, starts sending to .10\n6) **Automatic failover**\n\n**Scenario 3: Service Deleted**\n\nKubernetes:\n```bash\nkubectl delete service backend-api\n```\n\nWhat happens:\n1) Elchi discovery detects deletion\n2) Marks endpoint as deleted (or removes it)\n3) Envoy stops routing to that cluster\n4) Returns 503 for requests to that cluster\n\n---\n\n**DISCOVERY SYNC INTERVAL:**\n\nElchi checks Kubernetes API:\n- Default: Every 30 seconds\n- Configurable in discovery settings\n- Balance:\n  - **Faster** (15s): Quick updates, more API calls\n  - **Slower** (60s): Less API load, delayed updates\n\n---\n\n**MULTI-NAMESPACE DISCOVERY:**\n\nDiscover services across namespaces:\n\n**Option 1: Multiple Discovery Configs**\n```\nDiscovery 1: namespace=\"production\"\nDiscovery 2: namespace=\"staging\"\nDiscovery 3: namespace=\"default\"\n```\n\nResults in endpoints:\n```\nproduction.backend-api\nstaging.backend-api\ndefault.redis\n```\n\n**Option 2: All Namespaces**\n```\nDiscovery: namespace=\"\" (empty = all namespaces)\n```\n\nResults in endpoints for all services in all namespaces.\n\n---\n\n**FILTERING DISCOVERED SERVICES:**\n\nIn discovery configuration:\n\n**Label Selectors:**\n- Only discover services with specific labels\n- Example: `app=backend,tier=api`\n- Avoids discovering internal/system services\n\n**Annotation Filters:**\n- Only services with annotation: `elchi.io/discover: \"true\"`\n- Opt-in discovery model\n\n---\n\n**LOCALITY FROM KUBERNETES:**\n\nElchi can populate locality from Kubernetes node labels:\n\n**Kubernetes Node:**\n```yaml\nmetadata:\n  labels:\n    topology.kubernetes.io/region: us-east\n    topology.kubernetes.io/zone: us-east-1a\n```\n\n**Elchi Endpoint:**\n```\nlocality:\n  region: \"us-east\"\n  zone: \"us-east-1a\"\n```\n\nUsed for:\n- Locality-aware load balancing\n- Route to pods in same zone first\n- Failover to other zones if needed\n\n---\n\n**HEADLESS SERVICES:**\n\nFor StatefulSets with headless services:\n\n**Kubernetes:**\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-cluster\nspec:\n  clusterIP: None  # Headless\n  selector:\n    app: redis\n```\n\n**Elchi:**\n- Discovers individual pod IPs (not service ClusterIP)\n- Creates endpoint for each pod\n- Useful for stateful applications (Redis, Cassandra, etc.)\n\n---\n\n**TROUBLESHOOTING DISCOVERY:**\n\n**Problem: Endpoints not auto-created**\n\nCheck:\n1) Discovery configuration is active (not disabled)\n2) Kubeconfig is valid\n3) Elchi has permissions:\n   ```yaml\n   apiVersion: rbac.authorization.k8s.io/v1\n   kind: ClusterRole\n   metadata:\n     name: elchi-discovery\n   rules:\n     - apiGroups: [\"\"]\n       resources: [\"services\", \"endpoints\"]\n       verbs: [\"get\", \"list\", \"watch\"]\n     - apiGroups: [\"apps\"]\n       resources: [\"deployments\", \"statefulsets\"]\n       verbs: [\"get\", \"list\", \"watch\"]\n   ```\n4) Namespace exists and has services\n5) Check Elchi discovery logs\n\n**Problem: Endpoints have wrong IPs**\n\nCause: Service selector doesn't match pods\n\nFix:\n1) Check Kubernetes service selector\n2) Ensure pods have matching labels\n3) Verify with: `kubectl get endpoints <service-name>`\n\n**Problem: Endpoints not updating when pods scale**\n\nCause: Discovery sync not running\n\nFix:\n1) Check discovery status (should show last sync time)\n2) Restart Elchi discovery service\n3) Verify Kubernetes API is reachable\n\n---\n\n**MANUAL VS AUTOMATIC ENDPOINTS:**\n\n**When to use Manual:**\n- Non-Kubernetes backends (VMs, external services)\n- Static IP addresses\n- Third-party APIs\n- Testing with specific IPs\n\n**When to use Automatic (Discovery):**\n- Kubernetes Services/Deployments/StatefulSets\n- Dynamic pod scaling\n- Automatic failover\n- Cloud-native applications\n\n---\n\n**BEST PRACTICES:**\n\nâœ… **Use discovery for Kubernetes workloads**\n- Automatic updates\n- No manual IP management\n\nâœ… **Set up RBAC correctly**\n- Minimal permissions (read-only)\n- Namespace-scoped if possible\n\nâœ… **Monitor discovery sync**\n- Alert if sync fails\n- Check last sync timestamp\n\nâœ… **Label your services**\n- Use label selectors to filter\n- Avoid discovering system services\n\nâœ… **Test failover**\n- Delete a pod, verify Envoy updates\n- Scale deployment, verify new endpoints added\n\nâš ï¸ **Never manually edit auto-discovered endpoints**\n- Changes will be overwritten\n- Use discovery configuration to control behavior"}
{"resource":"Endpoint","category":"locality","instruction":"What is locality-based load balancing and how do I configure it with endpoints?","output":"LOCALITY-BASED LOAD BALANCING:\n\n**What is Locality?**\n- Geographic or logical location of endpoints\n- Defined by: region, zone, sub_zone\n- Used for intelligent traffic routing\n- Reduces latency and improves reliability\n\n**Why Use Locality-Based LB?**\n- **Latency**: Route to nearest endpoints first\n- **Cost**: Keep traffic within same cloud region (avoid data transfer fees)\n- **Reliability**: Failover to other zones if local endpoints down\n- **Compliance**: Keep data in specific geographic regions\n\n---\n\n**LOCALITY HIERARCHY:**\n\n```\nRegion (broadest)\n  â””â”€ Zone (middle)\n      â””â”€ Sub-Zone (most specific)\n```\n\n**Examples:**\n\n**AWS:**\n```\nregion: \"us-east-1\"\nzone: \"us-east-1a\"\nsub_zone: \"subnet-abc123\"\n```\n\n**GCP:**\n```\nregion: \"us-central1\"\nzone: \"us-central1-a\"\nsub_zone: \"rack-1\"\n```\n\n**On-Premise:**\n```\nregion: \"datacenter-east\"\nzone: \"building-a\"\nsub_zone: \"rack-5\"\n```\n\n---\n\n**CONFIGURING LOCALITY IN ENDPOINTS:**\n\n**STEP 1: CREATE ENDPOINT WITH MULTIPLE LOCALITIES**\n\n1) Navigate to 'Endpoint' â†’ Create new endpoint\n2) Set cluster_name (e.g., \"backend-api-cluster\")\n3) Click 'endpoints' from left anchor\n\n**STEP 2: CONFIGURE FIRST LOCALITY (US-EAST)**\n\n1) In \"Endpoint: 0\" tab\n2) Click 'locality' horizontal tag\n3) Configure:\n   ```\n   region: \"us-east\"\n   zone: \"us-east-1a\"\n   ```\n\n4) Click 'lb_endpoints' horizontal tag\n5) Add backend servers in us-east-1a:\n   ```\n   10.0.1.5:8080  (us-east-1a)\n   10.0.1.6:8080  (us-east-1a)\n   ```\n\n**STEP 3: ADD SECOND LOCALITY (US-WEST)**\n\n1) Click the '+' icon on tabs to add \"Endpoint: 1\"\n2) Click 'locality' tag\n3) Configure:\n   ```\n   region: \"us-west\"\n   zone: \"us-west-2a\"\n   ```\n\n4) Click 'lb_endpoints' tag\n5) Add backend servers in us-west-2a:\n   ```\n   10.1.1.5:8080  (us-west-2a)\n   10.1.1.6:8080  (us-west-2a)\n   ```\n\n**STEP 4: ADD THIRD LOCALITY (EU-WEST) - OPTIONAL**\n\n1) Add \"Endpoint: 2\" tab\n2) Configure:\n   ```\n   region: \"eu-west\"\n   zone: \"eu-west-1a\"\n   ```\n\n3) Add EU backend servers:\n   ```\n   10.2.1.5:8080  (eu-west-1a)\n   10.2.1.6:8080  (eu-west-1a)\n   ```\n\n**STEP 5: SAVE CONFIGURATION**\n\nYour endpoint now has 3 localities:\n```\nLocality 1: us-east (us-east-1a) â†’ 2 endpoints\nLocality 2: us-west (us-west-2a) â†’ 2 endpoints\nLocality 3: eu-west (eu-west-1a) â†’ 2 endpoints\n```\n\n---\n\n**ENVOY INSTANCE LOCALITY:**\n\nFor locality-based routing to work, **Envoy must know its own locality**.\n\n**Configure in Bootstrap:**\n\n1) Navigate to 'Bootstrap' â†’ Your bootstrap config\n2) Click 'node' from left anchor\n3) Click 'locality' horizontal tag\n4) Set Envoy's locality:\n\n**Envoy in us-east-1a:**\n```\nregion: \"us-east\"\nzone: \"us-east-1a\"\n```\n\n**Envoy in us-west-2a:**\n```\nregion: \"us-west\"\nzone: \"us-west-2a\"\n```\n\n---\n\n**LOCALITY-BASED ROUTING BEHAVIOR:**\n\n**Scenario 1: Envoy in us-east-1a**\n\nWith healthy endpoints:\n```\nRequest â†’ Envoy (us-east-1a)\n  â†“\nPrefers: us-east-1a endpoints (10.0.1.5, 10.0.1.6)\n  â†“\nFallback: us-west-2a endpoints (if us-east unhealthy)\n  â†“\nLast resort: eu-west-1a endpoints\n```\n\n**Traffic distribution (healthy state):**\n- 100% to us-east-1a (same locality)\n- 0% to us-west-2a\n- 0% to eu-west-1a\n\n**Scenario 2: us-east-1a endpoints all unhealthy**\n\n```\nEnvoy (us-east-1a) detects:\n- 10.0.1.5:8080 â†’ UNHEALTHY\n- 10.0.1.6:8080 â†’ UNHEALTHY\n\nFails over to next locality:\n- us-west-2a: 10.1.1.5, 10.1.1.6 â†’ HEALTHY\n\nTraffic distribution:\n- 0% to us-east-1a (all unhealthy)\n- 100% to us-west-2a (failover)\n- 0% to eu-west-1a (not needed)\n```\n\n**Scenario 3: Partial failure in local locality**\n\n```\nus-east-1a:\n- 10.0.1.5 â†’ HEALTHY\n- 10.0.1.6 â†’ UNHEALTHY\n\nTraffic distribution:\n- 100% to healthy us-east-1a endpoint (10.0.1.5)\n- Spillover to us-west-2a if 10.0.1.5 is overloaded\n```\n\n---\n\n**LOCALITY LOAD BALANCING POLICY:**\n\nConfigure in Cluster:\n\n1) Navigate to 'Cluster' â†’ Your EDS cluster\n2) Click 'common_lb_config' from left anchor\n3) Click 'locality_weighted_lb_config' tag\n\n**Default Behavior (without policy):**\n- 100% to same locality if healthy\n- Failover to other localities if unhealthy\n\n**With Locality Weighted Config:**\n\nSplit traffic across localities:\n\n```\nlocality_weighted_lb_config:\n  locality_weights:\n    us-east: 70\n    us-west: 20\n    eu-west: 10\n```\n\nTraffic distribution (even if all healthy):\n- 70% to us-east endpoints\n- 20% to us-west endpoints\n- 10% to eu-west endpoints\n\n**Use Case:**\n- Gradual migration between regions\n- Active-active multi-region setup\n- Load distribution across datacenters\n\n---\n\n**ZONE-AWARE ROUTING:**\n\n**Within Same Region:**\n\nIf you have multiple zones in same region:\n\n```\nEndpoint Localities:\n- Locality 1: us-east / us-east-1a\n- Locality 2: us-east / us-east-1b\n- Locality 3: us-east / us-east-1c\n\nEnvoy in us-east-1a:\n- Prefers: us-east-1a (same zone)\n- Failover: us-east-1b, us-east-1c (same region, different zones)\n```\n\n**Benefits:**\n- Lower latency (same AZ)\n- Lower cost (same AZ = no cross-AZ fees in AWS)\n- High availability (auto-failover to other AZs)\n\n---\n\n**PRIORITY LEVELS:**\n\nEnvoy locality routing uses priorities:\n\n**Priority 0 (Highest):**\n- Exact match: same region, zone, sub_zone\n\n**Priority 1:**\n- Same region, same zone, different sub_zone\n\n**Priority 2:**\n- Same region, different zone\n\n**Priority 3 (Lowest):**\n- Different region\n\n**Traffic Flow:**\n1) Try Priority 0 endpoints first\n2) If unhealthy, try Priority 1\n3) If still unhealthy, try Priority 2\n4) Last resort: Priority 3\n\n---\n\n**OVERPROVISIONING FACTOR:**\n\nControl when to failover to other localities:\n\n**In Cluster common_lb_config:**\n\n```\noverprovisioning_factor: 140  (default)\n```\n\n**What it means:**\n- Local locality has 10 endpoints\n- Capacity = 10 * 1.4 = 14 requests\n- If local endpoints handling > 14 requests/sec:\n  - Spillover to other localities\n  - Even if local endpoints are healthy\n\n**Use Case:**\n- Prevent overloading local zone\n- Distribute load across zones under high traffic\n\n---\n\n**COMPLETE EXAMPLE:**\n\n**Endpoint Configuration:**\n```\ncluster_name: \"api-cluster\"\nendpoints:\n  # US East Zone\n  - locality:\n      region: \"us-east\"\n      zone: \"us-east-1a\"\n    lb_endpoints:\n      - endpoint:\n          address: { socket_address: { address: \"10.0.1.5\", port_value: 8080 } }\n      - endpoint:\n          address: { socket_address: { address: \"10.0.1.6\", port_value: 8080 } }\n  \n  # US West Zone\n  - locality:\n      region: \"us-west\"\n      zone: \"us-west-2a\"\n    lb_endpoints:\n      - endpoint:\n          address: { socket_address: { address: \"10.1.1.5\", port_value: 8080 } }\n      - endpoint:\n          address: { socket_address: { address: \"10.1.1.6\", port_value: 8080 } }\n```\n\n**Cluster Configuration:**\n```\nname: \"api-cluster\"\ntype: EDS\neds_cluster_config:\n  service_name: \"api-cluster\"\ncommon_lb_config:\n  locality_weighted_lb_config: {}\n  overprovisioning_factor: 140\n```\n\n**Bootstrap (Envoy in us-east-1a):**\n```\nnode:\n  id: \"envoy-us-east-1a-001\"\n  locality:\n    region: \"us-east\"\n    zone: \"us-east-1a\"\n```\n\n**Result:**\n- Requests route to 10.0.1.5, 10.0.1.6 (local zone)\n- If local zone fails â†’ auto-failover to 10.1.1.5, 10.1.1.6 (us-west)\n\n---\n\n**MONITORING LOCALITY ROUTING:**\n\n**Check Envoy stats:**\n```bash\ncurl localhost:9901/stats | grep locality\n```\n\nMetrics:\n```\ncluster.api-cluster.locality.us-east.us-east-1a.upstream_rq_total: 1000\ncluster.api-cluster.locality.us-west.us-west-2a.upstream_rq_total: 0\n```\n\n**Interpretation:**\n- 1000 requests to us-east-1a (local)\n- 0 requests to us-west-2a (no failover needed)\n\n---\n\n**BEST PRACTICES:**\n\nâœ… **Match Envoy locality to its deployment location**\n- Envoy in AWS us-east-1a â†’ node.locality.zone = \"us-east-1a\"\n\nâœ… **Use consistent locality naming**\n- Same naming scheme across all endpoints\n- Avoid typos (\"us-east-1a\" vs \"us-east-1-a\")\n\nâœ… **Deploy Envoy in multiple zones**\n- High availability\n- Each Envoy routes to local zone first\n\nâœ… **Test failover**\n- Mark local endpoints unhealthy\n- Verify traffic fails over to other localities\n\nâœ… **Monitor cross-zone traffic**\n- Alert if significant traffic crosses zones\n- May indicate local zone issues\n\nâš ï¸ **Cost Awareness:**\n- Cross-AZ traffic has fees (AWS, GCP)\n- Cross-region traffic has higher fees\n- Locality routing reduces these costs"}
{"resource":"Endpoint","category":"health_priority","instruction":"How do I configure endpoint priorities and health statuses for advanced load balancing?","output":"ENDPOINT PRIORITIES AND HEALTH STATUSES:\n\n**Advanced Load Balancing Concepts:**\n- **Priority**: Control which endpoints are used first (0 = highest priority)\n- **Health Status**: Override automatic health checks\n- **Load Balancing Weight**: Control traffic distribution within priority level\n- **Combination**: Create sophisticated traffic management strategies\n\n---\n\n**PRIORITY-BASED LOAD BALANCING:**\n\n**What is Priority?**\n- Numeric value (0, 1, 2, ...)\n- Lower number = higher priority\n- **Priority 0**: Primary endpoints (used first)\n- **Priority 1**: Secondary endpoints (used if Priority 0 fails)\n- **Priority 2**: Tertiary endpoints (last resort)\n\n**Use Cases:**\n- Active-passive failover\n- Primary/backup server configuration\n- Cascading failover across datacenters\n\n---\n\n**CONFIGURING PRIORITY:**\n\n**Method 1: Via Locality (Automatic)**\n\nEnvoy automatically assigns priorities based on locality matching:\n\n```\nEnvoy locality: us-east-1a\n\nEndpoint localities:\n- us-east-1a â†’ Priority 0 (exact match)\n- us-east-1b â†’ Priority 1 (same region, different zone)\n- us-west-2a â†’ Priority 2 (different region)\n```\n\n**Method 2: Explicit Priority in Endpoints**\n\nIn the Endpoint configuration:\n\n1) Navigate to 'Endpoint' â†’ Your endpoint\n2) Click 'endpoints' â†’ Select a locality tab\n3) Click 'priority' horizontal tag\n4) Enter priority value:\n   - **0**: Highest priority (primary)\n   - **1**: Second priority (backup)\n   - **2+**: Lower priorities\n\n**Example Configuration:**\n\n```\nEndpoint \"backend-cluster\":\n\nLocality 1 (Priority 0 - Primary):\n  lb_endpoints:\n    - 10.0.1.5:8080\n    - 10.0.1.6:8080\n  priority: 0\n\nLocality 2 (Priority 1 - Backup):\n  lb_endpoints:\n    - 10.0.2.5:8080\n    - 10.0.2.6:8080\n  priority: 1\n```\n\n**Traffic Behavior:**\n- **Normal**: 100% traffic to Priority 0 (10.0.1.5, 10.0.1.6)\n- **Priority 0 fails**: 100% traffic to Priority 1 (10.0.2.5, 10.0.2.6)\n- **All fail**: 503 errors\n\n---\n\n**HEALTH STATUS CONFIGURATION:**\n\n**Health Status Values:**\n\n1) **UNKNOWN** (default)\n   - Health not yet determined\n   - Envoy will perform health checks\n   - Treated as healthy until proven otherwise\n\n2) **HEALTHY**\n   - Endpoint is healthy and serving traffic\n   - Manually forcing healthy (bypass health checks)\n   - Use case: Testing, overriding health checks\n\n3) **UNHEALTHY**\n   - Endpoint is down, no traffic sent\n   - Manually forcing unhealthy (maintenance mode)\n   - Use case: Draining server for maintenance\n\n4) **DRAINING**\n   - Endpoint being removed gracefully\n   - Only existing connections continue\n   - No new connections accepted\n   - Use case: Graceful shutdown, deployment\n\n5) **TIMEOUT**\n   - Health check timed out\n   - Treated as unhealthy\n   - Usually set automatically by health checker\n\n6) **DEGRADED**\n   - Endpoint partially healthy\n   - Receives reduced traffic\n   - Use case: Overloaded server, partial failure\n\n---\n\n**SETTING HEALTH STATUS:**\n\n**In Endpoint Configuration:**\n\n1) Navigate to 'Endpoint' â†’ Your endpoint\n2) Click 'endpoints' â†’ Select locality\n3) Click 'lb_endpoints' horizontal tag\n4) Expand an endpoint\n5) Click 'health_status' tag\n6) Select from dropdown:\n   - UNKNOWN\n   - HEALTHY\n   - UNHEALTHY\n   - DRAINING\n   - TIMEOUT\n   - DEGRADED\n\n---\n\n**USE CASE 1: ACTIVE-PASSIVE FAILOVER**\n\n**Scenario:**\n- Primary datacenter: us-east\n- Backup datacenter: us-west\n- us-west only used if us-east fails\n\n**Configuration:**\n\n```\nEndpoint:\n  # Primary (Active)\n  - locality:\n      region: \"us-east\"\n    priority: 0\n    lb_endpoints:\n      - endpoint: { address: \"10.0.1.5:8080\" }\n        health_status: HEALTHY\n      - endpoint: { address: \"10.0.1.6:8080\" }\n        health_status: HEALTHY\n  \n  # Backup (Passive)\n  - locality:\n      region: \"us-west\"\n    priority: 1\n    lb_endpoints:\n      - endpoint: { address: \"10.1.1.5:8080\" }\n        health_status: HEALTHY\n      - endpoint: { address: \"10.1.1.6:8080\" }\n        health_status: HEALTHY\n```\n\n**Cluster Configuration:**\n\nEnable priority-based failover:\n\n1) Navigate to 'Cluster'\n2) Click 'common_lb_config'\n3) Configure zone-aware load balancing:\n\n```\ncommon_lb_config:\n  zone_aware_lb_config:\n    routing_enabled:\n      default: 100\n    min_cluster_size: 2\n```\n\n**Traffic Flow:**\n- **Normal**: 100% â†’ Priority 0 (us-east)\n- **us-east 50% healthy**: Still 100% â†’ Priority 0 (if enough capacity)\n- **us-east all unhealthy**: 100% â†’ Priority 1 (us-west)\n\n---\n\n**USE CASE 2: CANARY DEPLOYMENT**\n\n**Scenario:**\n- 90% traffic to stable version (v1)\n- 10% traffic to new version (v2) for testing\n\n**Configuration:**\n\n```\nEndpoint:\n  - priority: 0  # Both in same priority\n    lb_endpoints:\n      # Stable version (v1) - 9 endpoints\n      - endpoint: { address: \"10.0.1.1:8080\" }  # v1\n        load_balancing_weight: 1\n      - endpoint: { address: \"10.0.1.2:8080\" }  # v1\n        load_balancing_weight: 1\n      ... (9 endpoints total for v1)\n      \n      # Canary version (v2) - 1 endpoint\n      - endpoint: { address: \"10.0.2.1:8080\" }  # v2\n        load_balancing_weight: 1\n```\n\n**Result:**\n- 9/10 = 90% traffic to v1\n- 1/10 = 10% traffic to v2\n\n**Alternative with Weight:**\n\n```\nEndpoint:\n  - priority: 0\n    lb_endpoints:\n      # Stable version\n      - endpoint: { address: \"10.0.1.1:8080\" }\n        load_balancing_weight: 90\n      \n      # Canary version\n      - endpoint: { address: \"10.0.2.1:8080\" }\n        load_balancing_weight: 10\n```\n\nSame result: 90% to v1, 10% to v2.\n\n---\n\n**USE CASE 3: GRADUAL SERVER DECOMMISSION**\n\n**Scenario:**\n- Removing server 10.0.1.6 from pool\n- Want existing connections to finish gracefully\n\n**Step-by-Step:**\n\n**Step 1: Mark as DRAINING**\n\n1) Edit endpoint\n2) Find lb_endpoint for 10.0.1.6\n3) Set health_status: **DRAINING**\n4) Save\n\n**What Happens:**\n- Existing connections to 10.0.1.6 continue\n- New connections go to 10.0.1.5 (other healthy endpoint)\n- Connections drain over time (minutes to hours)\n\n**Step 2: Monitor Connections**\n\nCheck Envoy stats:\n```bash\ncurl localhost:9901/stats | grep \"10.0.1.6.*cx_active\"\n```\n\nWait for `cx_active: 0` (no active connections).\n\n**Step 3: Mark as UNHEALTHY**\n\n1) Set health_status: **UNHEALTHY**\n2) Save\n\n**Step 4: Remove Endpoint**\n\n1) Delete the lb_endpoint entry\n2) Save\n\n**Result:** Server decommissioned with zero dropped connections.\n\n---\n\n**USE CASE 4: WEIGHTED LOAD BALANCING**\n\n**Scenario:**\n- 3 servers with different capacities\n- Small: 2 CPU cores\n- Medium: 4 CPU cores\n- Large: 8 CPU cores\n\n**Configuration:**\n\n```\nEndpoint:\n  - lb_endpoints:\n      - endpoint: { address: \"10.0.1.5:8080\" }  # Small\n        load_balancing_weight: 2\n      - endpoint: { address: \"10.0.1.6:8080\" }  # Medium\n        load_balancing_weight: 4\n      - endpoint: { address: \"10.0.1.7:8080\" }  # Large\n        load_balancing_weight: 8\n```\n\n**Traffic Distribution:**\n- Total weight: 2 + 4 + 8 = 14\n- Small: 2/14 = 14% of traffic\n- Medium: 4/14 = 29% of traffic\n- Large: 8/14 = 57% of traffic\n\n**Result:** Traffic proportional to server capacity.\n\n---\n\n**PRIORITY FAILOVER THRESHOLD:**\n\n**In Cluster Configuration:**\n\nControl when to failover to next priority:\n\n```\ncommon_lb_config:\n  healthy_panic_threshold:\n    value: 50  # 50%\n```\n\n**What it means:**\n- If < 50% of Priority 0 endpoints are healthy:\n  - Panic mode: Use Priority 1 endpoints\n- If â‰¥ 50% of Priority 0 endpoints healthy:\n  - Normal mode: Only use Priority 0\n\n**Example:**\n\nPriority 0: 4 endpoints\n- 3 healthy, 1 unhealthy (75% healthy)\n  - Stay in Priority 0 (above 50% threshold)\n- 1 healthy, 3 unhealthy (25% healthy)\n  - Panic: Failover to Priority 1 (below 50% threshold)\n\n---\n\n**MONITORING PRIORITIES AND HEALTH:**\n\n**Check Envoy stats:**\n\n```bash\n# Health status per endpoint\ncurl localhost:9901/clusters | grep backend-cluster\n```\n\nOutput:\n```\nbackend-cluster::10.0.1.5:8080::health_flags::healthy\nbackend-cluster::10.0.1.6:8080::health_flags::/failed_active_hc\nbackend-cluster::10.0.2.5:8080::health_flags::healthy\n```\n\nInterpretation:\n- 10.0.1.5: Healthy\n- 10.0.1.6: Failed health check (unhealthy)\n- 10.0.2.5: Healthy (backup, not used unless Priority 0 fails)\n\n**Priority stats:**\n```bash\ncurl localhost:9901/stats | grep priority\n```\n\nOutput:\n```\ncluster.backend-cluster.priority.0.upstream_rq_total: 1000\ncluster.backend-cluster.priority.1.upstream_rq_total: 0\n```\n\nInterpretation:\n- 1000 requests to Priority 0\n- 0 requests to Priority 1 (no failover occurred)\n\n---\n\n**BEST PRACTICES:**\n\nâœ… **Use priorities for failover, not load distribution**\n- Priority 0: Primary servers\n- Priority 1: Backup/DR servers\n- Use weights within same priority for load distribution\n\nâœ… **DRAINING for graceful shutdowns**\n- Always use DRAINING before removing servers\n- Prevents dropped connections\n\nâœ… **Monitor health status**\n- Alert when endpoints become unhealthy\n- Auto-remediation (restart backend service)\n\nâœ… **Test failover regularly**\n- Mark Priority 0 as unhealthy (testing)\n- Verify traffic fails over to Priority 1\n- Mark back as healthy\n\nâœ… **Document weight ratios**\n- Explain why certain weights chosen\n- Update when server capacity changes\n\nâš ï¸ **Don't over-complicate:**\n- Start simple (equal weights)\n- Add complexity only when needed\n- Monitor actual traffic distribution"}
{"resource":"Endpoint","category":"eds_workflow","instruction":"What is EDS (Endpoint Discovery Service) and how does the complete workflow work from cluster to endpoint to Envoy?","output":"EDS (ENDPOINT DISCOVERY SERVICE) WORKFLOW:\n\n**What is EDS?**\n- Part of Envoy's xDS protocol suite\n- Dynamically delivers endpoint configurations to Envoy at runtime\n- Elchi acts as the EDS server\n- Enables zero-downtime endpoint updates (add/remove servers)\n\n**Why Use EDS?**\n- **Dynamic**: Add/remove backends without restarting Envoy\n- **Centralized**: Manage all endpoints in Elchi UI\n- **Automatic**: Health status updates, auto-scaling, service discovery\n- **Zero Downtime**: Hot-reload endpoints without connection drops\n\n---\n\n**COMPLETE EDS WORKFLOW:**\n\n```\nStep 1: Create Endpoint in Elchi\n  â†“\nStep 2: Configure EDS Cluster\n  â†“\nStep 3: Envoy Startup\n  â†“\nStep 4: EDS Request/Response\n  â†“\nStep 5: Load Balancing\n  â†“\nStep 6: Endpoint Updates (Hot Reload)\n```\n\n---\n\n**STEP 1: CREATE ENDPOINT IN ELCHI**\n\n1) Navigate to 'Endpoint'\n2) Click blue '+' button\n3) Configure:\n\n```\ncluster_name: \"backend-api-cluster\"\nendpoints:\n  - lb_endpoints:\n      - endpoint:\n          address: { socket_address: { address: \"10.0.1.5\", port_value: 8080 } }\n      - endpoint:\n          address: { socket_address: { address: \"10.0.1.6\", port_value: 8080 } }\n```\n\n4) Save endpoint\n\n**What Happens:**\n- Endpoint stored in Elchi database\n- Available for EDS queries\n- Not yet active (no cluster references it)\n\n---\n\n**STEP 2: CONFIGURE EDS CLUSTER**\n\n1) Navigate to 'Cluster'\n2) Create or edit cluster\n3) Configure:\n\n**Cluster Type:**\n- Set **type** to **EDS** (Endpoint Discovery Service)\n\n**EDS Config:**\n- Click 'eds_cluster_config' from left anchor\n- Set **service_name**: Must match endpoint's cluster_name\n  - Example: \"backend-api-cluster\"\n\n**Optional - EDS Source:**\n- Click 'eds_config' to specify EDS server\n- Default: Uses Elchi's built-in EDS server\n- Advanced: Can point to external EDS server\n\n**Full Cluster Config:**\n```\nname: \"backend-api-cluster\"\ntype: EDS\nconnect_timeout: 1s\neds_cluster_config:\n  service_name: \"backend-api-cluster\"\n  eds_config:\n    ads: {}  # Use Elchi's ADS/EDS server\n```\n\n4) Save cluster\n\n---\n\n**STEP 3: ENVOY STARTUP**\n\nWhen Envoy starts:\n\n1) Reads Bootstrap configuration\n2) Sees cluster with type=EDS\n3) Connects to Elchi EDS server (via ADS cluster)\n4) Sends EDS request for \"backend-api-cluster\"\n\n**EDS Request (gRPC):**\n```protobuf\nDiscoveryRequest {\n  type_url: \"type.googleapis.com/envoy.config.endpoint.v3.ClusterLoadAssignment\"\n  resource_names: [\"backend-api-cluster\"]\n  node: {\n    id: \"envoy-instance-1\"\n    locality: { region: \"us-east\", zone: \"us-east-1a\" }\n  }\n}\n```\n\n---\n\n**STEP 4: EDS RESPONSE FROM ELCHI**\n\nElchi receives the request:\n\n1) Looks up endpoint with cluster_name=\"backend-api-cluster\"\n2) Retrieves endpoint configuration from database\n3) Sends EDS response to Envoy\n\n**EDS Response (gRPC):**\n```protobuf\nDiscoveryResponse {\n  version_info: \"1234567890\"\n  type_url: \"type.googleapis.com/envoy.config.endpoint.v3.ClusterLoadAssignment\"\n  resources: [\n    ClusterLoadAssignment {\n      cluster_name: \"backend-api-cluster\"\n      endpoints: [\n        LocalityLbEndpoints {\n          lb_endpoints: [\n            LbEndpoint {\n              endpoint: {\n                address: {\n                  socket_address: { address: \"10.0.1.5\", port_value: 8080 }\n                }\n              }\n              health_status: HEALTHY\n            },\n            LbEndpoint {\n              endpoint: {\n                address: {\n                  socket_address: { address: \"10.0.1.6\", port_value: 8080 }\n                }\n              }\n              health_status: HEALTHY\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}\n```\n\n---\n\n**STEP 5: ENVOY LOADS ENDPOINTS**\n\nEnvoy receives the EDS response:\n\n1) Parses endpoint configuration\n2) Stores endpoints in memory:\n   - 10.0.1.5:8080\n   - 10.0.1.6:8080\n3) Initializes load balancer\n4) Starts health checking (if configured)\n5) Begins routing traffic\n\n**Verify Endpoints Loaded:**\n```bash\ncurl localhost:9901/clusters | grep backend-api-cluster\n```\n\nOutput:\n```\nbackend-api-cluster::10.0.1.5:8080::health_flags::healthy\nbackend-api-cluster::10.0.1.6:8080::health_flags::healthy\n```\n\n---\n\n**STEP 6: TRAFFIC FLOW**\n\nRequest arrives at Envoy:\n\n```\nClient Request\n  â†“\nEnvoy Listener (port 80)\n  â†“\nHTTP Connection Manager\n  â†“\nRoute Match: /api â†’ backend-api-cluster\n  â†“\nCluster: backend-api-cluster\n  â†“\nLoad Balancer: Round Robin\n  â†“\nSelect Endpoint: 10.0.1.5:8080 (first request)\n  â†“\nProxy to Backend\n  â†“\nBackend Response\n  â†“\nClient receives response\n```\n\n**Second Request:**\n- Load balancer selects: 10.0.1.6:8080 (round robin)\n\n**Third Request:**\n- Back to: 10.0.1.5:8080\n\n**Traffic Distribution:**\n- 50% to 10.0.1.5\n- 50% to 10.0.1.6\n\n---\n\n**STEP 7: ENDPOINT UPDATE (HOT RELOAD)**\n\n**Scenario: Add a new backend server**\n\n**In Elchi:**\n\n1) Navigate to Endpoint â†’ \"backend-api-cluster\"\n2) Click 'endpoints' â†’ 'lb_endpoints'\n3) Click blue '+' button\n4) Add third endpoint:\n   ```\n   address: \"10.0.1.7\"\n   port_value: 8080\n   ```\n5) Save endpoint\n\n**What Happens (Automatic):**\n\n1) Elchi detects endpoint change\n2) Increments version_info (1234567890 â†’ 1234567891)\n3) Identifies all Envoy instances subscribed to \"backend-api-cluster\"\n4) Sends EDS update via existing gRPC stream:\n\n```protobuf\nDiscoveryResponse {\n  version_info: \"1234567891\"  # New version\n  resources: [\n    ClusterLoadAssignment {\n      cluster_name: \"backend-api-cluster\"\n      endpoints: [\n        LocalityLbEndpoints {\n          lb_endpoints: [\n            ... (10.0.1.5:8080)\n            ... (10.0.1.6:8080)\n            ... (10.0.1.7:8080)  # NEW!\n          ]\n        }\n      ]\n    }\n  ]\n}\n```\n\n5) Envoy receives update\n6) Compares version (new > old)\n7) Hot-reloads endpoints:\n   - Adds 10.0.1.7:8080 to load balancer\n   - Starts health checking it\n   - Begins sending traffic (within seconds)\n8) Sends ACK to Elchi\n9) **Zero downtime** - existing connections unaffected\n\n**Verify Update:**\n```bash\ncurl localhost:9901/clusters | grep backend-api-cluster\n```\n\nOutput:\n```\nbackend-api-cluster::10.0.1.5:8080::health_flags::healthy\nbackend-api-cluster::10.0.1.6:8080::health_flags::healthy\nbackend-api-cluster::10.0.1.7:8080::health_flags::healthy  # NEW!\n```\n\n**New Traffic Distribution:**\n- 33% to 10.0.1.5\n- 33% to 10.0.1.6\n- 33% to 10.0.1.7\n\n---\n\n**STEP 8: REMOVING AN ENDPOINT**\n\n**Scenario: Remove 10.0.1.6 from pool**\n\n1) Edit endpoint in Elchi\n2) Delete lb_endpoint for 10.0.1.6\n3) Save\n\n**What Happens:**\n\n1) Elchi pushes update (version 1234567892)\n2) Envoy receives:\n   - Only 10.0.1.5 and 10.0.1.7 in response\n   - 10.0.1.6 removed\n3) Envoy gracefully drains 10.0.1.6:\n   - Existing connections finish\n   - No new connections to 10.0.1.6\n4) Load balancer updated:\n   - 50% to 10.0.1.5\n   - 50% to 10.0.1.7\n\n**Result:** Server removed with minimal connection disruption.\n\n---\n\n**EDS VS STATIC ENDPOINTS:**\n\n**Static Endpoints (Old Way):**\n\n```yaml\ncluster:\n  name: \"backend-api-cluster\"\n  type: STATIC\n  load_assignment:\n    endpoints:\n      - lb_endpoints:\n          - endpoint:\n              address: \"10.0.1.5:8080\"\n```\n\n**Cons:**\n- Hardcoded in cluster config\n- Change requires cluster update + Envoy reload\n- Downtime during updates\n- No centralized management\n\n**Dynamic Endpoints (EDS - Modern Way):**\n\n```yaml\ncluster:\n  name: \"backend-api-cluster\"\n  type: EDS\n  eds_cluster_config:\n    service_name: \"backend-api-cluster\"\n```\n\n**Pros:**\nâœ… Zero-downtime updates\nâœ… Centralized in Elchi\nâœ… Hot-reload\nâœ… Automatic with Kubernetes discovery\nâœ… Supports priority, locality, weights\n\n---\n\n**MONITORING EDS:**\n\n**EDS Statistics:**\n```bash\ncurl localhost:9901/stats | grep eds\n```\n\nMetrics:\n- `cluster_manager.eds.update_success`: Successful EDS updates\n- `cluster_manager.eds.update_failure`: Failed EDS updates\n- `cluster_manager.eds.update_time`: Last update timestamp\n\n**Config Dump:**\n```bash\ncurl localhost:9901/config_dump | jq '.configs[] | select(.\"@type\" | contains(\"Endpoint\"))'\n```\n\nShows current endpoint configuration loaded in Envoy.\n\n---\n\n**TROUBLESHOOTING EDS:**\n\n**Problem: Endpoints not loading**\n\nCheck:\n1) Cluster type is **EDS** (not STATIC)\n2) eds_cluster_config.service_name matches endpoint cluster_name\n3) EDS connection healthy:\n   ```bash\n   curl localhost:9901/clusters | grep elchi_eds_cluster\n   ```\n4) Envoy logs:\n   ```bash\n   journalctl -u envoy | grep EDS\n   ```\n\n**Problem: Endpoint update not reflecting**\n\nCheck:\n1) Endpoint saved successfully in Elchi\n2) EDS stream active (not disconnected)\n3) Version incremented (check Elchi)\n4) Wait 10-30 seconds for propagation\n5) Force reload:\n   ```bash\n   systemctl reload envoy\n   ```\n\n**Problem: Wrong endpoints loaded**\n\nCause: service_name mismatch\n\nFix:\n1) Verify cluster's eds_cluster_config.service_name\n2) Verify endpoint's cluster_name\n3) Must match exactly (case-sensitive)\n\n---\n\n**BEST PRACTICES:**\n\nâœ… **Always use EDS in production**\n- Dynamic, zero-downtime updates\n- Required for auto-scaling, service discovery\n\nâœ… **Name endpoints clearly**\n- cluster_name should describe purpose\n- Example: \"production-api-backend\", \"staging-web-frontend\"\n\nâœ… **Monitor EDS updates**\n- Alert on update failures\n- Track update success rate\n\nâœ… **Use Kubernetes discovery**\n- Automatic endpoint management\n- No manual IP updates\n\nâœ… **Test EDS updates in staging first**\n- Add/remove endpoints\n- Verify zero downtime\n- Then apply to production\n\nâš ï¸ **Don't mix STATIC and EDS**\n- Cluster is either STATIC or EDS, not both\n- Choose EDS for almost all use cases"}
{"resource":"Endpoint","category":"policy","instruction":"What is the endpoint policy configuration and how do I use it for advanced traffic control?","output":"ENDPOINT POLICY CONFIGURATION:\n\n**What is Endpoint Policy?**\n- Advanced configuration for endpoint behavior\n- Controls:\n  - Overprovisioning (spillover to other localities)\n  - Endpoint stickiness\n  - Weighted priority load balancing\n- Optional - has sensible defaults\n\n**When to Use:**\n- Fine-tune locality failover behavior\n- Control when traffic spills to backup localities\n- Advanced multi-region setups\n\n---\n\n**CONFIGURING ENDPOINT POLICY:**\n\n**STEP 1: ACCESS POLICY CONFIGURATION**\n\n1) Navigate to 'Endpoint' â†’ Your endpoint\n2) Click 'policy' from left anchor menu\n3) The Policy card appears\n\n**Available Policy Options:**\n- **overprovisioning_factor**\n- **endpoint_stale_after**\n- **weighted_priority_health**\n\n---\n\n**OVERPROVISIONING FACTOR:**\n\n**What It Does:**\n- Controls when to use other localities even if local locality is healthy\n- Prevents overloading local endpoints\n- Allows traffic spillover under high load\n\n**Configuration:**\n\n1) Click 'overprovisioning_factor' tag in policy\n2) Enter a value (percentage)\n   - **Default**: 140 (140%)\n   - **Range**: 100-300 typically\n\n**How It Works:**\n\nWith **overprovisioning_factor: 140**:\n\n```\nLocal locality has 10 endpoints\nCapacity = 10 * 1.4 = 14 \"virtual\" endpoints\n\nIf local endpoints receive > 14 requests simultaneously:\n  â†’ Spillover to other localities\nIf local endpoints receive â‰¤ 14 requests:\n  â†’ Stay in local locality\n```\n\n**Example Scenarios:**\n\n**Scenario A: Low Traffic (overprovisioning_factor: 140)**\n```\nLocal: 10 endpoints\nCapacity: 14 concurrent requests\nCurrent load: 8 requests/sec\n\n8 < 14 â†’ All traffic to local locality\nOther localities: 0% traffic\n```\n\n**Scenario B: High Traffic (overprovisioning_factor: 140)**\n```\nLocal: 10 endpoints\nCapacity: 14 concurrent requests\nCurrent load: 20 requests/sec\n\n20 > 14 â†’ Overflow: 6 requests\nLocal locality: 14 requests (70%)\nOther localities: 6 requests (30%)\n```\n\n**Scenario C: Conservative (overprovisioning_factor: 110)**\n```\nLocal: 10 endpoints\nCapacity: 11 concurrent requests\nCurrent load: 12 requests/sec\n\n12 > 11 â†’ Overflow: 1 request\nSpillover happens sooner (more distributed)\n```\n\n**When to Adjust:**\n\n- **Higher value (160-200)**:\n  - Keep traffic local as much as possible\n  - Minimize cross-zone/region traffic (cost savings)\n  - Local endpoints can handle more load\n\n- **Lower value (110-120)**:\n  - Distribute traffic more evenly across localities\n  - Prevent hotspots\n  - Lower latency per endpoint\n\n---\n\n**ENDPOINT STALE AFTER:**\n\n**What It Does:**\n- Marks endpoints as stale if not updated within time period\n- Used with EDS to detect stale/old endpoint data\n- Automatically removes endpoints that haven't been refreshed\n\n**Configuration:**\n\n1) Click 'endpoint_stale_after' tag in policy\n2) Enter a duration:\n   - Format: \"300s\" (300 seconds = 5 minutes)\n   - Format: \"5m\" (5 minutes)\n   - Format: \"1h\" (1 hour)\n\n**How It Works:**\n\n```\nEndpoint last updated: T=0\nendpoint_stale_after: 5m\n\nT=0: Endpoint is fresh\nT=3m: Endpoint still fresh (< 5m)\nT=6m: Endpoint marked as stale (> 5m)\n  â†’ Removed from load balancer\n  â†’ Waiting for EDS update\n```\n\n**Use Case:**\n\nKubernetes discovery:\n- Pods are discovered via EDS\n- If pod deleted but EDS doesn't update:\n  - After 5m, endpoint marked stale\n  - Removed from rotation\n  - Prevents traffic to dead pods\n\n**Default:**\n- Usually not set (endpoints don't expire)\n- Only use if EDS updates can be delayed\n\n---\n\n**WEIGHTED PRIORITY HEALTH:**\n\n**What It Does:**\n- Enables traffic to multiple priorities simultaneously\n- Distributes traffic across priority levels based on health\n- Alternative to strict priority failover\n\n**Standard Priority Behavior (without weighted):**\n```\nPriority 0: 100% traffic (if any healthy endpoints)\nPriority 1: 0% traffic (only if Priority 0 all unhealthy)\n```\n\n**Weighted Priority Behavior (with weighted_priority_health):**\n```\nPriority 0: 70% healthy â†’ 70% of traffic\nPriority 1: 100% healthy â†’ 30% of traffic\n```\n\n**Configuration:**\n\n1) Click 'weighted_priority_health' tag in policy\n2) Configure:\n\n```\nweighted_priority_health: true\n```\n\n**Example:**\n\n**Endpoints:**\n```\nPriority 0 (Primary):\n  Total: 10 endpoints\n  Healthy: 7 endpoints (70% healthy)\n\nPriority 1 (Backup):\n  Total: 10 endpoints\n  Healthy: 10 endpoints (100% healthy)\n```\n\n**Traffic Distribution:**\n\nWithout weighted_priority_health:\n```\nPriority 0: 100% (all traffic to 7 healthy endpoints)\nPriority 1: 0%\n```\n\nWith weighted_priority_health:\n```\nPriority 0: 70% (proportional to health %)\nPriority 1: 30% (helps with load)\n```\n\n**Benefits:**\n- Prevents overloading partially healthy primary\n- Gradual failover (not binary)\n- Better load distribution\n\n**Use Case:**\n- Primary datacenter degraded (not fully down)\n- Want to use backup capacity to help\n- Avoid overwhelming remaining primary endpoints\n\n---\n\n**COMPLETE POLICY EXAMPLE:**\n\n**Scenario: Multi-Region Setup**\n\nRequirements:\n- Keep traffic local as much as possible (cost)\n- But prevent overload (performance)\n- Gradual failover to backup region\n\n**Endpoint Configuration:**\n\n```\ncluster_name: \"api-cluster\"\n\nendpoints:\n  # Primary Region (us-east)\n  - locality:\n      region: \"us-east\"\n    priority: 0\n    lb_endpoints:\n      - endpoint: { address: \"10.0.1.5:8080\" }\n      - endpoint: { address: \"10.0.1.6:8080\" }\n      ...(10 total)\n  \n  # Backup Region (us-west)\n  - locality:\n      region: \"us-west\"\n    priority: 1\n    lb_endpoints:\n      - endpoint: { address: \"10.1.1.5:8080\" }\n      - endpoint: { address: \"10.1.1.6:8080\" }\n      ...(10 total)\n\npolicy:\n  overprovisioning_factor: 150  # Allow up to 15 concurrent requests per endpoint before spillover\n  endpoint_stale_after: \"10m\"   # Remove stale endpoints after 10 minutes\n  weighted_priority_health: true  # Gradual failover based on health percentage\n```\n\n**Behavior:**\n\n**Normal Load:**\n- All traffic to us-east (Priority 0)\n- us-west idle\n\n**High Load (exceeds 150% capacity):**\n- Most traffic to us-east\n- Spillover to us-west (helps with load)\n\n**Partial Failure (us-east 60% healthy):**\n- 60% traffic to us-east (proportional)\n- 40% traffic to us-west (weighted priority)\n\n**Total Failure (us-east 0% healthy):**\n- 0% traffic to us-east\n- 100% traffic to us-west (full failover)\n\n---\n\n**POLICY IN CLUSTER vs ENDPOINT:**\n\n**Endpoint Policy:**\n- Configured on Endpoint resource\n- Applies to this specific endpoint configuration\n- Overrides cluster defaults\n\n**Cluster Policy (common_lb_config):**\n- Configured on Cluster resource\n- Applies to all endpoints for this cluster\n- Default if endpoint policy not set\n\n**Precedence:**\n```\nEndpoint policy > Cluster policy > Envoy defaults\n```\n\n**Example:**\n\nCluster has:\n```\ncommon_lb_config:\n  zone_aware_lb_config:\n    overprovisioning_factor: 140\n```\n\nEndpoint has:\n```\npolicy:\n  overprovisioning_factor: 160\n```\n\n**Result:** Uses 160 (endpoint policy wins)\n\n---\n\n**MONITORING POLICY EFFECTS:**\n\n**Check if spillover is happening:**\n```bash\ncurl localhost:9901/stats | grep locality\n```\n\nOutput:\n```\ncluster.api-cluster.locality.us-east.*.upstream_rq_total: 700\ncluster.api-cluster.locality.us-west.*.upstream_rq_total: 300\n```\n\nInterpretation:\n- 700 requests to us-east (local)\n- 300 requests to us-west (spillover)\n- Spillover is active (overprovisioning factor exceeded)\n\n**Check priority distribution:**\n```bash\ncurl localhost:9901/stats | grep priority\n```\n\nOutput:\n```\ncluster.api-cluster.priority.0.upstream_rq_total: 600\ncluster.api-cluster.priority.1.upstream_rq_total: 400\n```\n\nInterpretation:\n- Weighted priority is working\n- Traffic split across priorities (not binary)\n\n---\n\n**BEST PRACTICES:**\n\nâœ… **Start with defaults**\n- Only configure policy if you have specific requirements\n- Defaults work well for most use cases\n\nâœ… **Monitor before tuning**\n- Check actual traffic patterns\n- Identify hotspots or overload\n- Then adjust overprovisioning_factor\n\nâœ… **Use weighted_priority_health for gradual failover**\n- Better than binary failover\n- Prevents overload on partial failures\n\nâœ… **Set endpoint_stale_after with dynamic discovery**\n- Protects against stale data\n- Prevents routing to dead endpoints\n\nâœ… **Test policy changes in staging**\n- Simulate high load\n- Verify spillover behavior\n- Then apply to production\n\nâš ï¸ **Don't over-optimize prematurely**\n- Policy tuning is advanced\n- Start simple, add complexity only when needed"}
{"resource":"Secret","category":"basics","instruction":"What are Secrets in Envoy and how do I create a TLS Certificate secret in Elchi?","output":"SECRETS IN ENVOY:\n\nSecrets are sensitive configuration data used by Envoy, primarily for TLS/SSL:\n- TLS certificates and private keys\n- Certificate validation contexts (CA certificates)\n- Session ticket keys\n- Generic secrets for custom use cases\n\n**SECRET TYPES IN ELCHI:**\n\n1) **TLS Certificate** - Server certificates with private keys\n2) **Certificate Validation Context** - CA certificates for client verification\n3) **TLS Session Ticket Keys** - For session resumption\n4) **Generic Secret** - Custom secret data\n\n---\n\n**CREATING A TLS CERTIFICATE SECRET:**\n\n**STEP 1: NAVIGATE TO SECRETS**\n\n1) Click 'Secret' from the left menu under 'RESOURCES'\n2) The Secrets page opens showing existing secrets\n\n**STEP 2: SELECT SECRET TYPE**\n\n1) Click the blue '+' button at the top\n2) A dropdown appears with secret types:\n   - TLS Certificate\n   - Certificate Validation Context\n   - TLS Session Ticket Keys\n   - Generic Secret\n3) Select **'TLS Certificate'**\n\n**STEP 3: BASIC CONFIGURATION**\n\n1) Enter a name for the secret (e.g., \"api-server-cert\")\n2) Select Envoy version from dropdown\n3) Click to open the configuration page\n\n**STEP 4: CONFIGURE CERTIFICATE**\n\nYou'll see a table with certificate entries. Click the blue '+' button to add a certificate.\n\nThe left anchor menu shows available fields:\n- **certificate_chain** (Required)\n- **private_key** (Required)\n- **password** (Optional - for encrypted keys)\n- **ocsp_staple** (Optional)\n- **signed_certificate_timestamp** (Optional)\n- **pkcs12** (Optional - alternative format)\n- **watched_directory** (For file-based certificates)\n\n**STEP 5: ADD CERTIFICATE CHAIN**\n\n1) Click 'certificate_chain' from the left anchor menu\n2) The Certificate Chain card appears\n3) You have two options:\n\n**Option A: Inline Data (Direct paste)**\n- Click 'inline_bytes' or 'inline_string' tag\n- Paste your certificate content:\n  ```\n  -----BEGIN CERTIFICATE-----\n  MIIDXTCCAkWgAwIBAgIJAKZ...\n  -----END CERTIFICATE-----\n  ```\n- Include intermediate certificates if needed (concatenate)\n\n**Option B: File Reference**\n- Click 'filename' tag\n- Enter the file path on the Envoy server:\n  `/etc/ssl/certs/api-server.crt`\n\n**STEP 6: ADD PRIVATE KEY**\n\n1) Click 'private_key' from the left anchor menu\n2) The Private Key card appears\n3) Similar options as certificate:\n\n**Option A: Inline Data**\n- Click 'inline_bytes' or 'inline_string' tag\n- Paste your private key:\n  ```\n  -----BEGIN PRIVATE KEY-----\n  MIIEvQIBADANBgkqhkiG9w0...\n  -----END PRIVATE KEY-----\n  ```\n\n**Option B: File Reference**\n- Click 'filename' tag\n- Enter path: `/etc/ssl/private/api-server.key`\n\n**STEP 7: OPTIONAL - PASSWORD FOR ENCRYPTED KEY**\n\nIf your private key is encrypted:\n1) Click 'password' from the left anchor menu\n2) Click 'inline_string' tag\n3) Enter the password to decrypt the key\n\n**STEP 8: SAVE THE SECRET**\n\n1) Click the 'Create' button at the top\n2) The secret is saved and can now be used in TLS contexts\n\n---\n\n**USING THE SECRET:**\n\nAfter creating the secret, you can reference it in:\n- Downstream TLS Context (for listener TLS)\n- Upstream TLS Context (for backend TLS)\n- Via SDS (Secret Discovery Service) configuration\n\n**BEST PRACTICES:**\n\nâœ… **Security:**\n- Use file references instead of inline for production\n- Store files with restricted permissions (600 for keys)\n- Rotate certificates before expiry\n\nâœ… **Organization:**\n- Use descriptive names (e.g., \"api-prod-2024-cert\")\n- Include expiry date in description\n- Tag secrets by environment\n\nâš ï¸ **IMPORTANT:**\n- Private keys are sensitive - never commit to git\n- Use SDS for zero-downtime certificate rotation\n- Certificate chain must include all intermediates\n- Private key format must match certificate (RSA, ECDSA)"}
{"resource":"TLS","category":"downstream","instruction":"How do I configure Downstream TLS (client-to-Envoy HTTPS) for a listener?","output":"DOWNSTREAM TLS CONFIGURATION:\n\nDownstream TLS secures connections from clients (browsers, apps) to Envoy. This is the \"server-side\" TLS where Envoy presents a certificate to clients.\n\n**USE CASE:** Enable HTTPS on your listener (port 443)\n\n---\n\n**STEP 1: CREATE A TLS CERTIFICATE SECRET**\n\nBefore configuring TLS, you need a certificate secret:\n1) Navigate to 'Secret' from left menu\n2) Create a TLS Certificate (see previous question)\n3) Note the secret name (e.g., \"api-server-cert\")\n\n---\n\n**STEP 2: NAVIGATE TO DOWNSTREAM TLS**\n\n1) Click 'TLS' from the left menu under 'RESOURCES'\n2) Click the blue '+' button at the top\n3) Select **'Downstream TLS Context'** from dropdown\n4) Enter a name (e.g., \"api-https-tls\")\n5) Select Envoy version\n6) Click to open configuration page\n\n---\n\n**STEP 3: CONFIGURE COMMON TLS CONTEXT**\n\nThe left anchor menu shows main sections:\n- **common_tls_context** (Required - certificate and validation settings)\n- **require_client_certificate** (Optional - for mTLS)\n- **session_ticket_keys** (Optional - for session resumption)\n\n1) Click 'common_tls_context' from left anchor menu\n2) The Common TLS Context card appears with horizontal tags\n\n---\n\n**STEP 4: LINK CERTIFICATE VIA SDS**\n\nInside common_tls_context, click horizontal tags:\n\n1) Click 'tls_certificate_sds_secret_configs' tag\n2) The TLS Certificate SDS Config section appears\n3) Click the blue '+' button to add a certificate reference\n\n**Configure SDS:**\n- **name**: Enter the secret name (\"api-server-cert\")\n- **sds_config**: Leave default (uses Elchi as SDS server)\n\nThis tells Envoy to fetch the certificate from Elchi's Secret Discovery Service.\n\n---\n\n**STEP 5: CONFIGURE TLS PARAMETERS (OPTIONAL BUT RECOMMENDED)**\n\nFor production security, configure TLS parameters:\n\n1) In common_tls_context, click 'tls_params' horizontal tag\n2) The TLS Parameters card appears\n3) Configure:\n\n**TLS Protocol Versions:**\n- Click 'tls_minimum_protocol_version' tag\n- Select from dropdown:\n  - TLSv1_0 (Avoid - deprecated)\n  - TLSv1_1 (Avoid - deprecated)\n  - **TLSv1_2** (Recommended minimum)\n  - **TLSv1_3** (Most secure)\n- Recommendation: Set minimum to TLSv1_2\n\n- Click 'tls_maximum_protocol_version' tag\n- Select TLSv1_3 for maximum\n\n**Cipher Suites (Optional):**\n- Click 'cipher_suites' tag\n- Add specific cipher suites if you need to restrict\n- Example: \"ECDHE-RSA-AES128-GCM-SHA256\"\n- Leave empty for Envoy defaults (recommended)\n\n**ALPN Protocols:**\n- Click 'alpn_protocols' tag\n- Add protocols for HTTP/2 and HTTP/1.1:\n  - \"h2\" (HTTP/2)\n  - \"http/1.1\" (HTTP/1.1)\n- This enables protocol negotiation\n\n---\n\n**STEP 6: CLIENT CERTIFICATE VALIDATION (OPTIONAL - FOR mTLS)**\n\nFor mutual TLS (client authentication):\n\n1) In common_tls_context, click 'validation_context_sds_secret_config' tag\n2) Configure:\n   - **name**: Name of CA certificate secret\n   - This secret contains trusted CA certificates to validate client certs\n\n3) Go back to main Downstream TLS Context level\n4) Click 'require_client_certificate' from left anchor\n5) Set to **true** to enforce client certificates\n\nWithout this, TLS is server-only (normal HTTPS).\n\n---\n\n**STEP 7: SESSION RESUMPTION (OPTIONAL)**\n\nFor performance optimization:\n\n1) Click 'session_ticket_keys_sds_secret_config' from left anchor\n2) Reference a TLS Session Ticket Keys secret\n3) This enables fast session resumption (avoids full handshake)\n\nOR\n\n1) Click 'disable_stateless_session_resumption' tag\n2) Set to **true** to disable (more secure but slower)\n\n---\n\n**STEP 8: SAVE DOWNSTREAM TLS CONTEXT**\n\n1) Click 'Create' button at top\n2) The Downstream TLS Context is saved\n3) Note the name (\"api-https-tls\")\n\n---\n\n**STEP 9: ATTACH TO LISTENER**\n\nNow link the TLS context to your listener:\n\n1) Navigate to 'Listener' from left menu\n2) Open your listener (or create a new one on port 443)\n3) Scroll to the Filter Chain section\n4) Click on your filter chain (or create one)\n5) Find 'transport_socket' in the left anchor menu\n6) Click 'transport_socket' tag\n7) The Transport Socket card appears\n\n**Configure Transport Socket:**\n- Click 'name' tag â†’ Select **\"envoy.transport_sockets.tls\"**\n- Click 'typed_config' tag\n- In the dropdown, select **\"DownstreamTlsContext\"**\n- A reference field appears\n- Enter or select your TLS context name: **\"api-https-tls\"**\n\n8) Save the listener\n9) Reload the service\n\n---\n\n**STEP 10: TEST HTTPS**\n\nAfter deployment:\n\n```bash\ncurl https://your-domain.com/\n```\n\nCheck certificate:\n```bash\nopenssl s_client -connect your-domain.com:443 -servername your-domain.com\n```\n\nYou should see your certificate presented by Envoy.\n\n---\n\n**COMMON CONFIGURATIONS:**\n\n**1) Simple HTTPS (no client cert):**\n- common_tls_context â†’ tls_certificate_sds_secret_configs â†’ your cert\n- tls_params â†’ TLSv1_2 minimum, TLSv1_3 maximum\n- alpn_protocols â†’ h2, http/1.1\n\n**2) Mutual TLS (mTLS):**\n- Same as above, PLUS:\n- validation_context_sds_secret_config â†’ CA cert secret\n- require_client_certificate â†’ true\n\n**3) Strict Security:**\n- TLS 1.3 only\n- Custom cipher suites\n- Client certificate required\n- No session resumption\n\n---\n\n**TROUBLESHOOTING:**\n\n**Problem: Certificate not found**\n- Ensure Secret name matches exactly\n- Check secret was created successfully\n- Verify SDS config points to Elchi\n\n**Problem: TLS handshake fails**\n- Check certificate chain is complete (includes intermediates)\n- Verify private key matches certificate\n- Check TLS version compatibility (client vs server)\n\n**Problem: Browser shows \"insecure\"**\n- Certificate may be self-signed\n- Domain name mismatch (cert vs actual domain)\n- Certificate expired\n- Missing intermediate certificates"}
{"resource":"Secret","category":"certificate_types","instruction":"What's the difference between inline_bytes, inline_string, and filename for certificates, and which should I use?","output":"CERTIFICATE DATA SOURCE OPTIONS:\n\nWhen configuring certificates and private keys in Secrets, you have three ways to provide the data:\n\n---\n\n**1) INLINE_STRING**\n\n**What it is:**\n- Certificate/key content pasted directly as text\n- Stored in Elchi database\n- Sent to Envoy via xDS (SDS)\n\n**How to use:**\n1) Click 'inline_string' tag in certificate_chain or private_key\n2) A text area appears\n3) Paste the PEM-formatted content:\n```\n-----BEGIN CERTIFICATE-----\nMIIDXTCCAkWgAwIBAgIJAKZ5...\n-----END CERTIFICATE-----\n```\n\n**Pros:**\nâœ… Easy to set up (copy-paste)\nâœ… No file system management needed\nâœ… Works immediately\nâœ… Good for testing/development\n\n**Cons:**\nâŒ Stored in database (security concern for private keys)\nâŒ Visible in UI (anyone with access can see)\nâŒ Not ideal for large fleets (xDS payload size)\n\n**Use when:**\n- Development/testing environments\n- Small deployments\n- Temporary certificates\n- POC/demos\n\n---\n\n**2) INLINE_BYTES**\n\n**What it is:**\n- Certificate/key content as base64-encoded bytes\n- Similar to inline_string but encoded\n- Also stored in Elchi database\n\n**How to use:**\n1) Click 'inline_bytes' tag\n2) Encode your certificate to base64:\n```bash\ncat server.crt | base64\n```\n3) Paste the base64 string (no PEM headers)\n\n**Example:**\n```\nTUlJRFhUQ0NBa1dnQXdJQkFnSUpBS1o1Li4u...\n```\n\n**Pros:**\nâœ… Binary-safe (handles any data)\nâœ… Works for non-text formats\nâœ… Good for automation (programmatic base64 encoding)\n\n**Cons:**\nâŒ Less human-readable than inline_string\nâŒ Same security concerns as inline_string\nâŒ Stored in database\n\n**Use when:**\n- Automation scripts (CI/CD)\n- Binary certificate formats\n- API-driven deployments\n\n---\n\n**3) FILENAME**\n\n**What it is:**\n- Reference to a file on the Envoy server's filesystem\n- File must exist on each Envoy instance\n- Envoy reads the file at startup and on reload\n\n**How to use:**\n1) First, place certificate files on Envoy servers:\n```bash\nssh user@envoy-server\nsudo cp server.crt /etc/ssl/certs/\nsudo cp server.key /etc/ssl/private/\nsudo chmod 644 /etc/ssl/certs/server.crt\nsudo chmod 600 /etc/ssl/private/server.key\n```\n\n2) In Elchi, click 'filename' tag\n3) Enter the absolute path:\n```\n/etc/ssl/certs/server.crt\n```\n\n**Pros:**\nâœ… **Most secure** - keys never stored in database\nâœ… Standard file permissions apply (chmod 600)\nâœ… Smaller xDS payload (just filename sent)\nâœ… Easy to rotate (just replace file and reload)\nâœ… **Recommended for production**\n\n**Cons:**\nâŒ Requires file deployment to all Envoy instances\nâŒ Manual file management\nâŒ Files must be identical across fleet\nâŒ Path must be correct on all servers\n\n**Use when:**\n- **Production environments** (ALWAYS)\n- Security compliance required\n- Large Envoy fleets\n- Certificate rotation needed\n- Sensitive private keys\n\n---\n\n**4) WATCHED_DIRECTORY (Special Case)**\n\n**What it is:**\n- Monitors a directory for certificate changes\n- Automatically reloads when files change\n- Zero-downtime certificate rotation\n\n**How to use:**\n1) Click 'watched_directory' tag in certificate_chain\n2) Configure:\n   - **path**: Directory to watch (e.g., `/etc/ssl/certs/active/`)\n\n3) Place certificate files in that directory\n4) When you update the file, Envoy detects and reloads\n\n**Pros:**\nâœ… **Automatic rotation** - no Envoy reload needed\nâœ… Zero-downtime certificate updates\nâœ… Ideal for Let's Encrypt / ACME\nâœ… File-based security\n\n**Cons:**\nâŒ Requires file system access\nâŒ More complex setup\nâŒ Directory must exist on all instances\n\n**Use when:**\n- Automated certificate renewal (Let's Encrypt)\n- Frequent certificate rotation\n- Zero-downtime requirement\n- Production with cert-manager/ACME\n\n---\n\n**COMPARISON TABLE:**\n\n| Feature | inline_string | inline_bytes | filename | watched_directory |\n|---------|--------------|--------------|----------|------------------|\n| Security | Low | Low | **High** | **High** |\n| Production | âŒ No | âŒ No | âœ… Yes | âœ… Yes |\n| Easy Setup | âœ… Yes | âœ… Yes | âŒ No | âŒ No |\n| Auto Reload | âŒ No | âŒ No | âŒ No | âœ… Yes |\n| File Required | âŒ No | âŒ No | âœ… Yes | âœ… Yes |\n| Use Case | Dev/Test | Automation | Production | Auto-Renew |\n\n---\n\n**RECOMMENDATIONS:**\n\n**Development:**\n```yaml\ncertificate_chain:\n  inline_string: |\n    -----BEGIN CERTIFICATE-----\n    ...\n    -----END CERTIFICATE-----\n```\n- Quick and easy\n- No file management\n\n**Production (Manual Rotation):**\n```yaml\ncertificate_chain:\n  filename: \"/etc/ssl/certs/api-server.crt\"\nprivate_key:\n  filename: \"/etc/ssl/private/api-server.key\"\n```\n- Secure (file permissions)\n- Keys not in database\n\n**Production (Auto Rotation):**\n```yaml\ncertificate_chain:\n  watched_directory:\n    path: \"/etc/ssl/certs/active/\"\nprivate_key:\n  watched_directory:\n    path: \"/etc/ssl/private/active/\"\n```\n- Zero-downtime rotation\n- Works with cert-manager/ACME\n\n---\n\n**CERTIFICATE ROTATION WORKFLOW:**\n\n**Using filename:**\n1) Generate new certificate\n2) Copy to Envoy servers (replace old file)\n3) Reload Envoy service (brief interruption)\n\n**Using watched_directory:**\n1) Generate new certificate\n2) Copy to watched directory\n3) Envoy automatically detects and reloads (zero downtime)\n\n---\n\n**SECURITY BEST PRACTICES:**\n\nâœ… **ALWAYS use filename or watched_directory for production**\nâœ… **Private keys should NEVER be inline in production**\nâœ… Set file permissions correctly:\n   - Certificates: `chmod 644` (world-readable OK)\n   - Private keys: `chmod 600` (owner-only)\nâœ… Use encrypted filesystems for key storage\nâœ… Rotate certificates before expiry\nâœ… Use separate keys per environment (dev/staging/prod)\n\nâš ï¸ **NEVER:**\n- Commit inline_string keys to git\n- Share inline keys across environments\n- Use inline in production\n- Store keys in plain text in database"}
{"resource":"TLS","category":"sds","instruction":"What is SDS (Secret Discovery Service) and how does it work in Elchi?","output":"SDS (SECRET DISCOVERY SERVICE):\n\n**What is SDS?**\n- Part of Envoy's xDS protocol suite\n- Dynamically delivers secrets (certificates, keys) to Envoy at runtime\n- Enables zero-downtime certificate rotation\n- Elchi acts as the SDS server\n\n**How it works:**\n```\n[Envoy] --gRPC--> [Elchi SDS Server] --Fetch--> [Secret Database]\n  â†“\nReceives certificate\n  â†“\nLoads into memory\n  â†“\nServes HTTPS traffic\n```\n\n---\n\n**SDS CONFIGURATION FLOW IN ELCHI:**\n\n**STEP 1: CREATE SECRET IN ELCHI**\n\n1) Navigate to 'Secret' from left menu\n2) Create TLS Certificate secret (e.g., \"api-cert-2024\")\n3) Upload certificate and private key\n4) Save the secret in Elchi database\n\n**STEP 2: CONFIGURE SDS REFERENCE IN TLS CONTEXT**\n\n1) Navigate to 'TLS' â†’ Downstream TLS Context\n2) Click 'common_tls_context' â†’ 'tls_certificate_sds_secret_configs'\n3) Add SDS configuration:\n\n**Fields:**\n- **name**: The secret name (\"api-cert-2024\")\n  - This is the SDS resource name\n  - Must match the secret name exactly\n\n- **sds_config**: (Usually left default)\n  - **api_config_source**:\n    - api_type: GRPC\n    - grpc_services:\n      - envoy_grpc:\n        - cluster_name: \"elchi_sds_cluster\"\n  - Points Envoy to Elchi's SDS server\n\n**STEP 3: ENVOY STARTUP WITH SDS**\n\nWhen Envoy starts:\n1) Reads Bootstrap configuration\n2) Sees tls_certificate_sds_secret_configs with name \"api-cert-2024\"\n3) Connects to Elchi SDS server (via elchi_sds_cluster)\n4) Sends SDS request: \"Give me secret: api-cert-2024\"\n5) Elchi responds with certificate and private key\n6) Envoy loads the certificate into memory\n7) Starts serving HTTPS traffic\n\n**STEP 4: CERTIFICATE ROTATION (ZERO DOWNTIME)**\n\n**Traditional approach (WITHOUT SDS):**\n1) Update certificate file on server\n2) Restart Envoy\n3) **Downtime during restart**\n4) New cert loaded\n\n**With SDS:**\n1) Update secret in Elchi UI (new certificate)\n2) Elchi pushes update to Envoy via SDS stream\n3) Envoy hot-reloads the certificate **without restart**\n4) **Zero downtime** - connections continue\n5) New connections use new certificate\n\n---\n\n**SDS vs STATIC CERTIFICATE:**\n\n**Static (filename approach):**\n```yaml\ncommon_tls_context:\n  tls_certificates:\n    - certificate_chain:\n        filename: /etc/ssl/certs/server.crt\n      private_key:\n        filename: /etc/ssl/private/server.key\n```\n- Certificate read from file at startup\n- Rotation requires Envoy restart\n- Simple but has downtime\n\n**Dynamic (SDS approach):**\n```yaml\ncommon_tls_context:\n  tls_certificate_sds_secret_configs:\n    - name: \"api-cert-2024\"\n      sds_config:\n        api_config_source:\n          api_type: GRPC\n          grpc_services:\n            - envoy_grpc:\n                cluster_name: \"elchi_sds_cluster\"\n```\n- Certificate fetched from Elchi SDS at runtime\n- Rotation is zero-downtime (hot reload)\n- Modern, recommended approach\n\n---\n\n**SDS TYPES IN ELCHI:**\n\n**1) TLS Certificate SDS:**\n- Field: `tls_certificate_sds_secret_configs`\n- Delivers: Server certificates + private keys\n- Used for: Downstream TLS (client â†’ Envoy)\n\n**2) Validation Context SDS:**\n- Field: `validation_context_sds_secret_config`\n- Delivers: CA certificates for client validation\n- Used for: Mutual TLS (mTLS)\n\n**3) Session Ticket Keys SDS:**\n- Field: `session_ticket_keys_sds_secret_config`\n- Delivers: TLS session ticket encryption keys\n- Used for: Session resumption\n\n---\n\n**CONFIGURING VALIDATION CONTEXT SDS (FOR mTLS):**\n\n**Scenario:** Validate client certificates\n\n**Step 1:** Create CA certificate secret\n1) Navigate to 'Secret'\n2) Create **'Certificate Validation Context'** type\n3) Name: \"client-ca-2024\"\n4) Upload CA certificate (trusted_ca)\n\n**Step 2:** Reference in TLS Context\n1) Navigate to Downstream TLS Context\n2) common_tls_context â†’ validation_context_sds_secret_config\n3) Enter:\n   - name: \"client-ca-2024\"\n   - sds_config: (default Elchi SDS)\n\n**Step 3:** Require client certificates\n1) Set `require_client_certificate: true`\n\nNow Envoy will:\n- Request client certificate during handshake\n- Validate against CA from SDS\n- Reject connections without valid client cert\n\n---\n\n**SDS UPDATE FLOW (CERTIFICATE ROTATION):**\n\n**1) Update Secret in Elchi:**\n- Go to 'Secret' â†’ \"api-cert-2024\"\n- Edit â†’ Replace certificate/key with new ones\n- Save\n\n**2) Elchi Triggers SDS Push:**\n- Elchi detects secret change\n- Identifies which Envoy instances use this secret\n- Sends SDS update via existing gRPC stream:\n  ```\n  DiscoveryResponse {\n    version_info: \"1234567891\"\n    resources: [\n      Secret {\n        name: \"api-cert-2024\"\n        tls_certificate: {\n          certificate_chain: { ... }\n          private_key: { ... }\n        }\n      }\n    ]\n  }\n  ```\n\n**3) Envoy Receives Update:**\n- Compares version_info (new > old)\n- Validates certificate\n- Hot-swaps certificate in memory\n- Sends ACK to Elchi\n- **No restart, no connection drop**\n\n**4) New Connections:**\n- Use the new certificate immediately\n- Existing connections drain gracefully\n\n---\n\n**MULTIPLE CERTIFICATES (SNI):**\n\nServe different certificates based on domain:\n\n**Step 1:** Create multiple secrets\n- \"example-com-cert\" (for example.com)\n- \"api-example-com-cert\" (for api.example.com)\n\n**Step 2:** Add multiple SDS configs\n```yaml\ntls_certificate_sds_secret_configs:\n  - name: \"example-com-cert\"\n    sds_config: { ... }\n  - name: \"api-example-com-cert\"\n    sds_config: { ... }\n```\n\n**Step 3:** Envoy selects based on SNI\n- Client requests `https://api.example.com`\n- Envoy matches SNI to certificate\n- Serves \"api-example-com-cert\"\n\n---\n\n**TROUBLESHOOTING SDS:**\n\n**Problem: Certificate not loading**\n\nCheck:\n1) Secret name matches exactly (case-sensitive)\n2) SDS cluster reachable:\n   ```bash\n   curl http://localhost:9901/clusters | grep elchi_sds_cluster\n   ```\n3) Envoy logs for SDS errors:\n   ```bash\n   journalctl -u envoy | grep SDS\n   ```\n\n**Problem: Rotation not working**\n\nCheck:\n1) SDS stream is active (not disconnected)\n2) Secret version incremented in Elchi\n3) Envoy received update (check /config_dump):\n   ```bash\n   curl http://localhost:9901/config_dump | jq '.configs[] | select(.\"@type\" | contains(\"Secret\"))'\n   ```\n\n**Problem: Multiple Envoys, only some updated**\n\nCause: SDS stream broken on some instances\nFix:\n- Check network connectivity to Elchi\n- Restart affected Envoy instances\n- Check Elchi server logs for push failures\n\n---\n\n**BENEFITS OF SDS:**\n\nâœ… **Zero-downtime rotation**\n- Update certificates without Envoy restart\n- No dropped connections\n\nâœ… **Centralized management**\n- All secrets managed in Elchi UI\n- No manual file distribution\n\nâœ… **Audit trail**\n- Track who changed which secret and when\n- Version history\n\nâœ… **Consistency**\n- All Envoy instances get the same certificate\n- No file sync issues\n\nâœ… **Automation-friendly**\n- API-driven certificate updates\n- Integrate with cert-manager/ACME\n\n---\n\n**SDS BEST PRACTICES:**\n\nâœ… Use SDS for all TLS certificates in production\nâœ… Implement certificate expiry monitoring\nâœ… Automate rotation (e.g., 30 days before expiry)\nâœ… Test rotation in staging first\nâœ… Monitor SDS stream health (metrics)\nâœ… Keep Elchi SDS cluster highly available\n\nâš ï¸ Fallback:\n- Configure static certificate as backup\n- In case SDS server is unreachable\n- Envoy can still start with static cert"}
{"resource":"TLS","category":"mtls","instruction":"How do I configure mutual TLS (mTLS) to require client certificates?","output":"MUTUAL TLS (mTLS) CONFIGURATION:\n\n**What is mTLS?**\n- Both client AND server present certificates\n- Server validates client certificate against CA\n- Two-way authentication (vs normal TLS which is one-way)\n- Used for service-to-service communication, API security\n\n**Use Cases:**\n- Microservices authentication\n- API access control (no API keys needed)\n- Zero-trust networking\n- Regulatory compliance (banking, healthcare)\n\n---\n\n**PREREQUISITES:**\n\nYou need:\n1. **Server certificate** (Envoy's certificate)\n2. **CA certificate** (to validate client certificates)\n3. **Client certificate** (issued by the CA)\n\n---\n\n**STEP 1: CREATE SERVER CERTIFICATE SECRET**\n\n1) Navigate to 'Secret' â†’ Click blue '+' button\n2) Select **'TLS Certificate'**\n3) Name: \"api-server-cert\"\n4) Add certificate_chain and private_key (your server cert)\n5) Save\n\n---\n\n**STEP 2: CREATE CA CERTIFICATE SECRET**\n\nThis CA will be used to validate client certificates.\n\n1) Navigate to 'Secret' â†’ Click blue '+' button\n2) Select **'Certificate Validation Context'**\n3) Name: \"client-ca\"\n4) Click to open configuration\n\n**Configure Validation Context:**\n\n1) Left anchor menu â†’ Click 'trusted_ca'\n2) The Trusted CA card appears\n3) Choose data source:\n\n**Option A: Inline**\n- Click 'inline_string' tag\n- Paste your CA certificate:\n```\n-----BEGIN CERTIFICATE-----\nMIIDXTCCAkWgAwIBAgIJAKZ5...\n-----END CERTIFICATE-----\n```\n\n**Option B: Filename**\n- Click 'filename' tag\n- Path: `/etc/ssl/ca-certs/client-ca.crt`\n\n4) Save the secret\n\n---\n\n**STEP 3: CREATE DOWNSTREAM TLS CONTEXT**\n\n1) Navigate to 'TLS' from left menu\n2) Click blue '+' button â†’ Select **'Downstream TLS Context'**\n3) Name: \"api-mtls-context\"\n4) Open configuration page\n\n---\n\n**STEP 4: CONFIGURE SERVER CERTIFICATE (SDS)**\n\n1) Left anchor â†’ Click 'common_tls_context'\n2) Horizontal tags â†’ Click 'tls_certificate_sds_secret_configs'\n3) Click blue '+' button\n4) Configure:\n   - **name**: \"api-server-cert\" (from Step 1)\n   - **sds_config**: Leave default\n\nThis configures Envoy's server certificate (presented to clients).\n\n---\n\n**STEP 5: CONFIGURE CLIENT CERTIFICATE VALIDATION (THE mTLS PART)**\n\nStill in common_tls_context:\n\n1) Horizontal tags â†’ Click 'validation_context_sds_secret_config'\n2) The Validation Context SDS Config section appears\n3) Configure:\n   - **name**: \"client-ca\" (from Step 2)\n   - **sds_config**: Leave default\n\nThis tells Envoy:\n- Expect client to present a certificate\n- Validate it against the \"client-ca\" CA certificate\n\n**Advanced Validation (Optional):**\n\nIf you need stricter validation:\n\n1) Instead of SDS, click 'validation_context' tag (inline config)\n2) Inside validation_context:\n   - **trusted_ca**: The CA certificate\n   - **match_subject_alt_names**: Restrict to specific SANs\n     - Example: Only allow clients with SAN \"*.example.com\"\n   - **verify_certificate_spki**: Pin specific public keys\n   - **verify_certificate_hash**: Pin specific certificate hashes\n\n---\n\n**STEP 6: REQUIRE CLIENT CERTIFICATE**\n\nGo back to main Downstream TLS Context level (exit common_tls_context):\n\n1) Left anchor menu â†’ Click 'require_client_certificate'\n2) The field appears\n3) Set to **true**\n\n**What this does:**\n- **true**: Client MUST present a certificate (strict mTLS)\n- **false**: Client certificate is optional (validated if provided)\n\n**When to use false:**\n- Mixed mode: some clients with certs, some without\n- Gradual rollout of mTLS\n- Use application logic to check certificate (custom header)\n\n---\n\n**STEP 7: CONFIGURE TLS PARAMETERS (RECOMMENDED)**\n\n1) In common_tls_context â†’ Click 'tls_params'\n2) Set:\n   - **tls_minimum_protocol_version**: TLSv1_2\n   - **tls_maximum_protocol_version**: TLSv1_3\n   - **alpn_protocols**: [\"h2\", \"http/1.1\"]\n\n---\n\n**STEP 8: SAVE TLS CONTEXT**\n\n1) Click 'Create' button\n2) TLS context \"api-mtls-context\" is saved\n\n---\n\n**STEP 9: ATTACH TO LISTENER**\n\n1) Navigate to 'Listener' â†’ Open your listener\n2) Go to Filter Chain configuration\n3) Click 'transport_socket' â†’ 'typed_config'\n4) Select **\"DownstreamTlsContext\"**\n5) Reference: \"api-mtls-context\"\n6) Save listener\n7) Deploy and reload service\n\n---\n\n**STEP 10: GENERATE CLIENT CERTIFICATE**\n\nClients need certificates signed by your CA:\n\n**Generate client private key:**\n```bash\nopenssl genrsa -out client.key 2048\n```\n\n**Create CSR (Certificate Signing Request):**\n```bash\nopenssl req -new -key client.key -out client.csr \\\n  -subj \"/CN=client1.example.com\"\n```\n\n**Sign with CA:**\n```bash\nopenssl x509 -req -in client.csr \\\n  -CA ca.crt -CAkey ca.key -CAcreateserial \\\n  -out client.crt -days 365\n```\n\nNow you have:\n- `client.crt` (client certificate)\n- `client.key` (client private key)\n- `ca.crt` (CA certificate, for validation)\n\n---\n\n**STEP 11: TEST mTLS**\n\n**Test WITH client certificate (should work):**\n```bash\ncurl --cert client.crt --key client.key \\\n  --cacert ca.crt \\\n  https://your-domain.com/api\n```\n\nExpected: **200 OK** (certificate validated)\n\n**Test WITHOUT client certificate (should fail):**\n```bash\ncurl https://your-domain.com/api\n```\n\nExpected: **SSL handshake failure** (certificate required)\n\n---\n\n**EXTRACTING CLIENT INFO IN APPLICATION:**\n\nAfter mTLS validation, you can extract client certificate info:\n\n**In HTTP headers (configured in HCM):**\n\nEnvoy can forward client certificate details:\n\n1) Go to Listener â†’ HTTP Connection Manager filter\n2) Configure `forward_client_cert_details`:\n   - Options: SANITIZE, FORWARD_ONLY, APPEND_FORWARD, etc.\n\n3) Set `set_current_client_cert_details`:\n   - Subject: %DOWNSTREAM_PEER_SUBJECT%\n   - URI: %DOWNSTREAM_PEER_URI_SAN%\n   - DNS: %DOWNSTREAM_PEER_DNS_SAN%\n\n4) These get added as HTTP headers:\n   - `X-Forwarded-Client-Cert`\n   - `X-Client-Subject`\n\nYour backend application receives:\n```\nX-Client-Subject: CN=client1.example.com,O=Example Inc\n```\n\nUse this for authorization decisions.\n\n---\n\n**VALIDATION MODES:**\n\n**1) Strict mTLS (require_client_certificate: true)**\n- Client MUST present certificate\n- Certificate MUST be valid (signed by CA)\n- Connection rejected otherwise\n\n**2) Optional mTLS (require_client_certificate: false)**\n- Client MAY present certificate\n- If presented, it's validated\n- If not presented, connection still allowed\n- Application decides based on headers\n\n**3) Subject Alternative Name (SAN) Matching:**\n\nRestrict to specific clients:\n\n```yaml\nvalidation_context:\n  match_subject_alt_names:\n    - exact: \"client1.example.com\"\n    - prefix: \"service-\"\n    - suffix: \".internal.example.com\"\n```\n\nOnly clients with matching SANs are allowed.\n\n---\n\n**COMMON mTLS USE CASES:**\n\n**1) Service Mesh (Microservices):**\n- Every service has a certificate\n- Service A â†’ Envoy (mTLS) â†’ Service B\n- Mutual authentication between all services\n\n**2) API Gateway:**\n- External clients get certificates\n- API key alternative (certificate = identity)\n- Stronger than bearer tokens\n\n**3) Zero Trust Network:**\n- No trust based on network location\n- Every connection authenticated via certificate\n- Combined with RBAC policies\n\n---\n\n**TROUBLESHOOTING mTLS:**\n\n**Problem: \"certificate required\" error**\n\nCause: `require_client_certificate: true` but client didn't send cert\nFix:\n- Client must use `--cert` and `--key` flags\n- Check client is configured for mTLS\n\n**Problem: \"certificate verify failed\"**\n\nCause: Client certificate not signed by trusted CA\nFix:\n- Ensure client cert signed by CA in \"client-ca\" secret\n- Check CA certificate is correct\n- Verify certificate hasn't expired\n\n**Problem: \"unknown ca\"**\n\nCause: Server can't find the CA to validate client cert\nFix:\n- Check validation_context_sds_secret_config references correct secret\n- Verify \"client-ca\" secret exists and contains CA cert\n- Reload service after secret changes\n\n**Problem: Works in curl, fails in browser**\n\nCause: Browser doesn't have client certificate installed\nFix:\n- Import client.p12 (PKCS#12) into browser\n- Convert to PKCS#12:\n  ```bash\n  openssl pkcs12 -export -out client.p12 \\\n    -inkey client.key -in client.crt\n  ```\n- Install in browser (Settings â†’ Certificates)\n\n---\n\n**mTLS BEST PRACTICES:**\n\nâœ… Use short-lived client certificates (30-90 days)\nâœ… Automate certificate issuance (cert-manager)\nâœ… Rotate CA certificates periodically\nâœ… Monitor certificate expiry\nâœ… Use SAN matching for stricter validation\nâœ… Log client subject for audit trails\nâœ… Combine with RBAC for authorization\n\nâš ï¸ Security:\n- Protect CA private key (offline storage)\n- Use separate CAs for different environments\n- Revocation: Use CRL or OCSP for revoked certs"}
{"resource":"TLS","category":"sni","instruction":"How do I configure SNI (Server Name Indication) to serve different certificates for different domains?","output":"SNI (SERVER NAME INDICATION) CONFIGURATION:\n\n**What is SNI?**\n- TLS extension that allows multiple HTTPS domains on a single IP\n- Client sends hostname during TLS handshake\n- Server selects appropriate certificate based on hostname\n- Enables virtual hosting for HTTPS (like HTTP vhosts)\n\n**Use Case:**\n- One Envoy instance, multiple domains:\n  - example.com\n  - api.example.com\n  - admin.example.com\n- Each with its own certificate\n\n---\n\n**ARCHITECTURE:**\n\n```\nClient Request: https://api.example.com\n  â†“ TLS Handshake\n  â†“ SNI: api.example.com\n  â†“\nEnvoy checks SNI\n  â†“\nMatches \"api.example.com\"\n  â†“\nServes api-example-com-cert\n  â†“\nTLS established\n  â†“\nHTTP Request processed\n```\n\n---\n\n**METHOD 1: MULTIPLE CERTIFICATES IN ONE TLS CONTEXT (SIMPLE)**\n\n**STEP 1: CREATE CERTIFICATES FOR EACH DOMAIN**\n\n1) Navigate to 'Secret' â†’ Create TLS Certificates:\n\n**Certificate 1: example.com**\n- Name: \"example-com-cert\"\n- Certificate for: example.com\n- SAN (Subject Alternative Name): example.com, www.example.com\n\n**Certificate 2: api.example.com**\n- Name: \"api-example-com-cert\"\n- Certificate for: api.example.com\n\n**Certificate 3: admin.example.com**\n- Name: \"admin-example-com-cert\"\n- Certificate for: admin.example.com\n\n---\n\n**STEP 2: CREATE DOWNSTREAM TLS CONTEXT WITH MULTIPLE CERTS**\n\n1) Navigate to 'TLS' â†’ Downstream TLS Context\n2) Name: \"multi-domain-tls\"\n3) Open configuration\n\n**Configure Multiple Certificates:**\n\n1) common_tls_context â†’ tls_certificate_sds_secret_configs\n2) Add ALL certificates:\n\n**First certificate (default):**\n- Click blue '+' button\n- name: \"example-com-cert\"\n\n**Second certificate:**\n- Click blue '+' button again\n- name: \"api-example-com-cert\"\n\n**Third certificate:**\n- Click blue '+' button again\n- name: \"admin-example-com-cert\"\n\nEnvoy will:\n- Use first certificate as default (if SNI doesn't match)\n- Match SNI to certificate SAN\n- Select appropriate certificate automatically\n\n3) Save TLS context\n\n---\n\n**STEP 3: ATTACH TO LISTENER**\n\n1) Navigate to Listener (port 443)\n2) Filter Chain â†’ transport_socket â†’ DownstreamTlsContext\n3) Reference: \"multi-domain-tls\"\n4) Save and reload\n\n---\n\n**STEP 4: TEST SNI**\n\n**Test each domain:**\n```bash\n# Test example.com\ncurl https://example.com/ -v 2>&1 | grep \"subject:\"\nExpected: CN=example.com\n\n# Test api.example.com\ncurl https://api.example.com/ -v 2>&1 | grep \"subject:\"\nExpected: CN=api.example.com\n\n# Test admin.example.com  \ncurl https://admin.example.com/ -v 2>&1 | grep \"subject:\"\nExpected: CN=admin.example.com\n```\n\nEach request should receive the correct certificate.\n\n---\n\n**METHOD 2: SEPARATE FILTER CHAINS PER DOMAIN (ADVANCED)**\n\nFor more control (different routes, filters per domain):\n\n**STEP 1: CREATE TLS CONTEXTS (ONE PER DOMAIN)**\n\n1) Create Downstream TLS Context: \"example-com-tls\"\n   - Certificate: \"example-com-cert\"\n\n2) Create Downstream TLS Context: \"api-example-com-tls\"\n   - Certificate: \"api-example-com-cert\"\n\n3) Create Downstream TLS Context: \"admin-example-com-tls\"\n   - Certificate: \"admin-example-com-cert\"\n\n---\n\n**STEP 2: CREATE FILTER CHAINS WITH SNI MATCHING**\n\n1) Navigate to Listener (port 443)\n2) Create multiple Filter Chains:\n\n**Filter Chain 1: example.com**\n\n1) Click blue '+' button to add filter chain\n2) Configure **filter_chain_match**:\n   - Click 'filter_chain_match' from left anchor\n   - Click 'server_names' tag\n   - Add server names:\n     - \"example.com\"\n     - \"www.example.com\"\n3) Configure **transport_socket**:\n   - DownstreamTlsContext â†’ \"example-com-tls\"\n4) Configure **filters** (HCM, routes, etc.)\n\n**Filter Chain 2: api.example.com**\n\n1) Add another filter chain\n2) filter_chain_match â†’ server_names:\n   - \"api.example.com\"\n3) transport_socket â†’ \"api-example-com-tls\"\n4) filters â†’ Different HCM/routes for API\n\n**Filter Chain 3: admin.example.com**\n\n1) Add another filter chain\n2) filter_chain_match â†’ server_names:\n   - \"admin.example.com\"\n3) transport_socket â†’ \"admin-example-com-tls\"\n4) filters â†’ Different HCM/routes for admin\n\n**Default Filter Chain (no SNI match):**\n\n1) Add a filter chain without filter_chain_match\n2) This catches requests with no SNI or unmatched SNI\n3) Can return 404 or redirect\n\n---\n\n**STEP 3: SAVE AND TEST**\n\n1) Save listener\n2) Deploy and reload\n3) Test each domain\n\nNow each domain:\n- Has its own certificate\n- Can have different routes\n- Can have different filters\n- Can have different backend clusters\n\n---\n\n**WILDCARD CERTIFICATES:**\n\nFor `*.example.com` (all subdomains):\n\n**STEP 1: Create wildcard certificate**\n\n1) Secret â†’ TLS Certificate\n2) Name: \"wildcard-example-com\"\n3) Certificate with:\n   - CN: *.example.com\n   - SAN: *.example.com, example.com\n\n**STEP 2: Single TLS context**\n\n1) Downstream TLS Context\n2) One certificate: \"wildcard-example-com\"\n3) Matches all: api.example.com, admin.example.com, etc.\n\n**Pros:**\n- One certificate for all subdomains\n- Easier management\n\n**Cons:**\n- If compromised, all subdomains affected\n- Not all CAs issue wildcards\n\n---\n\n**SNI MATCHING PATTERNS:**\n\nIn `filter_chain_match.server_names`, you can use:\n\n**Exact match:**\n```yaml\nserver_names:\n  - \"api.example.com\"\n```\n\n**Wildcard prefix:**\n```yaml\nserver_names:\n  - \"*.example.com\"  # Matches api.example.com, admin.example.com\n```\n\n**Wildcard suffix:**\n```yaml\nserver_names:\n  - \"example.*\"  # Matches example.com, example.org\n```\n\n**Multiple domains:**\n```yaml\nserver_names:\n  - \"example.com\"\n  - \"www.example.com\"\n  - \"example.org\"\n```\n\n---\n\n**SNI + ROUTING EXAMPLE:**\n\nDifferent backends per domain:\n\n**Filter Chain 1: api.example.com**\n- SNI: api.example.com\n- Certificate: api-cert\n- Route: /api/* â†’ backend-api-cluster\n\n**Filter Chain 2: admin.example.com**\n- SNI: admin.example.com\n- Certificate: admin-cert\n- Route: /* â†’ backend-admin-cluster\n- Extra: Basic Auth filter for security\n\n**Filter Chain 3: www.example.com**\n- SNI: www.example.com, example.com\n- Certificate: www-cert\n- Route: /* â†’ backend-web-cluster\n\n---\n\n**TROUBLESHOOTING SNI:**\n\n**Problem: Wrong certificate served**\n\nCause: SNI not matching any certificate SAN\nFix:\n- Check certificate SAN includes the domain\n- Verify filter_chain_match server_names\n- Test with openssl:\n  ```bash\n  openssl s_client -connect example.com:443 \\\n    -servername api.example.com\n  ```\n\n**Problem: Certificate error in browser**\n\nCause: Certificate CN/SAN doesn't match requested domain\nFix:\n- Ensure certificate issued for correct domain\n- Check browser is sending correct SNI\n- Verify DNS points to correct IP\n\n**Problem: Default cert always served**\n\nCause: Envoy not receiving SNI from client\nFix:\n- Old clients may not support SNI (very rare)\n- Check client is using HTTPS (not HTTP)\n- Verify TLS 1.0+ (SNI requires TLS)\n\n**Problem: Filter chain not matching**\n\nDebug:\n1) Check Envoy logs for filter chain selection:\n   ```bash\n   journalctl -u envoy | grep \"filter chain\"\n   ```\n2) Verify order (first match wins)\n3) Check for typos in server_names\n\n---\n\n**CERTIFICATE MANAGEMENT AT SCALE:**\n\nFor many domains (10+):\n\n**Option 1: Wildcard Certificate**\n- *.example.com covers all subdomains\n- One certificate to manage\n- Risk: Single point of failure\n\n**Option 2: Multiple specific certificates**\n- api.example.com, admin.example.com, etc.\n- More secure (isolation)\n- More management overhead\n\n**Option 3: Automated cert management**\n- Use cert-manager with Let's Encrypt\n- Automatic issuance and renewal\n- SDS integration for zero-downtime rotation\n\n**Automation workflow:**\n1) cert-manager watches Ingress/Certificate resources\n2) Issues certificates via ACME\n3) Stores in Kubernetes Secrets\n4) Elchi fetches from K8s\n5) Pushes via SDS to Envoy\n6) Envoy hot-reloads certificates\n\n---\n\n**SNI BEST PRACTICES:**\n\nâœ… Use specific certificates per domain (not wildcard) for security\nâœ… Include both root and www in SAN (example.com + www.example.com)\nâœ… Set default filter chain for unmatched SNI\nâœ… Monitor certificate expiry per domain\nâœ… Use SDS for easy rotation\nâœ… Test SNI with `openssl s_client -servername`\n\nâš ï¸ Order matters:\n- First matching filter chain is used\n- Put specific matches before wildcards\n- Default filter chain goes last"}
{"resource":"Secret","category":"rotation","instruction":"How do I rotate TLS certificates with zero downtime using SDS?","output":"ZERO-DOWNTIME CERTIFICATE ROTATION WITH SDS:\n\n**Why SDS for Rotation?**\n- Traditional: Replace file â†’ Restart Envoy â†’ **Downtime**\n- With SDS: Update secret â†’ Envoy hot-reloads â†’ **Zero downtime**\n\n---\n\n**PREREQUISITES:**\n\nYour setup must use SDS (not static filename):\n\n**Check your TLS context:**\n1) Navigate to TLS â†’ Your Downstream TLS Context\n2) Verify it uses `tls_certificate_sds_secret_configs`\n3) If using `filename`, migrate to SDS first\n\n---\n\n**CERTIFICATE ROTATION WORKFLOW:**\n\n**STEP 1: GENERATE NEW CERTIFICATE**\n\nBefore expiry of current certificate:\n\n**Option A: Commercial CA**\n1) Generate CSR (Certificate Signing Request):\n```bash\nopenssl req -new -newkey rsa:2048 -nodes \\\n  -keyout new-server.key -out new-server.csr \\\n  -subj \"/CN=api.example.com\"\n```\n\n2) Submit CSR to CA (DigiCert, Let's Encrypt, etc.)\n3) Receive new certificate: `new-server.crt`\n\n**Option B: Let's Encrypt (Automated)**\n1) Use certbot:\n```bash\ncertbot certonly --standalone \\\n  -d api.example.com \\\n  -d www.api.example.com\n```\n\n2) Certificate saved to:\n```\n/etc/letsencrypt/live/api.example.com/fullchain.pem\n/etc/letsencrypt/live/api.example.com/privkey.pem\n```\n\n**Option C: Self-signed (Testing)**\n```bash\nopenssl req -x509 -newkey rsa:2048 -nodes \\\n  -keyout new-server.key -out new-server.crt \\\n  -days 365 -subj \"/CN=api.example.com\"\n```\n\n---\n\n**STEP 2: UPDATE SECRET IN ELCHI (THE CRITICAL STEP)**\n\n1) Navigate to 'Secret' from left menu\n2) Find your existing secret (e.g., \"api-server-cert\")\n3) Click on the secret to edit\n\n**Replace Certificate:**\n\n1) Scroll to the certificate entry\n2) Click 'certificate_chain'\n3) If using inline_string:\n   - Delete old certificate content\n   - Paste new certificate:\n   ```\n   -----BEGIN CERTIFICATE-----\n   MIIDXTCCAkWgAwIBAgIJAKZ5... (new cert)\n   -----END CERTIFICATE-----\n   ```\n\n4) Click 'private_key'\n5) If using inline_string:\n   - Delete old private key content\n   - Paste new private key:\n   ```\n   -----BEGIN PRIVATE KEY-----\n   MIIEvQIBADANBgkqhkiG9w0... (new key)\n   -----END PRIVATE KEY-----\n   ```\n\n**IMPORTANT:** Keep the secret NAME the same (\"api-server-cert\")\n- Only the content changes\n- Don't create a new secret\n- SDS references by name\n\n6) Click 'Update' or 'Save'\n\n---\n\n**STEP 3: ELCHI TRIGGERS SDS UPDATE (AUTOMATIC)**\n\nWhen you save the secret:\n\n1) Elchi detects secret version change\n2) Identifies all Envoy instances using this secret\n3) Sends SDS DiscoveryResponse via gRPC:\n```json\n{\n  \"version_info\": \"1234567891\",\n  \"resources\": [\n    {\n      \"@type\": \"type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.Secret\",\n      \"name\": \"api-server-cert\",\n      \"tls_certificate\": {\n        \"certificate_chain\": { \"inline_string\": \"<new-cert>\" },\n        \"private_key\": { \"inline_string\": \"<new-key>\" }\n      }\n    }\n  ]\n}\n```\n\n4) All Envoy instances receive the update **simultaneously**\n\n---\n\n**STEP 4: ENVOY HOT-RELOADS CERTIFICATE (AUTOMATIC)**\n\nEach Envoy instance:\n\n1) Receives SDS update\n2) Validates new certificate:\n   - Checks expiry date\n   - Verifies private key matches\n   - Parses certificate chain\n3) If valid:\n   - Loads new certificate into memory\n   - Keeps old certificate for existing connections\n   - Uses new certificate for new connections\n4) Sends ACK to Elchi\n5) Old connections drain naturally\n6) **Zero downtime** - no connection drops\n\n---\n\n**STEP 5: VERIFY NEW CERTIFICATE IS ACTIVE**\n\n**Test with OpenSSL:**\n```bash\nopenssl s_client -connect api.example.com:443 \\\n  -servername api.example.com | \\\n  openssl x509 -noout -dates\n```\n\nOutput:\n```\nnotBefore=Jan 15 00:00:00 2025 GMT\nnotAfter=Jan 14 23:59:59 2026 GMT\n```\n\nVerify expiry date is the NEW certificate.\n\n**Test with curl:**\n```bash\ncurl -v https://api.example.com/ 2>&1 | grep \"expire date\"\n```\n\n**Check Envoy config dump:**\n```bash\ncurl localhost:9901/config_dump | \\\n  jq '.configs[] | select(.\"@type\" | contains(\"Secret\"))'\n```\n\nVerify certificate content matches new cert.\n\n---\n\n**MONITORING THE ROTATION:**\n\n**Before rotation:**\n1) Check current certificate expiry:\n```bash\ncurl localhost:9901/config_dump | \\\n  jq -r '.configs[].dynamic_active_secrets[].secret.tls_certificate.certificate_chain.inline_string' | \\\n  openssl x509 -noout -enddate\n```\n\n2) Note the expiry date\n\n**After rotation:**\n1) Wait 10-30 seconds for SDS propagation\n2) Re-run the command above\n3) Verify new expiry date\n\n**Check SDS statistics:**\n```bash\ncurl localhost:9901/stats | grep sds\n```\n\nMetrics to monitor:\n- `sds.update_success`: Should increment\n- `sds.update_failure`: Should NOT increment\n\n---\n\n**AUTOMATION WITH CERTBOT + ELCHI API:**\n\nFor automatic Let's Encrypt renewal:\n\n**Step 1: Certbot renewal hook**\n\nCreate `/etc/letsencrypt/renewal-hooks/deploy/update-elchi.sh`:\n\n```bash\n#!/bin/bash\nDOMAIN=\"api.example.com\"\nSECRET_NAME=\"api-server-cert\"\nELCHI_API=\"https://elchi.example.com/api\"\nAPI_TOKEN=\"your-api-token\"\n\n# Read new certificate and key\nCERT=$(cat /etc/letsencrypt/live/$DOMAIN/fullchain.pem)\nKEY=$(cat /etc/letsencrypt/live/$DOMAIN/privkey.pem)\n\n# Update Elchi secret via API\ncurl -X PUT \"$ELCHI_API/v1/secrets/$SECRET_NAME\" \\\n  -H \"Authorization: Bearer $API_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"certificate_chain\": {\"inline_string\": \"'\"$CERT\"'\"},\n    \"private_key\": {\"inline_string\": \"'\"$KEY\"'\"}\n  }'\n\necho \"Certificate rotated in Elchi: $SECRET_NAME\"\n```\n\nMake executable:\n```bash\nchmod +x /etc/letsencrypt/renewal-hooks/deploy/update-elchi.sh\n```\n\n**Step 2: Test renewal**\n```bash\ncertbot renew --dry-run\n```\n\n**Step 3: Automatic renewal**\nCertbot cron runs daily:\n- Checks certificate expiry\n- If < 30 days, renews\n- Calls hook script\n- Elchi updates secret\n- Envoy hot-reloads\n- **Zero downtime**\n\n---\n\n**ROLLBACK PROCEDURE:**\n\nIf new certificate causes issues:\n\n**Quick rollback:**\n1) Navigate to Secret â†’ \"api-server-cert\"\n2) Replace with old certificate content (keep backup)\n3) Save\n4) Elchi pushes old certificate\n5) Envoy reloads (back to working state)\n\n**Version control:**\n- Keep certificate versions in git (encrypt private keys)\n- Tag each rotation\n- Easy to revert to previous version\n\n---\n\n**MULTI-CERTIFICATE ROTATION:**\n\nRotate multiple domains at once:\n\n**Scenario:** 10 domains, all expiring soon\n\n**Parallel rotation:**\n1) Generate all 10 new certificates\n2) Update all 10 secrets in Elchi (can be done simultaneously)\n3) Elchi sends 10 SDS updates to Envoy\n4) Envoy hot-reloads all 10 certificates\n5) Total time: ~30 seconds\n6) Zero downtime for all domains\n\n---\n\n**CERTIFICATE OVERLAP STRATEGY:**\n\nFor critical systems:\n\n**1) Request new cert 30 days before expiry**\n- Old cert still valid for 30 days\n- New cert valid for 365 days\n- Overlap: 30 days\n\n**2) Test new cert in staging first**\n- Update staging secret\n- Verify HTTPS works\n- Monitor for 24-48 hours\n\n**3) Rotate in production**\n- Low-traffic window (but not required)\n- Update secret\n- Monitor immediately\n\n**4) Keep old cert backup for 7 days**\n- In case rollback needed\n- After 7 days, securely delete old key\n\n---\n\n**TROUBLESHOOTING ROTATION:**\n\n**Problem: New certificate not loading**\n\nCheck:\n1) SDS connection healthy:\n   ```bash\n   curl localhost:9901/clusters | grep elchi_sds_cluster\n   ```\n2) Envoy logs:\n   ```bash\n   journalctl -u envoy | grep -i sds\n   ```\n3) Certificate validation error:\n   - Check key matches certificate\n   - Verify certificate chain includes intermediates\n   - Check expiry date (not in past)\n\n**Problem: Some Envoys updated, some didn't**\n\nCause: SDS stream broken on some instances\n\nFix:\n1) Check network connectivity to Elchi\n2) Restart affected Envoy instances\n3) They will re-establish SDS stream and fetch new cert\n\n**Problem: Downtime during rotation**\n\nCause: Not using SDS (using filename)\n\nFix:\n- Migrate to SDS configuration\n- Never use filename for production\n\n---\n\n**BEST PRACTICES:**\n\nâœ… **Timing:**\n- Rotate 30 days before expiry\n- Avoid last-minute rotations\n- Schedule during low-traffic (optional with SDS)\n\nâœ… **Testing:**\n- Test new cert in staging first\n- Verify certificate chain is complete\n- Check expiry date before deploying\n\nâœ… **Monitoring:**\n- Alert 60 days before expiry\n- Monitor SDS update success/failure\n- Track rotation history\n\nâœ… **Automation:**\n- Use certbot/cert-manager\n- API-driven secret updates\n- No manual steps\n\nâœ… **Security:**\n- Securely delete old private keys after rotation\n- Use encrypted storage for keys\n- Audit who rotated certificates (Elchi audit log)\n\nâš ï¸ **Never:**\n- Rotate in production without testing\n- Use expired certificates\n- Skip intermediate certificates in chain\n- Restart Envoy for rotation (defeats SDS purpose)"}
{"resource":"TLS","category":"troubleshooting","instruction":"My TLS configuration isn't working - how do I debug TLS issues in Envoy?","output":"TLS TROUBLESHOOTING GUIDE:\n\n**Common TLS Problems and Solutions:**\n\n---\n\n**PROBLEM 1: \"SSL handshake failed\" or \"certificate verify failed\"**\n\n**Possible Causes:**\n\n**A) Certificate and Private Key Mismatch**\n\nCheck if they match:\n```bash\n# Get certificate modulus\nopenssl x509 -noout -modulus -in server.crt | openssl md5\n\n# Get private key modulus\nopenssl rsa -noout -modulus -in server.key | openssl md5\n```\n\nIf hashes differ â†’ **Key doesn't match certificate**\n\nFix:\n1) Navigate to Secret â†’ Your TLS Certificate\n2) Verify you uploaded matching cert and key\n3) Re-upload correct pair\n4) Save â†’ SDS will push update\n\n---\n\n**B) Incomplete Certificate Chain**\n\nSymptom: Works in curl, fails in browsers\n\nCause: Missing intermediate certificates\n\nCheck chain:\n```bash\nopenssl s_client -connect yourdomain.com:443 -showcerts\n```\n\nYou should see:\n1. Your server certificate\n2. Intermediate CA certificate(s)\n3. (Root CA not needed, in browser trust store)\n\nFix:\n1) Get full chain from CA\n2) Concatenate in order:\n```bash\ncat server.crt intermediate.crt > fullchain.crt\n```\n\n3) Upload to Secret:\n```\n-----BEGIN CERTIFICATE-----\n<your server cert>\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\n<intermediate cert>\n-----END CERTIFICATE-----\n```\n\n---\n\n**C) Certificate Expired**\n\nCheck expiry:\n```bash\nopenssl x509 -noout -enddate -in server.crt\n```\n\nFix: Rotate certificate (see rotation question)\n\n---\n\n**D) Wrong Domain/CN**\n\nCheck certificate subject and SAN:\n```bash\nopenssl x509 -noout -text -in server.crt | grep -A1 \"Subject:\"\nopenssl x509 -noout -text -in server.crt | grep -A1 \"Subject Alternative Name\"\n```\n\nIf CN/SAN doesn't match your domain â†’ Browser shows \"certificate error\"\n\nFix: Request certificate for correct domain\n\n---\n\n**PROBLEM 2: \"TLS context not found\" or \"Secret not loaded\"**\n\n**Debugging Steps:**\n\n**Step 1: Verify Secret Exists**\n1) Navigate to 'Secret' in Elchi\n2) Check secret name matches exactly (case-sensitive)\n3) Verify secret has certificate_chain and private_key\n\n**Step 2: Check TLS Context References Correct Secret**\n1) Navigate to TLS â†’ Your Downstream TLS Context\n2) common_tls_context â†’ tls_certificate_sds_secret_configs\n3) Verify \"name\" field matches secret name exactly\n\n**Step 3: Check Listener References Correct TLS Context**\n1) Navigate to Listener\n2) Filter Chain â†’ transport_socket â†’ typed_config\n3) Verify DownstreamTlsContext name is correct\n\n**Step 4: Check Envoy Config Dump**\n```bash\ncurl localhost:9901/config_dump | jq '.configs[] | select(.\"@type\" | contains(\"Secret\"))'\n```\n\nIf secret missing â†’ SDS not working\n\n**Step 5: Check SDS Connection**\n```bash\ncurl localhost:9901/clusters | grep elchi_sds_cluster\n```\n\nIf unhealthy â†’ Envoy can't reach Elchi SDS server\n\nFix:\n1) Check network connectivity\n2) Verify Bootstrap has correct elchi_sds_cluster\n3) Check Elchi server is running\n\n---\n\n**PROBLEM 3: \"Connection Refused\" on HTTPS Port**\n\n**Debugging:**\n\n**Step 1: Check Listener is Bound**\n```bash\ncurl localhost:9901/listeners\n```\n\nLook for your listener on port 443.\n\nIf missing:\n1) Verify Listener is created in Elchi\n2) Check Service deployment\n3) Reload Envoy service\n\n**Step 2: Check Port is Open**\n```bash\nsudo lsof -i :443\n```\n\nShould show Envoy listening.\n\nIf not:\n1) Check firewall rules\n2) Verify Listener address (0.0.0.0 vs specific IP)\n\n**Step 3: Check Transport Socket**\n\nIn Listener config:\n- Filter Chain must have transport_socket configured\n- typed_config must reference DownstreamTlsContext\n\nFix: Add transport_socket to filter chain\n\n---\n\n**PROBLEM 4: \"Browser shows certificate from wrong domain\"**\n\n**Cause: SNI not working or wrong certificate selected**\n\n**Debugging:**\n\nTest SNI:\n```bash\nopenssl s_client -connect yourdomain.com:443 \\\n  -servername api.yourdomain.com\n```\n\nVerify certificate CN matches requested domain.\n\nIf wrong:\n1) Check certificate SAN includes the domain\n2) Verify filter_chain_match.server_names\n3) Check certificate order (first match wins)\n\nFix:\n1) Add domain to certificate SAN\n2) OR configure SNI matching (see SNI question)\n\n---\n\n**PROBLEM 5: \"mTLS not working - client cert not requested\"**\n\n**Debugging:**\n\n**Step 1: Check require_client_certificate**\n1) Downstream TLS Context\n2) require_client_certificate must be **true**\n\n**Step 2: Check Validation Context**\n1) common_tls_context â†’ validation_context_sds_secret_config\n2) Must reference CA certificate secret\n3) CA secret must exist and contain trusted_ca\n\n**Step 3: Test with curl**\n```bash\n# Should request client cert\ncurl -v https://yourdomain.com/\n```\n\nOutput should show:\n```\n* TLSv1.3 (IN), TLS handshake, Request CERT (13):\n```\n\nIf not requesting cert â†’ Fix validation_context\n\n---\n\n**PROBLEM 6: \"Performance issues / slow HTTPS\"**\n\n**Possible Causes:**\n\n**A) No Session Resumption**\n\nEvery connection does full TLS handshake (expensive).\n\nFix:\n1) Enable session tickets:\n   - Downstream TLS Context\n   - session_ticket_keys_sds_secret_config\n   - Reference session ticket keys secret\n\nOR\n\n2) Enable session cache (in TLS parameters)\n\n**B) Weak Cipher Suites**\n\nCheck negotiated cipher:\n```bash\nopenssl s_client -connect yourdomain.com:443 | grep Cipher\n```\n\nIf using slow ciphers (e.g., CBC mode):\n\nFix:\n1) common_tls_context â†’ tls_params â†’ cipher_suites\n2) Prioritize fast ciphers:\n   - ECDHE-RSA-AES128-GCM-SHA256\n   - ECDHE-RSA-CHACHA20-POLY1305\n\n**C) TLS 1.3 Not Enabled**\n\nTLS 1.3 is faster (1-RTT handshake).\n\nFix:\n1) tls_params â†’ tls_maximum_protocol_version â†’ TLSv1_3\n\n---\n\n**PROBLEM 7: \"Certificate rotation not working\"**\n\n**Debugging:**\n\n**Step 1: Check SDS Stream Active**\n```bash\ncurl localhost:9901/stats | grep sds\n```\n\nMetrics:\n- sds.update_success: Should increment after rotation\n- sds.update_failure: Should be 0\n\nIf update_failure > 0:\n1) Check certificate is valid\n2) Check key matches cert\n3) Review Envoy logs for validation errors\n\n**Step 2: Verify Secret Version Changed**\n\nIn Elchi:\n1) Navigate to Secret\n2) Check \"Updated At\" timestamp\n3) Should reflect recent update\n\nIf not â†’ Secret wasn't actually updated\n\n**Step 3: Force Refresh**\n\nRestart Envoy to force SDS fetch:\n```bash\nsystemctl restart envoy\n```\n\nIf new cert loads after restart â†’ SDS push failed, investigate network/Elchi logs\n\n---\n\n**DEBUGGING COMMANDS CHEAT SHEET:**\n\n**Check certificate details:**\n```bash\n# Expiry date\nopenssl x509 -noout -enddate -in cert.crt\n\n# Subject and SAN\nopenssl x509 -noout -text -in cert.crt | grep -E \"Subject:|DNS:\"\n\n# Certificate chain\nopenssl s_client -connect domain.com:443 -showcerts\n\n# Check key matches cert\nopenssl x509 -noout -modulus -in cert.crt | openssl md5\nopenssl rsa -noout -modulus -in key.key | openssl md5\n```\n\n**Check Envoy TLS config:**\n```bash\n# Loaded secrets\ncurl localhost:9901/config_dump | jq '.configs[] | select(.\"@type\" | contains(\"Secret\"))'\n\n# Listeners\ncurl localhost:9901/listeners\n\n# Clusters (SDS cluster health)\ncurl localhost:9901/clusters | grep elchi_sds_cluster\n\n# TLS statistics\ncurl localhost:9901/stats | grep tls\ncurl localhost:9901/stats | grep sds\n```\n\n**Test TLS connection:**\n```bash\n# Basic test\ncurl -v https://domain.com/\n\n# With SNI\nopenssl s_client -connect domain.com:443 -servername api.domain.com\n\n# With client cert (mTLS)\ncurl --cert client.crt --key client.key https://domain.com/\n\n# Check cipher\nopenssl s_client -connect domain.com:443 | grep Cipher\n\n# Check TLS version\nopenssl s_client -connect domain.com:443 | grep Protocol\n```\n\n---\n\n**ENVOY LOGS:**\n\nEnable debug logging for TLS:\n\n```bash\n# Runtime log level change (via admin API)\ncurl -X POST localhost:9901/logging?level=debug\n\n# View logs\njournalctl -u envoy -f | grep -i tls\n```\n\nLook for:\n- \"tls_inspector\": SNI detection\n- \"sds\": Secret fetching\n- \"handshake failed\": TLS errors with details\n\n---\n\n**COMMON ERROR MESSAGES:**\n\n**\"SSL routines:tls_process_client_hello:no shared cipher\"**\n- Cause: No common cipher suites between client and server\n- Fix: Broaden cipher_suites in tls_params\n\n**\"SSL routines:tls_process_client_hello:unsupported protocol\"**\n- Cause: Client using TLS version not supported\n- Fix: Adjust tls_minimum_protocol_version (e.g., allow TLSv1_2)\n\n**\"SSL routines:tls_process_server_certificate:certificate verify failed\"**\n- Cause: Certificate not trusted (self-signed, expired, or incomplete chain)\n- Fix: Provide full certificate chain\n\n**\"unable to get local issuer certificate\"**\n- Cause: Missing intermediate certificate\n- Fix: Add intermediate to certificate_chain\n\n---\n\n**BEST PRACTICES FOR AVOIDING TLS ISSUES:**\n\nâœ… **Always test certificates before deploying:**\n```bash\nopenssl verify -CAfile ca.crt fullchain.crt\n```\n\nâœ… **Use full certificate chain (server + intermediates)**\n\nâœ… **Monitor certificate expiry:**\n- Alert 60 days before expiry\n- Automate rotation\n\nâœ… **Use SDS for production:**\n- Easier debugging (centralized)\n- Zero-downtime rotation\n\nâœ… **Enable TLS 1.3:**\n- Faster, more secure\n\nâœ… **Test in staging first:**\n- Rotate cert in staging\n- Monitor for 24h\n- Then rotate in production\n\nâš ï¸ **Security:**\n- Never use self-signed certs in production\n- Rotate certificates regularly (90 days for Let's Encrypt)\n- Use strong cipher suites\n- Disable TLS 1.0/1.1 (deprecated)"}
{"resource":"HTTPFilter","category":"basics","instruction":"What is HTTP filter and how to add it to listener?","output":"HTTP FILTER BASICS AND ADDING:\n\n1) WHAT IS HTTP FILTER:\n   - HTTP-level request/response processing\n   - Works inside HTTP Connection Manager (HCM)\n   - Processed sequentially as filter chain\n   - Last filter must be Router\n\n2) FILTER CATEGORIES:\n   - Authentication: Basic Auth, OAuth2\n   - Authorization: RBAC (role-based access control)\n   - Security: CORS, CSRF, WAF (Wasm)\n   - Traffic Control: Rate limit, bandwidth limit, admission control\n   - Transformation: Compressor, buffer, Lua\n   - Session: Stateful session\n   - Routing: Router (required)\n\n3) HTTP FILTER ADDING STEPS:\n   \n   a) EXPAND LISTENER:\n      - In Resources â†’ Listener tab\n      - Click relevant listener row (expand)\n   \n   b) GO TO HTTP CONNECTION MANAGER:\n      - When listener expanded, 'Filters' tab appears inside\n      - Find 'HTTP Connection Manager' card\n      - (If not exists, first add HCM network filter)\n   \n   c) SWITCH TO HTTP FILTERS TAB:\n      - Select 'Filters' tag from HCM card left menu\n      - 'HTTP Filters' section opens on right\n      - Blue '+' button in HTTP Filters card\n   \n   d) FILTER SELECTION WINDOW:\n      - Click blue '+' button\n      - Drawer (filter selection window) opens from right\n      - 15 different HTTP filters listed:\n        * Adaptive Concurrency\n        * Admission Control\n        * Bandwidth Limit\n        * Basic Auth\n        * Buffer\n        * Compressor\n        * CORS\n        * CSRF Policy\n        * Local Rate Limit\n        * Lua\n        * OAuth2\n        * RBAC\n        * Router\n        * Stateful Session\n        * Wasm\n   \n   e) SELECT AND CONFIGURE FILTER:\n      - Select desired filter (e.g., CORS)\n      - Drawer closes\n      - Added to HTTP Filters list\n      - Expand filter (click row)\n      - Select tags from left menu and configure\n   \n   f) ADD ROUTER FILTER:\n      - âš  Router filter must be at the end\n      - If not exists, add (select 'Router' from drawer)\n      - Listener won't work without Router\n\n4) FILTER ORDERING:\n   - Filters processed sequentially (top to bottom)\n   - Correct ordering:\n     1. Authentication (Basic Auth, OAuth2)\n     2. Authorization (RBAC)\n     3. Security (CORS, WAF)\n     4. Rate Limiting\n     5. Transformation (Compressor, Buffer)\n     6. Custom (Lua, Wasm)\n     7. Router (LAST)\n   \n   - Change ordering:\n     * Up/down arrow buttons on filter row\n     * Click to change ordering\n\n5) FILTER DELETION:\n   - Red trash icon on filter row\n   - Click to delete filter\n   âš  If Router filter deleted, listener won't work\n\n6) IMPORTANT NOTES:\n   âš  Router filter required (must be last)\n   âš  Filter ordering very important (wrong order causes unexpected behavior)\n   âš  Each filter requires different configuration"}
{"resource":"HTTPFilter","category":"cors","instruction":"How to configure CORS filter?","output":"CORS FILTER CONFIGURATION:\n\n1) WHAT IS CORS:\n   - Cross-Origin Resource Sharing\n   - Browser security policy\n   - Allows API calls from different domains\n   - Example: frontend (app.example.com) â†’ API (api.example.com)\n\n2) ADDING CORS FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'Cors' from drawer\n   c) CORS filter added to list\n\n3) CREATING CORS FILTER RESOURCE:\n   - CORS filter created as standalone resource\n   - From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'Cors'\n   - 'Create Cors' button at top right\n   - Click opens creation page\n   - âš  No fields in CORS filter, just name and save\n\n4) CORS POLICY CONFIGURATION:\n   CORS policy actually configured at Route or Virtual Host level\n   \n   a) AT ROUTE LEVEL:\n      - Select 'typed_per_filter_config' tag in route details\n      - Click blue '+' button\n      - Filter name: envoy.filters.http.cors\n      - Configure CorsPolicy in config section:\n   \n   b) CORS POLICY FIELDS:\n      \n      - allow_origin_string_match (Allowed origins):\n        * Add origin with blue '+'\n        * exact: \"https://app.example.com\"\n        * prefix: \"https://\"\n        * suffix: \".example.com\"\n        * safe_regex: \".*\\.example\\.com\"\n      \n      - allow_methods (Allowed HTTP methods):\n        * String list\n        * Example: GET, POST, PUT, DELETE, OPTIONS\n      \n      - allow_headers (Allowed headers):\n        * String list\n        * Example: Content-Type, Authorization, X-Requested-With\n      \n      - expose_headers (Headers to expose to client):\n        * String list\n        * Example: X-Custom-Header, X-Rate-Limit\n      \n      - max_age (Preflight cache duration):\n        * Duration format\n        * Example: 3600s (1 hour)\n      \n      - allow_credentials:\n        * Boolean\n        * true: Allow cookies and authentication headers\n        * false: Don't allow credentials\n      \n      - allow_private_network_access:\n        * Boolean\n        * Allow private network (localhost, 192.168.x.x) access\n\n5) EXAMPLE CORS CONFIGURATION:\n   \n   Scenario: SPA frontend (https://app.example.com) â†’ API (https://api.example.com)\n   \n   Route configuration:\n   - typed_per_filter_config â†’ envoy.filters.http.cors\n   - CorsPolicy:\n     * allow_origin_string_match:\n       - exact: \"https://app.example.com\"\n     * allow_methods: [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"]\n     * allow_headers: [\"Content-Type\", \"Authorization\"]\n     * expose_headers: [\"X-Request-Id\"]\n     * max_age: 86400s (24 hours)\n     * allow_credentials: true\n\n6) WILDCARD ORIGIN (ALLOW ALL ORIGINS):\n   \n   âš  Security risk, use only for development\n   \n   allow_origin_string_match:\n   - safe_regex:\n       regex: \".*\"\n   \n   allow_credentials: false (cannot use true with wildcard)\n\n7) MULTIPLE ORIGINS:\n   \n   allow_origin_string_match:\n   - exact: \"https://app.example.com\"\n   - exact: \"https://admin.example.com\"\n   - suffix: \".partner.com\"\n\n8) PREFLIGHT REQUEST:\n   - Browser sends OPTIONS request (preflight)\n   - CORS policy checked\n   - If allowed: 200 OK + CORS headers\n   - If not allowed: 403 Forbidden\n   - max_age: Preflight cache duration (in browser)\n\n9) CORS DEBUGGING:\n   \n   Problem: Getting CORS error\n   Solution:\n   - Read error in browser console:\n     * \"Access-Control-Allow-Origin\" missing: allow_origin missing\n     * \"Access-Control-Allow-Methods\" missing: allow_methods missing\n     * \"Credentials flag is 'true'\": allow_credentials + wildcard conflict\n   - Check Envoy access log:\n     * Does OPTIONS request return 200\n   - Check if CORS policy on correct route\n\n10) IMPORTANT NOTES:\n    âš  CORS filter must be in HCM (before route policy)\n    âš  Define policy at route level (typed_per_filter_config)\n    âš  Wildcard origin + credentials = error\n    âš  OPTIONS request handling automatic (by Envoy)"}
{"resource":"HTTPFilter","category":"rbac", "instruction": "How to do authorization with HTTP RBAC filter?", "output": "HTTP RBAC (ROLE-BASED ACCESS CONTROL):\n\n1) WHAT IS HTTP RBAC:\n   - HTTP-level authorization\n   - Access control based on path, header, source IP\n   - Policy-based: Rules + Policies\n   - Different from Network RBAC: Accesses HTTP features (path, header, method)\n\n2) ADDING RBAC FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'RBAC' from drawer\n   c) RBAC filter added to list\n\n3) CREATING RBAC RESOURCE:\n   a) From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'RBAC'\n   b) 'Create RBAC' button at top right\n   c) Creation page opens\n   d) Tags in left menu: rules, shadow_rules\n\n4) RBAC RULES CONFIGURATION:\n   \n   a) Select 'rules' tag\n   b) 'Rules' card opens\n   c) In left menu: action, policies\n   \n   d) ACTION SELECTION:\n      - Select 'action' tag\n      - Select from dropdown:\n        * ALLOW: Allow (whitelist)\n        * DENY: Deny (blacklist)\n        * LOG: Just log (allow but record)\n   \n   e) ADDING POLICIES:\n      - Select 'policies' tag\n      - 'Policies' card opens\n      - Click blue '+' button\n      - Policy drawer opens\n\n5) POLICY CONFIGURATION:\n   \n   Policy = Permissions + Principals\n   (\"WHO can do WHAT\")\n   \n   a) POLICY NAME:\n      - Give policy name (e.g., \"admin-only\")\n   \n   b) PERMISSIONS (What can be done):\n      - Select 'permissions' tag\n      - Add permission with blue '+'\n      - Permission types:\n        \n        * ANY (everything allowed):\n          - any: true\n        \n        * AND (all required):\n          - and_rules: [rule1, rule2, rule3]\n        \n        * OR (one sufficient):\n          - or_rules: [rule1, rule2]\n        \n        * Header Matching:\n          - header:\n            * name: \"x-admin\"\n            * exact_match: \"true\"\n        \n        * Path Matching:\n          - url_path:\n            * path:\n              - exact: \"/admin\"\n              - prefix: \"/api/admin\"\n              - safe_regex: \"/api/v[0-9]+/admin\"\n        \n        * Destination IP:\n          - destination_ip:\n            * address_prefix: \"10.0.0.0\"\n            * prefix_len: 8\n        \n        * Destination Port:\n          - destination_port: 443\n        \n        * Method Matching:\n          - metadata:\n            * filter: \"envoy.filters.http.method_match\"\n            * method: \"POST\"\n   \n   c) PRINCIPALS (Who can access):\n      - Select 'principals' tag\n      - Add principal with blue '+'\n      - Principal types:\n        \n        * ANY (everyone):\n          - any: true\n        \n        * Source IP:\n          - remote_ip:\n            * address_prefix: \"192.168.1.0\"\n            * prefix_len: 24\n        \n        * Header Matching:\n          - header:\n            * name: \"Authorization\"\n            * prefix_match: \"Bearer \"\n        \n        * Authenticated:\n          - authenticated:\n            * principal_name:\n              - exact: \"user@example.com\"\n              - suffix: \"@example.com\"\n\n6) EXAMPLE 1 - ADMIN PATH PROTECTION:\n   \n   Scenario: /admin accessible only from 192.168.1.0/24 network\n   \n   Rules:\n   - action: ALLOW\n   - policies:\n     * Policy: \"admin-access\"\n       - permissions:\n         * url_path:\n           - path:\n             - prefix: \"/admin\"\n       - principals:\n         * remote_ip:\n           - address_prefix: \"192.168.1.0\"\n           - prefix_len: 24\n\n7) EXAMPLE 2 - HEADER-BASED AUTHORIZATION:\n   \n   Scenario: Those with X-Admin: true header can access all API\n   \n   Rules:\n   - action: ALLOW\n   - policies:\n     * Policy: \"admin-header\"\n       - permissions:\n         * url_path:\n           - path:\n             - prefix: \"/api\"\n       - principals:\n         * header:\n           - name: \"X-Admin\"\n           - exact_match: \"true\"\n\n8) EXAMPLE 3 - METHOD-BASED RESTRICTION:\n   \n   Scenario: POST/PUT/DELETE only for authenticated users\n   \n   Rules:\n   - action: DENY\n   - policies:\n     * Policy: \"write-methods-deny\"\n       - permissions:\n         * or_rules:\n           - metadata: {method: \"POST\"}\n           - metadata: {method: \"PUT\"}\n           - metadata: {method: \"DELETE\"}\n       - principals:\n         * not_id:\n           - authenticated: {}\n\n9) SHADOW RULES:\n   - shadow_rules: Don't actually allow, just log\n   - Used for testing before production\n   - Test scenario:\n     a) Add new policy to shadow_rules\n     b) Observe impact in logs (how many requests would be blocked)\n     c) Move to rules if no issues\n\n10) RBAC TESTING:\n    \n    a) Test Request:\n       ```bash\n       # Admin path:\n       curl -v http://listener-ip:port/admin\n       \n       # With header:\n       curl -v -H \"X-Admin: true\" http://listener-ip:port/api\n       \n       # From different IP:\n       curl -v --interface 10.0.0.5 http://listener-ip:port/admin\n       ```\n    \n    b) Expected Result:\n       - If allowed: 200 OK (upstream response)\n       - If not allowed: 403 Forbidden\n       - Log action: 200 OK + log entry\n    \n    c) Log Check:\n       - Search with \"rbac\" filter in Logs tab\n       - Denied requests:\n         ```\n         [rbac] Policy \"admin-access\" denied request\n         ```\n\n11) TROUBLESHOOTING:\n    \n    Problem: RBAC always returns 403\n    Solution:\n    - Check if action is ALLOW\n    - Does at least one principal match\n    - Does at least one permission match\n    - Is it in shadow rules (shadow doesn't actually block)\n    \n    Problem: RBAC not working at all\n    Solution:\n    - Does RBAC filter exist in HCM\n    - Is filter ordering correct (before Router)\n    - Is policy not empty\n\n12) BEST PRACTICES:\n    âœ… Use default DENY + explicit ALLOW\n    âœ… Test with shadow_rules first\n    âœ… Specific policy for specific paths\n    âœ… Combine IP whitelist + path matching\n    âš  Use ANY principal carefully (security risk)\n    âš  Watch regex performance"}
{"resource":"HTTPFilter","category":"compressor", "instruction": "How to do response compression with Compressor filter?", "output": "COMPRESSOR FILTER (RESPONSE COMPRESSION):\n\n1) WHAT IS COMPRESSOR:\n   - HTTP response compression\n   - Bandwidth savings\n   - Supported algorithms: gzip, brotli\n   - Request and response direction can be configured separately\n\n2) ADDING COMPRESSOR FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'Compressor' from drawer\n   c) Compressor filter added to list\n\n3) CREATING COMPRESSOR RESOURCE:\n   a) From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'Compressor'\n   b) 'Create Compressor' button at top right\n   c) Creation page opens\n   d) Tags in left menu:\n      - compressor_library\n      - request_direction_config\n      - response_direction_config\n      - remove_accept_encoding_header\n      - content_length, content_type, disable_on_etag_header\n\n4) COMPRESSOR LIBRARY SELECTION:\n   \n   a) Select 'compressor_library' tag\n   b) 'Compressor Library' card opens\n   c) Horizontal tags: name, typed_config\n   \n   d) NAME:\n      - Select 'name' tag\n      - Give extension name (e.g., \"envoy.compression.gzip.compressor\")\n   \n   e) TYPED_CONFIG:\n      - Select 'typed_config' tag\n      - Select from '@type' dropdown:\n        * Gzip: type.googleapis.com/envoy.extensions.compression.gzip.compressor.v3.Gzip\n        * Brotli: type.googleapis.com/envoy.extensions.compression.brotli.compressor.v3.Brotli\n      \n      - GZIP SETTINGS:\n        * compression_level: 1-9 (default: 6)\n          - 1: Fast, low compression\n          - 9: Slow, high compression\n        * compression_strategy: DEFAULT, FILTERED, HUFFMAN_ONLY, RLE, FIXED\n        * memory_level: 1-9 (default: 5)\n        * window_bits: 9-15 (default: 12)\n      \n      - BROTLI SETTINGS:\n        * quality: 0-11 (default: 6)\n        * encoder_mode: GENERIC, TEXT, FONT\n        * window_bits: 10-24\n        * block_bits: 16-24\n\n5) RESPONSE DIRECTION CONFIG:\n   \n   a) Select 'response_direction_config' tag\n   b) 'Response Direction Config' card opens\n   c) Horizontal tags:\n      - common_config\n      - disable_on_etag_header\n   \n   d) COMMON_CONFIG:\n      - Select 'common_config' tag\n      - min_content_length: Minimum bytes (e.g., 1024)\n        * Responses smaller than 1024 not compressed\n      - content_type: MIME type list\n        * Example: [\"text/html\", \"application/json\", \"text/css\", \"application/javascript\"]\n      - enabled: Boolean (default: true)\n   \n   e) DISABLE_ON_ETAG_HEADER:\n      - Boolean\n      - true: Don't compress if ETag header exists\n      - false: Compress if ETag exists (important for caching)\n\n6) REQUEST DIRECTION CONFIG:\n   \n   - request_direction_config: Decompress incoming request\n   - Rarely used (rare use case)\n   - If client sends with gzip, Envoy decompresses\n\n7) EXAMPLE CONFIGURATION - GZIP:\n   \n   Compressor resource:\n   - compressor_library:\n     * name: \"envoy.compression.gzip.compressor\"\n     * typed_config:\n       - @type: Gzip\n       - compression_level: 6\n       - window_bits: 12\n   \n   - response_direction_config:\n     * common_config:\n       - min_content_length: 1024\n       - content_type:\n         * \"text/html\"\n         * \"application/json\"\n         * \"text/css\"\n         * \"application/javascript\"\n         * \"text/plain\"\n       - enabled: true\n     * disable_on_etag_header: false\n\n8) EXAMPLE CONFIGURATION - BROTLI:\n   \n   Compressor resource:\n   - compressor_library:\n     * name: \"envoy.compression.brotli.compressor\"\n     * typed_config:\n       - @type: Brotli\n       - quality: 8 (high compression)\n       - encoder_mode: TEXT\n       - window_bits: 20\n\n9) CONTENT-TYPE FILTERING:\n   \n   Which content-types should be compressed:\n   âœ… text/html, text/css, application/javascript\n   âœ… application/json, application/xml, text/plain\n   âœ… image/svg+xml\n   \n   Which should NOT be compressed:\n   âŒ image/jpeg, image/png (already compressed)\n   âŒ video/mp4, audio/mp3 (compressed)\n   âŒ application/zip, application/gzip (compressed)\n\n10) COMPRESSION TESTING:\n    \n    a) Test request:\n       ```bash\n       # With gzip support:\n       curl -v -H \"Accept-Encoding: gzip\" http://listener-ip:port/api/data\n       \n       # With brotli support:\n       curl -v -H \"Accept-Encoding: br\" http://listener-ip:port/api/data\n       \n       # Both:\n       curl -v -H \"Accept-Encoding: gzip, br\" http://listener-ip:port/\n       ```\n    \n    b) Response header check:\n       ```\n       Content-Encoding: gzip\n       ```\n       or\n       ```\n       Content-Encoding: br\n       ```\n    \n    c) Compression ratio check:\n       ```bash\n       # Compressed:\n       curl -H \"Accept-Encoding: gzip\" http://listener-ip:port/ | wc -c\n       \n       # Uncompressed:\n       curl http://listener-ip:port/ | wc -c\n       ```\n\n11) PERFORMANCE CONSIDERATIONS:\n    \n    - Compression level trade-off:\n      * Level 1-3: Fast, low CPU, low compression ratio\n      * Level 6: Balanced (recommended)\n      * Level 9: Slow, high CPU, high compression ratio\n    \n    - Min content length:\n      * Don't compress below 1024 bytes (overhead is more)\n      * 2048 bytes recommended for JSON API\n    \n    - Gzip vs Brotli:\n      * Gzip: Faster, more widely supported\n      * Brotli: Better compression, slightly slower\n\n12) TROUBLESHOOTING:\n    \n    Problem: Response not being compressed\n    Solution:\n    - Does Accept-Encoding header exist (client side)\n    - Is Content-Type in content_type list\n    - Is Content-Length greater than min_content_length\n    - Is response_direction_config enabled: true\n    \n    Problem: ETag header disappeared\n    Solution:\n    - Set disable_on_etag_header: true (preserves ETag)\n    \n    Problem: Binary file being compressed (unnecessary)\n    Solution:\n    - Narrow content_type list (only text/* and application/json)"}
{"resource":"HTTPFilter","category":"rate_limit", "instruction": "How to configure HTTP Local Rate Limit filter?", "output": "HTTP LOCAL RATE LIMIT FILTER:\n\n1) WHAT IS RATE LIMIT:\n   - Request count limiting (throttling)\n   - DDoS protection, API quota\n   - Local: Per Envoy instance (not global)\n   - Separate filter exists for global rate limit (requires external rate limit service)\n\n2) ADDING LOCAL RATE LIMIT FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'Local Ratelimit' from drawer\n   c) Filter added to list\n\n3) CREATING LOCAL RATE LIMIT RESOURCE:\n   a) From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'Local Ratelimit'\n   b) 'Create' button at top right\n   c) Creation page opens\n   d) Tags in left menu:\n      - stat_prefix\n      - token_bucket\n      - filter_enabled, filter_enforced\n      - response_headers_to_add\n      - local_rate_limit_per_downstream_connection\n\n4) TOKEN BUCKET CONFIGURATION:\n   \n   Token bucket algorithm:\n   - If tokens in bucket â†’ request passes, token decreases\n   - If bucket empty â†’ request rejected (429 Too Many Requests)\n   - Tokens regularly added (fill_interval)\n   \n   a) Select 'token_bucket' tag\n   b) 'Token Bucket' card opens\n   c) Fields:\n      \n      - max_tokens (Bucket capacity):\n        * Maximum number of tokens\n        * Example: 100 (for burst)\n      \n      - tokens_per_fill (Tokens added per fill):\n        * Example: 10\n      \n      - fill_interval (Fill interval):\n        * Duration format\n        * Example: 1s (10 tokens every second)\n        * Rate: 10 req/sec\n\n5) FILTER ENABLED AND ENFORCED:\n   \n   a) FILTER_ENABLED:\n      - Horizontal tags: runtime_key, default_value, numerator, denominator\n      - default_value:\n        * numerator: 100\n        * denominator: HUNDRED\n        * Meaning: Check rate limit on 100% of requests\n   \n   b) FILTER_ENFORCED:\n      - Horizontal tags: runtime_key, default_value, numerator, denominator\n      - default_value:\n        * numerator: 100\n        * denominator: HUNDRED\n        * Meaning: Reject on 100% of rate limit violations\n      - If numerator: 0 â†’ dry-run mode (just log, don't reject)\n\n6) RESPONSE HEADERS:\n   \n   - response_headers_to_add: Add rate limit headers\n   - Add header with blue '+'\n   - Recommended headers:\n     * X-RateLimit-Limit: {max_tokens}\n     * X-RateLimit-Remaining: {remaining_tokens}\n     * X-RateLimit-Reset: {reset_time}\n\n7) PER-CONNECTION RATE LIMIT:\n   \n   - local_rate_limit_per_downstream_connection: true\n   - Separate token bucket per connection\n   - Use case: Limit per connection (e.g., WebSocket)\n\n8) EXAMPLE 1 - BASIC RATE LIMIT:\n   \n   Scenario: 100 req/sec limit\n   \n   token_bucket:\n   - max_tokens: 100\n   - tokens_per_fill: 100\n   - fill_interval: 1s\n   \n   filter_enabled:\n   - default_value:\n     * numerator: 100\n     * denominator: HUNDRED\n   \n   filter_enforced:\n   - default_value:\n     * numerator: 100\n     * denominator: HUNDRED\n\n9) EXAMPLE 2 - BURST HANDLING:\n   \n   Scenario: Steady 10 req/sec, allow burst up to 50\n   \n   token_bucket:\n   - max_tokens: 50 (burst capacity)\n   - tokens_per_fill: 10 (steady rate)\n   - fill_interval: 1s\n   \n   Explanation:\n   - Normal: 10 req/sec processed\n   - Burst: 50 requests can come instantly (if bucket full)\n   - Then: Drops to 10 req/sec (token refill rate)\n\n10) EXAMPLE 3 - DRY-RUN MODE:\n    \n    Scenario: Test rate limit but don't reject\n    \n    filter_enforced:\n    - default_value:\n      * numerator: 0 (don't reject)\n      * denominator: HUNDRED\n    \n    Result:\n    - Even if rate limit exceeded, returns 200 OK\n    - But rate limit violation visible in logs\n\n11) ROUTE LEVEL OVERRIDE:\n    \n    In route details:\n    - typed_per_filter_config â†’ envoy.filters.http.local_ratelimit\n    - LocalRateLimitPerRoute:\n      * token_bucket: {different settings}\n      * Different limit for specific route\n\n12) RATE LIMIT TESTING:\n    \n    a) Test script:\n       ```bash\n       # Send 200 requests:\n       for i in {1..200}; do\n         curl -v http://listener-ip:port/api\n       done\n       ```\n    \n    b) Expected result:\n       - First 100: 200 OK\n       - Next: 429 Too Many Requests\n       - Response headers:\n         ```\n         X-RateLimit-Limit: 100\n         X-RateLimit-Remaining: 0\n         ```\n    \n    c) Log check:\n       - In access log:\n         ```\n         429 - ratelimited\n         ```\n\n13) TROUBLESHOOTING:\n    \n    Problem: Rate limit not working at all\n    Solution:\n    - Does filter exist in HCM\n    - Is filter_enforced numerator > 0\n    - Is token_bucket configured\n    \n    Problem: Too aggressive blocking\n    Solution:\n    - Increase max_tokens (burst capacity)\n    - Shorten fill_interval (faster token refill)\n    - Activate dry-run mode (numerator: 0)\n\n14) BEST PRACTICES:\n    âœ… max_tokens = burst capacity (2x-5x steady rate)\n    âœ… fill_interval = 1s (for simplicity)\n    âœ… Test with dry-run mode\n    âœ… Add response headers (client notification)\n    âš  Use external service for global rate limit\n    âš  Use per-connection carefully (resource consumption)"}
{"resource":"HTTPFilter","category":"lua", "instruction": "How to run custom scripts with Lua filter?", "output": "LUA FILTER (CUSTOM SCRIPTING):\n\n1) WHAT IS LUA FILTER:\n   - Run custom Lua scripts in HTTP filter chain\n   - Request/response manipulation\n   - Dynamic routing, header modification, logging\n   - Uses Lua 5.1 runtime\n\n2) ADDING LUA FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'Lua' from drawer\n   c) Lua filter added to list\n\n3) CREATING LUA RESOURCE:\n   a) From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'Lua'\n   b) 'Create Lua' button at top right\n   c) Creation page opens\n   d) Tags in left menu:\n      - default_source_code\n      - source_codes\n      - stat_prefix\n\n4) DEFAULT SOURCE CODE:\n\n   a) Select 'default_source_code' tag\n   b) 'Default Source Code' card opens\n   c) Horizontal tags: inline_string, filename\n\n   d) INLINE_STRING (Direct code):\n      - Select 'inline_string' tag\n      - Textarea opens\n      - Write Lua script\n\n   e) FILENAME (Load from file):\n      - Select 'filename' tag\n      - Give file path (e.g., /etc/envoy/lua/script.lua)\n      - âš  File must be in elchi-client\n\n5) LUA SCRIPT STRUCTURE:\n\n   Basic template:\n   ```lua\n   function envoy_on_request(request_handle)\n     -- Request processing\n   end\n\n   function envoy_on_response(response_handle)\n     -- Response processing\n   end\n   ```\n\n6) REQUEST HANDLE API:\n\n   a) READING HEADERS:\n      ```lua\n      function envoy_on_request(rh)\n        local auth = rh:headers():get(\"Authorization\")\n        if auth == nil then\n          rh:respond({[\":status\"] = \"401\"}, \"Unauthorized\")\n        end\n      end\n      ```\n\n   b) ADDING/MODIFYING HEADERS:\n      ```lua\n      function envoy_on_request(rh)\n        rh:headers():add(\"X-Custom-Header\", \"value\")\n        rh:headers():replace(\"User-Agent\", \"CustomAgent/1.0\")\n        rh:headers():remove(\"X-Unwanted-Header\")\n      end\n      ```\n\n   c) READING BODY:\n      ```lua\n      function envoy_on_request(rh)\n        local body = rh:body():getBytes(0, rh:body():length())\n        -- body processing\n      end\n      ```\n\n   d) READING METADATA:\n      ```lua\n      function envoy_on_request(rh)\n        local path = rh:headers():get(\":path\")\n        local method = rh:headers():get(\":method\")\n        rh:logInfo(string.format(\"%s %s\", method, path))\n      end\n      ```\n\n   e) SENDING RESPONSE:\n      ```lua\n      function envoy_on_request(rh)\n        rh:respond(\n          {[\":status\"] = \"200\", [\"content-type\"] = \"application/json\"},\n          '{\"message\": \"Hello from Lua\"}'\n        )\n      end\n      ```\n\n7) RESPONSE HANDLE API:\n\n   a) READING RESPONSE HEADERS:\n      ```lua\n      function envoy_on_response(rh)\n        local status = rh:headers():get(\":status\")\n        if status == \"500\" then\n          rh:logError(\"Upstream returned 500\")\n        end\n      end\n      ```\n\n   b) ADDING RESPONSE HEADERS:\n      ```lua\n      function envoy_on_response(rh)\n        rh:headers():add(\"X-Response-Time\", os.time())\n        rh:headers():add(\"X-Powered-By\", \"Envoy\")\n      end\n      ```\n\n   c) READING RESPONSE BODY:\n      ```lua\n      function envoy_on_response(rh)\n        local body = rh:body():getBytes(0, rh:body():length())\n        -- body manipulation\n      end\n      ```\n\n8) LOGGING:\n\n   ```lua\n   function envoy_on_request(rh)\n     rh:logTrace(\"Trace log\")    -- Trace level\n     rh:logDebug(\"Debug log\")    -- Debug level\n     rh:logInfo(\"Info log\")      -- Info level\n     rh:logWarn(\"Warning log\")   -- Warning level\n     rh:logErr(\"Error log\")      -- Error level\n     rh:logCritical(\"Critical\")  -- Critical level\n   end\n   ```\n\n9) EXAMPLE 1 - AUTH HEADER CHECK:\n\n   ```lua\n   function envoy_on_request(rh)\n     local auth = rh:headers():get(\"Authorization\")\n\n     if auth == nil or auth == \"\" then\n       rh:respond(\n         {[\":status\"] = \"401\", [\"content-type\"] = \"application/json\"},\n         '{\"error\": \"Missing Authorization header\"}'\n       )\n       return\n     end\n\n     -- Validate token (example: Bearer prefix)\n     if not string.match(auth, \"^Bearer \") then\n       rh:respond(\n         {[\":status\"] = \"401\"},\n         '{\"error\": \"Invalid Authorization format\"}'\n       )\n       return\n     end\n\n     rh:logInfo(\"Auth header validated\")\n   end\n   ```\n\n10) EXAMPLE 2 - CUSTOM ROUTING:\n\n    ```lua\n    function envoy_on_request(rh)\n      local path = rh:headers():get(\":path\")\n      local user_agent = rh:headers():get(\"User-Agent\")\n\n      -- Route mobile users to different upstream\n      if string.match(user_agent, \"Mobile\") then\n        rh:headers():add(\"X-Upstream-Cluster\", \"mobile_backend\")\n      else\n        rh:headers():add(\"X-Upstream-Cluster\", \"web_backend\")\n      end\n\n      rh:logInfo(\"Routed to \" .. rh:headers():get(\"X-Upstream-Cluster\"))\n    end\n    ```\n\n11) EXAMPLE 3 - RESPONSE TRANSFORMATION:\n\n    ```lua\n    function envoy_on_response(rh)\n      local status = rh:headers():get(\":status\")\n\n      -- Make 500 errors user-friendly\n      if status == \"500\" then\n        rh:body():setBytes('{\"error\": \"Service temporarily unavailable\"}')\n        rh:headers():replace(\"content-type\", \"application/json\")\n      end\n\n      -- Add security headers\n      rh:headers():add(\"X-Content-Type-Options\", \"nosniff\")\n      rh:headers():add(\"X-Frame-Options\", \"DENY\")\n      rh:headers():add(\"X-XSS-Protection\", \"1; mode=block\")\n    end\n    ```\n\n12) MULTIPLE SOURCE CODES:\n\n    - source_codes: Different scripts for different routes\n    - Route level override\n    - Rarely used (default_source_code usually sufficient)\n\n13) PERFORMANCE CONSIDERATIONS:\n\n    âš  Lua script runs for every request (adds latency)\n    âš  Body reading is expensive (requires buffering)\n    âš  Avoid complex computations (CPU intensive)\n    âœ… Ideal for simple header manipulation\n    âœ… Good for logging/metrics\n\n14) DEBUGGING:\n\n    a) Add logging:\n       ```lua\n       rh:logInfo(\"Debug: \" .. tostring(variable))\n       ```\n\n    b) Check Envoy logs:\n       ```bash\n       tail -f /var/log/envoy/envoy.log | grep lua\n       ```\n\n    c) Script syntax error:\n       - Envoy fails at startup\n       - Lua syntax error appears in error log\n\n15) IMPORTANT NOTES:\n    âš  Lua script error â†’ 500 Internal Server Error\n    âš  respond() call terminates request (doesn't go to upstream)\n    âš  Body read/write requires buffering (memory)\n    âœ… Use lightweight scripts in production\n    âœ… For complex logic prefer Wasm or external service"}
{"resource":"HTTPFilter","category":"oauth2", "instruction": "How to do authentication with OAuth2 filter?", "output": "OAUTH2 FILTER (AUTHENTICATION):\n\n1) WHAT IS OAUTH2 FILTER:\n   - OAuth 2.0 authorization code flow\n   - Third-party authentication (Google, GitHub, Okta, etc.)\n   - Token-based authentication\n   - Envoy acts as OAuth client proxy\n\n2) ADDING OAUTH2 FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'OAuth2' from drawer\n   c) OAuth2 filter added to list\n\n3) CREATING OAUTH2 RESOURCE:\n   a) From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'OAuth2'\n   b) 'Create OAuth2' button at top right\n   c) Creation page opens\n   d) Tags in left menu:\n      - config\n      - (within config: token_endpoint, authorization_endpoint, credentials, redirect_uri, etc.)\n\n4) OAUTH2 CONFIG CONFIGURATION:\n\n   a) Select 'config' tag\n   b) 'OAuth2 Config' card opens\n   c) Horizontal tags:\n      - token_endpoint\n      - authorization_endpoint\n      - credentials\n      - redirect_uri\n      - redirect_path_matcher\n      - signout_path\n      - forward_bearer_token\n      - auth_scopes\n\n5) TOKEN ENDPOINT:\n\n   - OAuth provider's token endpoint\n   - Select 'token_endpoint' tag\n   - Horizontal tags: cluster, uri, timeout\n\n   a) CLUSTER:\n      - Envoy cluster name (for OAuth provider)\n      - Example: \"oauth_provider_cluster\"\n      - âš  This cluster must be created beforehand\n\n   b) URI:\n      - Token endpoint path\n      - Examples:\n        * Google: \"https://oauth2.googleapis.com/token\"\n        * GitHub: \"https://github.com/login/oauth/access_token\"\n        * Okta: \"https://your-domain.okta.com/oauth2/default/v1/token\"\n\n   c) TIMEOUT:\n      - Duration\n      - Example: 5s\n\n6) AUTHORIZATION ENDPOINT:\n\n   - OAuth provider's authorization endpoint\n   - URL where user will be redirected\n   - Examples:\n     * Google: \"https://accounts.google.com/o/oauth2/v2/auth\"\n     * GitHub: \"https://github.com/login/oauth/authorize\"\n     * Okta: \"https://your-domain.okta.com/oauth2/default/v1/authorize\"\n\n7) CREDENTIALS (CLIENT ID & SECRET):\n\n   a) Select 'credentials' tag\n   b) Horizontal tags: client_id, token_secret\n\n   c) CLIENT_ID:\n      - OAuth app client ID\n      - Obtained from OAuth provider\n      - Example: \"123456789.apps.googleusercontent.com\"\n\n   d) TOKEN_SECRET (Client Secret):\n      - Secret resource reference\n      - Uses SDS (Secret Discovery Service)\n      - Example:\n        * name: \"oauth_client_secret\"\n        * âš  Secret resource must be created beforehand\n\n8) REDIRECT URI:\n\n   - OAuth callback URI\n   - Must be registered with OAuth provider\n   - Format: https://your-domain.com/callback\n   - Example: \"https://api.example.com/oauth/callback\"\n   - âš  Must be listener's public URL\n\n9) REDIRECT PATH MATCHER:\n\n   - Callback path matching\n   - Select 'redirect_path_matcher' tag\n   - Horizontal tags: path\n   - path:\n     * exact: \"/oauth/callback\"\n     * prefix: \"/oauth\"\n   - This path is reserved for OAuth redirect (doesn't go to upstream)\n\n10) AUTH SCOPES:\n\n    - OAuth scope list\n    - String array\n    - Examples:\n      * Google: [\"openid\", \"email\", \"profile\"]\n      * GitHub: [\"read:user\", \"user:email\"]\n      * Okta: [\"openid\", \"profile\", \"email\"]\n\n11) FORWARD BEARER TOKEN:\n\n    - Boolean\n    - true: Forward access token to upstream (Authorization header)\n    - false: Keep token only in Envoy\n    - Usually true (for upstream to validate token)\n\n12) SIGNOUT PATH:\n\n    - Logout endpoint\n    - Select 'signout_path' tag\n    - path:\n      * exact: \"/logout\"\n    - When request comes to this path:\n      * Session cookie deleted\n      * User logged out\n\n13) EXAMPLE CONFIGURATION - GOOGLE OAUTH:\n\n    Prerequisite: Create OAuth app in Google Cloud Console\n\n    OAuth2 config:\n    - token_endpoint:\n      * cluster: \"google_oauth\"\n      * uri: \"https://oauth2.googleapis.com/token\"\n      * timeout: 5s\n\n    - authorization_endpoint: \"https://accounts.google.com/o/oauth2/v2/auth\"\n\n    - credentials:\n      * client_id: \"YOUR_CLIENT_ID.apps.googleusercontent.com\"\n      * token_secret:\n        - name: \"google_oauth_secret\" (Secret resource)\n\n    - redirect_uri: \"https://api.example.com/oauth/callback\"\n\n    - redirect_path_matcher:\n      * path:\n        - exact: \"/oauth/callback\"\n\n    - auth_scopes: [\"openid\", \"email\", \"profile\"]\n\n    - forward_bearer_token: true\n\n    - signout_path:\n      * path:\n        - exact: \"/logout\"\n\n14) OAUTH FLOW:\n\n    1. User â†’ https://api.example.com/protected\n    2. Envoy: No session cookie â†’ Redirect\n    3. User â†’ Google login page\n    4. Google: User login â†’ Redirect to callback\n    5. User â†’ https://api.example.com/oauth/callback?code=AUTH_CODE\n    6. Envoy: Exchange code for token (token_endpoint)\n    7. Envoy: Set session cookie\n    8. Envoy: Redirect to /protected\n    9. User â†’ /protected (with session cookie)\n    10. Envoy: Validate token â†’ Forward to upstream (Authorization: Bearer TOKEN)\n\n15) CLUSTER CONFIGURATION:\n\n    Cluster needed for OAuth provider:\n\n    Cluster resource:\n    - name: \"google_oauth\"\n    - type: STRICT_DNS\n    - load_assignment:\n      * endpoints:\n        - lb_endpoints:\n          * endpoint:\n            - address:\n              * socket_address:\n                - address: \"oauth2.googleapis.com\"\n                - port_value: 443\n    - transport_socket:\n      * TLS context (for HTTPS)\n\n16) SECRET CONFIGURATION:\n\n    Secret resource for client secret:\n\n    Secret resource:\n    - name: \"google_oauth_secret\"\n    - generic_secret:\n      * secret:\n        - inline_string: \"YOUR_CLIENT_SECRET\"\n\n    âš  In production use environment variable or external secret manager\n\n17) TESTING:\n\n    a) Browser test:\n       1. Open https://api.example.com/protected\n       2. Should redirect to Google login\n       3. Login\n       4. Should return to /protected page\n       5. Session cookie should be set\n\n    b) Cookie check:\n       - Browser DevTools â†’ Application â†’ Cookies\n       - OauthHMAC cookie should be visible\n       - Secure, HttpOnly flags should be set\n\n    c) Logout test:\n       - Open https://api.example.com/logout\n       - Cookie should be deleted\n       - /protected should redirect again\n\n18) TROUBLESHOOTING:\n\n    Problem: Redirect loop (constantly redirects to Google)\n    Solution:\n    - Is redirect_uri registered in OAuth app\n    - Is redirect_path_matcher correct\n    - Is cluster reachable (token_endpoint)\n\n    Problem: \"Invalid client\" error\n    Solution:\n    - Is client_id correct\n    - Is client_secret correct (check Secret resource)\n    - Is OAuth app active (in provider)\n\n    Problem: Token not forwarded to upstream\n    Solution:\n    - Is forward_bearer_token: true\n    - Does upstream read Authorization header\n\n19) IMPORTANT NOTES:\n    âš  HTTPS required (for OAuth redirect)\n    âš  Store client secret securely (use Secret resource)\n    âš  Redirect URI must match exactly (with provider)\n    âš  Session cookie SameSite=Lax (CSRF protection)\n    âœ… Use external secret manager in production\n    âœ… Keep scopes minimal (least privilege)"}
{"resource":"HTTPFilter","category":"basic_auth", "instruction": "How to do HTTP basic authentication with Basic Auth filter?", "output": "BASIC AUTH FILTER:\n\n1) WHAT IS BASIC AUTH:\n   - HTTP Basic Authentication (RFC 7617)\n   - Username:password base64 encoded\n   - Authorization: Basic <base64>\n   - Simple authentication (common for APIs)\n\n2) ADDING BASIC AUTH FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'Basic Auth' from drawer\n   c) Basic Auth filter added to list\n\n3) CREATING BASIC AUTH RESOURCE:\n   a) From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'Basic Auth'\n   b) 'Create' button at top right\n   c) Creation page opens\n   d) Tags in left menu:\n      - users (inline credentials)\n      - forward_username_header\n\n4) USERS CONFIGURATION:\n\n   a) Select 'users' tag\n   b) 'Users' card opens\n   c) Horizontal tags: inline_bytes, inline_string, filename\n\n   d) INLINE_STRING (Plain text):\n      - Select 'inline_string' tag\n      - Textarea opens\n      - Format: username:hashed_password (htpasswd format)\n      - Each line is one user\n      - Example:\n        ```\n        admin:{SHA}0DPiKuNIrrVmD8IUCuw1hQxNqZc=\n        user1:{SHA}W6ph5Mm5Pz8GgiULbPgzG37mj9g=\n        ```\n\n   e) INLINE_BYTES (Base64 encoded):\n      - Select 'inline_bytes' tag\n      - Base64 encoded htpasswd content\n      - Rarely used\n\n   f) FILENAME (Load from file):\n      - Select 'filename' tag\n      - File path: /etc/envoy/.htpasswd\n      - âš  File must be in elchi-client\n\n5) PASSWORD HASH GENERATION:\n\n   a) HTPASSWD COMMAND (Linux/Mac):\n      ```bash\n      # SHA hash:\n      htpasswd -nbs admin mypassword\n      # Output: admin:{SHA}0DPiKuNIrrVmD8IUCuw1hQxNqZc=\n\n      # Bcrypt (more secure):\n      htpasswd -nbB admin mypassword\n      # Output: admin:$2y$05$...\n      ```\n\n   b) ONLINE GENERATOR:\n      - https://www.web2generators.com/apache-tools/htpasswd-generator\n      - Enter username and password\n      - Select hash algorithm (SHA, Bcrypt)\n      - Copy output\n\n6) FORWARD USERNAME HEADER:\n\n   - forward_username_header: Header name\n   - Forward authenticated username to upstream\n   - Example: \"X-Authenticated-User\"\n   - Upstream can read this header to know the user\n\n7) EXAMPLE CONFIGURATION:\n\n   Basic Auth resource:\n   - users:\n     * inline_string:\n       ```\n       admin:{SHA}0DPiKuNIrrVmD8IUCuw1hQxNqZc=\n       user1:{SHA}W6ph5Mm5Pz8GgiULbPgzG37mj9g=\n       apiuser:{SHA}5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8\n       ```\n\n   - forward_username_header: \"X-Authenticated-User\"\n\n8) ROUTE LEVEL BASIC AUTH:\n\n   Different user list for specific routes:\n\n   In route details:\n   - typed_per_filter_config â†’ envoy.filters.http.basic_auth\n   - BasicAuthPerRoute:\n     * users:\n       - inline_string: \"specialuser:{SHA}hash\"\n\n9) TESTING:\n\n   a) Test with curl:\n      ```bash\n      # With username:password:\n      curl -v -u admin:mypassword http://listener-ip:port/api\n\n      # Manual Authorization header:\n      curl -v -H \"Authorization: Basic YWRtaW46bXlwYXNzd29yZA==\" http://listener-ip:port/api\n      ```\n\n   b) Manual base64 encoding:\n      ```bash\n      echo -n \"admin:mypassword\" | base64\n      # Output: YWRtaW46bXlwYXNzd29yZA==\n      ```\n\n   c) Expected result:\n      - Correct credentials: 200 OK (upstream response)\n      - Wrong credentials: 401 Unauthorized\n      - No header: 401 Unauthorized\n      - Response header:\n        ```\n        WWW-Authenticate: Basic realm=\"Restricted\"\n        ```\n\n10) BROWSER TEST:\n\n    a) Open URL in browser:\n       http://listener-ip:port/api\n\n    b) Login dialog appears:\n       - Username: admin\n       - Password: mypassword\n\n    c) Submit:\n       - If correct: Page loads\n       - If wrong: Prompt again\n\n11) MULTIPLE USERS:\n\n    inline_string:\n    ```\n    admin:{SHA}hash1\n    user1:{SHA}hash2\n    user2:{SHA}hash3\n    readonly:{SHA}hash4\n    apikey1:{SHA}hash5\n    ```\n\n    Each user authenticates with separate credentials\n\n    âš  No user roles/permissions (authentication only)\n    âš  Use RBAC for authorization\n\n12) USING USERNAME IN UPSTREAM:\n\n    If forward_username_header: \"X-Authenticated-User\" is set:\n\n    Upstream receives:\n    ```\n    GET /api/data HTTP/1.1\n    Host: backend\n    X-Authenticated-User: admin\n    ```\n\n    Upstream code:\n    ```python\n    username = request.headers.get('X-Authenticated-User')\n    if username == 'admin':\n        # Admin operations\n    else:\n        # Regular user operations\n    ```\n\n13) SECURITY CONSIDERATIONS:\n\n    âš  Use Basic Auth over HTTPS (password sent in plain text)\n    âš  Prefer Bcrypt hash (SHA-1 deprecated)\n    âš  Implement password rotation policy\n    âš  Add rate limiting for brute-force protection\n    âœ… Prefer OAuth for modern apps (instead of API key)\n    âœ… Prefer mTLS for machine-to-machine\n\n14) PASSWORD ROTATION:\n\n    a) Generate new hash:\n       ```bash\n       htpasswd -nbB admin new_password\n       ```\n\n    b) Update Basic Auth resource:\n       - Change users inline_string\n       - Save\n\n    c) Service reload:\n       - Job starts automatically\n       - Envoy config reloaded\n\n    d) Test:\n       - Old password: 401\n       - New password: 200\n\n15) TROUBLESHOOTING:\n\n    Problem: Always returns 401 (credentials correct)\n    Solution:\n    - Is hash format correct ({SHA}, $2y$, etc.)\n    - Was hash generated correctly (htpasswd)\n    - Username is case-sensitive\n    - Special characters in password (may need escaping)\n\n    Problem: Filter not working\n    Solution:\n    - Does filter exist in HCM\n    - Is filter ordering correct (before Router)\n    - Are users configured\n\n    Problem: Username not reaching upstream\n    Solution:\n    - Is forward_username_header set\n    - Does upstream read the header\n\n16) IMPORTANT NOTES:\n    âš  HTTPS mandatory (for security)\n    âš  Prefer Bcrypt hash algorithm\n    âš  User management is simple (requires config change to add/remove)\n    âœ… Quick auth method for APIs\n    âœ… Compatible with legacy systems"}
{"resource":"HTTPFilter","category":"buffer", "instruction": "What is Buffer filter used for and how to configure it?", "output": "BUFFER FILTER (REQUEST/RESPONSE BUFFERING):\n\n1) WHAT IS BUFFER FILTER:\n   - Buffers entire request or response body\n   - Reads entire body before sending to upstream\n   - Use case: Body transformation, validation, logging\n   - Trade-off: Increased latency and memory usage\n\n2) ADDING BUFFER FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'Buffer' from drawer\n   c) Buffer filter added to list\n\n3) CREATING BUFFER RESOURCE:\n   a) From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'Buffer'\n   b) 'Create Buffer' button at top right\n   c) Creation page opens\n   d) Tags in left menu:\n      - max_request_bytes\n      - max_request_time\n\n4) MAX REQUEST BYTES:\n\n   - Select 'max_request_bytes' tag\n   - Maximum buffer size (bytes)\n   - Example: 1048576 (1MB)\n   - If body larger than this:\n     * 413 Payload Too Large\n     * Not sent to upstream\n\n5) MAX REQUEST TIME:\n\n   - Select 'max_request_time' tag\n   - Duration format\n   - Maximum buffering time\n   - Example: 5s\n   - If body not completed within this time:\n     * 408 Request Timeout\n     * Connection closed\n\n6) EXAMPLE CONFIGURATION:\n\n   Buffer resource:\n   - max_request_bytes: 2097152 (2MB)\n   - max_request_time: 10s\n\n   Meaning:\n   - Request body up to 2MB will be buffered\n   - Must complete within 10 seconds\n   - Returns error if exceeded\n\n7) USE CASE 1 - BODY VALIDATION:\n\n   Scenario: Validate JSON body (with Lua filter)\n\n   Filter chain:\n   1. Buffer (buffer entire body)\n   2. Lua (read body, validate JSON)\n   3. Router (send to upstream)\n\n   Buffer config:\n   - max_request_bytes: 1048576 (1MB)\n   - max_request_time: 5s\n\n8) USE CASE 2 - LOGGING:\n\n   Scenario: Log entire request body\n\n   Buffer + Access log:\n   - Buffer: Buffer entire body\n   - Access log: Log body with %REQ(BODY)%\n\n9) USE CASE 3 - TRANSFORMATION:\n\n   Scenario: Transform request body (e.g., XML â†’ JSON)\n\n   Filter chain:\n   1. Buffer (buffer body)\n   2. Wasm/Lua (transform body)\n   3. Router (send transformed body to upstream)\n\n10) ROUTE LEVEL OVERRIDE:\n\n    In route details:\n    - typed_per_filter_config â†’ envoy.filters.http.buffer\n    - BufferPerRoute:\n      * max_request_bytes: 5242880 (5MB, different limit)\n      * disabled: true (disable buffer on this route)\n\n11) RESPONSE BUFFERING:\n\n    âš  Buffer filter only buffers REQUEST body\n    âš  No separate filter for response buffering\n    âš  Use Lua/Wasm body manipulation for response transformation\n\n12) PERFORMANCE IMPACT:\n\n    Trade-offs:\n    - âœ… Pros: Read entire body (transformation, validation)\n    - âœ… Protects from upstream body errors\n    - âŒ Increased latency (waits until body fully buffered)\n    - âŒ Increased memory usage (buffer per request)\n    - âŒ No streaming upload support\n\n13) MEMORY CALCULATION:\n\n    Example:\n    - max_request_bytes: 2MB\n    - Concurrent requests: 100\n    - Worst case memory: 2MB * 100 = 200MB\n\n    âš  Configure carefully in production (OOM risk)\n\n14) TESTING:\n\n    a) Normal request (under limit):\n       ```bash\n       curl -X POST -d '{\"key\": \"value\"}' http://listener-ip:port/api\n       ```\n       Expected: 200 OK\n\n    b) Large request (over limit):\n       ```bash\n       dd if=/dev/zero bs=1M count=3 | curl -X POST --data-binary @- http://listener-ip:port/api\n       ```\n       Expected: 413 Payload Too Large\n\n    c) Slow request (timeout):\n       ```bash\n       # Send slowly (more than 10 seconds):\n       curl -X POST --limit-rate 1K -d @large_file.json http://listener-ip:port/api\n       ```\n       Expected: 408 Request Timeout (if max_request_time exceeded)\n\n15) TROUBLESHOOTING:\n\n    Problem: 413 Payload Too Large\n    Solution:\n    - Increase max_request_bytes\n    - Or reduce body size from client\n    - Or override at route level\n\n    Problem: 408 Request Timeout\n    Solution:\n    - Increase max_request_time\n    - Check network latency\n    - Check client upload speed\n\n    Problem: OOM (Out of Memory)\n    Solution:\n    - Reduce max_request_bytes\n    - Add concurrent connection limit\n    - Increase Envoy memory limit\n\n16) BEST PRACTICES:\n    âœ… Configure max_request_bytes carefully (for memory)\n    âœ… Use only on required routes (performance)\n    âœ… Don't use buffer for streaming uploads\n    âš  Prefer S3 presigned URLs for large file uploads\n    âš  Buffer not suitable for video/image uploads\n\n17) ALTERNATIVE APPROACHES:\n\n    Instead of Buffer:\n    - Lua filter: body:getBytes() (lazy read)\n    - Wasm filter: On-the-fly processing\n    - External processor: Body stream processing\n\n    These use less memory\n\n18) IMPORTANT NOTES:\n    âš  Buffer filter is for REQUEST body (not response)\n    âš  Calculate memory overhead (max_bytes * concurrency)\n    âš  Don't use for streaming use cases\n    âœ… Suitable for validation/transformation\n    âœ… Ideal for small payloads (API JSON)"}
{"resource":"HTTPFilter","category":"stateful_session", "instruction": "How to do session management with Stateful Session filter?", "output": "STATEFUL SESSION FILTER:\n\n1) WHAT IS STATEFUL SESSION:\n   - HTTP session stickiness (cookie/header based)\n   - Same user goes to same upstream instance\n   - Use case: Session affinity, stateful backend\n   - Provides consistent routing in load balancer\n\n2) ADDING STATEFUL SESSION FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'Stateful Session' from drawer\n   c) Stateful Session filter added to list\n\n3) CREATING STATEFUL SESSION RESOURCE:\n   a) From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'Stateful Session'\n   b) 'Create' button at top right\n   c) Creation page opens\n   d) Tags in left menu:\n      - session_state (cookie or header based)\n\n4) SESSION STATE CONFIGURATION:\n\n   a) Select 'session_state' tag\n   b) 'Session State' card opens\n   c) Horizontal tags: name, typed_config\n\n   d) NAME:\n      - Extension name\n      - Examples:\n        * Cookie: \"envoy.http.stateful_session.cookie\"\n        * Header: \"envoy.http.stateful_session.header\"\n\n   e) TYPED_CONFIG:\n      - Select from '@type' dropdown:\n        * Cookie: type.googleapis.com/envoy.extensions.http.stateful_session.cookie.v3.CookieBasedSessionState\n        * Header: type.googleapis.com/envoy.extensions.http.stateful_session.header.v3.HeaderBasedSessionState\n\n5) COOKIE-BASED SESSION:\n\n   a) TYPED_CONFIG SETTINGS:\n      - @type: CookieBasedSessionState\n      - Horizontal tags: cookie\n\n   b) COOKIE:\n      - Select 'cookie' tag\n      - Horizontal tags: name, path, ttl\n\n      - name: Cookie name\n        * Example: \"ENVOY_SESSION\"\n\n      - path: Cookie path\n        * Example: \"/\"\n\n      - ttl: Time-to-live (Duration)\n        * Example: 3600s (1 hour)\n        * Cookie expiration time\n\n6) HEADER-BASED SESSION:\n\n   a) TYPED_CONFIG SETTINGS:\n      - @type: HeaderBasedSessionState\n      - Horizontal tags: name\n\n   b) NAME:\n      - Header name\n      - Example: \"X-Session-Hash\"\n      - Client must send this header with every request\n\n7) EXAMPLE - COOKIE BASED:\n\n   Stateful Session resource:\n   - session_state:\n     * name: \"envoy.http.stateful_session.cookie\"\n     * typed_config:\n       - @type: CookieBasedSessionState\n       - cookie:\n         * name: \"ENVOY_SESSION\"\n         * path: \"/\"\n         * ttl: 3600s\n\n   Behavior:\n   - First request: No cookie â†’ Envoy selects random upstream\n   - Response: Set-Cookie: ENVOY_SESSION=hash\n   - Subsequent requests: With cookie â†’ Goes to same upstream\n\n8) EXAMPLE - HEADER BASED:\n\n   Stateful Session resource:\n   - session_state:\n     * name: \"envoy.http.stateful_session.header\"\n     * typed_config:\n       - @type: HeaderBasedSessionState\n       - name: \"X-Session-Hash\"\n\n   Behavior:\n   - Client sends X-Session-Hash header with every request\n   - Envoy selects consistent upstream based on hash\n   - Client must manage the hash\n\n9) CLUSTER CONFIGURATION:\n\n   Cluster must be configured with extension for stateful session to work:\n\n   Cluster resource:\n   - load_balancing_policy:\n     * policies:\n       - typed_extension_config:\n         * name: \"envoy.load_balancing_policies.stateful_session\"\n         * typed_config:\n           - @type: StatefulSessionConfig\n           - session_state:\n             * name: \"envoy.http.stateful_session.cookie\" (or header)\n\n10) USE CASE - SHOPPING CART:\n\n    Scenario: E-commerce cart in-memory (in backend)\n\n    Problem:\n    - User adds item to cart â†’ Backend A\n    - Next request â†’ Backend B (cart appears empty)\n\n    Solution:\n    - Stateful session cookie\n    - Same user always goes to Backend A\n    - Cart stays in session\n\n11) USE CASE - WEBSOCKET CONNECTION:\n\n    Scenario: WebSocket connection must be sticky\n\n    Solution:\n    - Stateful session header\n    - Header set during WebSocket upgrade\n    - All messages go to same backend\n\n12) TESTING:\n\n    a) Cookie-based test:\n       ```bash\n       # First request:\n       curl -v -c cookies.txt http://listener-ip:port/api\n\n       # Response header:\n       Set-Cookie: ENVOY_SESSION=abc123; Path=/; Max-Age=3600\n\n       # Subsequent request (with cookie):\n       curl -v -b cookies.txt http://listener-ip:port/api\n\n       # Should go to same upstream (check in access log)\n       ```\n\n    b) Header-based test:\n       ```bash\n       # Same hash in each request:\n       curl -v -H \"X-Session-Hash: user123\" http://listener-ip:port/api\n       curl -v -H \"X-Session-Hash: user123\" http://listener-ip:port/api\n\n       # Should go to same upstream\n       ```\n\n    c) Access log check:\n       ```\n       [2024-01-15] 200 upstream_cluster: backend upstream_host: 10.0.1.5:8080\n       [2024-01-15] 200 upstream_cluster: backend upstream_host: 10.0.1.5:8080\n       ```\n       Same upstream_host â†’ Session sticky is working\n\n13) COOKIE EXPIRATION:\n\n    - ttl: 3600s â†’ Cookie expires after 1 hour\n    - After expiration:\n      * New upstream selected\n      * New cookie set\n    - If session TTL is long:\n      * Problem during backend scale-down (requests go to old backend)\n\n14) LOAD BALANCING IMPACT:\n\n    - Stateful session affects load balancing:\n      * Round robin â†’ Becomes sticky\n      * Random â†’ Becomes hash-based\n    - Can cause load imbalance:\n      * Some backends receive more requests (due to session stickiness)\n    - Mitigation:\n      * Keep session TTL short\n      * Increase backend count\n\n15) TROUBLESHOOTING:\n\n    Problem: Cookie not being set\n    Solution:\n    - Does filter exist in HCM\n    - Does cluster have stateful_session extension\n    - Are cookie name and config correct\n\n    Problem: Session sticky not working (going to different backends)\n    Solution:\n    - Cookie may have expired (check TTL)\n    - Is cluster load_balancing_policy correct\n    - Is cookie being sent by client (check DevTools)\n\n    Problem: Load imbalance\n    Solution:\n    - Shorten session TTL\n    - Increase backend count\n    - Prefer stateless design instead of stateful session\n\n16) BEST PRACTICES:\n    âœ… Keep session TTL short (for scaling)\n    âœ… Prefer stateless backend (if possible)\n    âœ… Use HttpOnly and Secure flags for cookies\n    âš  Keep cookie size small (sent with every request)\n    âš  Monitor for load imbalance\n\n17) STATELESS ALTERNATIVE:\n\n    Instead of stateful session:\n    - Redis/Memcached: Shared session store\n    - JWT: Client-side session (stateless)\n    - Database: Session persistence\n\n    Advantages:\n    - Better load balancing\n    - Easier backend scaling\n    - Session doesn't disappear on backend crash\n\n18) IMPORTANT NOTES:\n    âš  Stateful session = backend dependency\n    âš  Risk of load imbalance\n    âš  Cluster extension required (filter alone not enough)\n    âœ… Temporary solution for legacy stateful apps\n    âœ… Suitable for WebSocket"}
{"resource":"HTTPFilter","category":"router", "instruction": "What is Router filter and why is it mandatory?", "output": "ROUTER FILTER (HTTP ROUTING):\n\n1) WHAT IS ROUTER FILTER:\n   - Routes HTTP requests to upstream clusters\n   - Applies route configuration\n   - Must be the LAST filter in HTTP filter chain\n   - âš  HTTP listener doesn't work without Router\n\n2) ROUTER FILTER REQUIREMENT:\n\n   HTTP filter chain:\n   [Auth] â†’ [RBAC] â†’ [CORS] â†’ [Rate Limit] â†’ [Router]\n\n   - Router must be at the end\n   - Router sends request to upstream\n   - Without Router: Filter chain incomplete â†’ 500 Internal Server Error\n\n3) ADDING ROUTER FILTER:\n   a) Listener â†’ HCM â†’ HTTP Filters â†’ blue '+' button\n   b) Select 'Router' from drawer\n   c) Router filter added to list\n   d) âš  Ordering: Must be at the end (move to bottom with down arrow)\n\n4) CREATING ROUTER RESOURCE:\n   a) From left menu 'Filters' â†’ 'HTTP Filters' â†’ 'Router'\n   b) 'Create Router' button at top right\n   c) Creation page opens\n   d) Tags in left menu:\n      - dynamic_stats\n      - start_child_span\n      - upstream_log\n      - suppress_envoy_headers\n      - strict_check_headers\n\n5) ROUTER SETTINGS:\n\n   a) DYNAMIC_STATS:\n      - Boolean (default: true)\n      - true: Separate metrics per virtual host\n      - false: Aggregate metrics\n      - Use case: Set false if many vhosts (prevents metric explosion)\n\n   b) START_CHILD_SPAN:\n      - Boolean (default: false)\n      - true: Create child span for distributed tracing\n      - Use case: OpenTelemetry/Jaeger tracing\n\n   c) UPSTREAM_LOG:\n      - Access log configuration\n      - Log upstream request/response\n      - Format: JSON, text, custom\n\n   d) SUPPRESS_ENVOY_HEADERS:\n      - Boolean (default: false)\n      - true: Remove Envoy headers (x-envoy-*)\n      - Use case: Hide Envoy presence from backend\n\n   e) STRICT_CHECK_HEADERS:\n      - String array\n      - Returns 404 if these headers missing\n      - Use case: Mandatory header check\n\n6) ROUTING LOGIC:\n\n   Router filter uses route configuration:\n   1. Request arrives (e.g., GET /api/users)\n   2. Router matches virtual host (Host header)\n   3. Router matches route (path, header, query)\n   4. Router selects cluster (from route config)\n   5. Router sends request to upstream\n   6. Router returns response\n\n7) ROUTE CONFIGURATION REFERENCE:\n\n   Router filter + Route resource work together:\n\n   HTTP Connection Manager:\n   - route_config (STATIC) or\n   - rds (RDS - Route Discovery Service)\n\n   Route resource:\n   - Virtual hosts\n   - Routes (path matching, cluster selection)\n\n8) EXAMPLE CONFIGURATION:\n\n   Router resource:\n   - dynamic_stats: false (if many vhosts)\n   - start_child_span: true (for tracing)\n   - suppress_envoy_headers: true (don't send x-envoy-* to backend)\n   - upstream_log:\n     * Access log: /var/log/envoy/upstream.log\n     * Format: JSON\n\n9) ROUTER METRICS:\n\n   Router automatically produces metrics:\n   - http.<stat_prefix>.downstream_rq_total: Total requests\n   - http.<stat_prefix>.downstream_rq_2xx: 2xx responses\n   - http.<stat_prefix>.downstream_rq_4xx: 4xx responses\n   - http.<stat_prefix>.downstream_rq_5xx: 5xx responses\n   - http.<stat_prefix>.downstream_rq_time: Request duration\n   - vhost.<vhost_name>.vcluster.<cluster_name>.upstream_rq_total\n\n10) UPSTREAM SELECTION:\n\n    Router cluster selection:\n    - Route match â†’ cluster name\n    - Weighted cluster â†’ multiple clusters (canary, A/B)\n    - Header matching â†’ dynamic cluster selection\n    - Redirect â†’ doesn't go to upstream, returns redirect response\n\n11) RETRY POLICY:\n\n    Router retry logic:\n    - retry_policy in route configuration\n    - Retry conditions: 5xx, gateway-error, reset, retriable-4xx\n    - Num retries, timeout, backoff\n    - Router automatically retries\n\n12) TIMEOUT HANDLING:\n\n    Router timeout:\n    - timeout in route configuration\n    - Upstream response timeout\n    - If timeout exceeded: 504 Gateway Timeout\n    - Router manages connection pool\n\n13) ERROR RESPONSES:\n\n    Router error scenarios:\n    - No route match: 404 Not Found\n    - No cluster: 503 Service Unavailable\n    - Upstream unreachable: 503 Service Unavailable\n    - Upstream timeout: 504 Gateway Timeout\n    - Upstream 5xx: Passthrough (or retry)\n\n14) TESTING:\n\n    a) Check if Router exists:\n       ```bash\n       curl -v http://listener-ip:port/api\n       ```\n       - With Router: Upstream response or 404 (no route)\n       - Without Router: 500 Internal Server Error\n\n    b) Check metrics:\n       ```bash\n       curl http://listener-ip:9901/stats | grep http\n       ```\n       - Router metrics should be visible\n\n15) TROUBLESHOOTING:\n\n    Problem: 500 Internal Server Error (every request)\n    Solution:\n    - Does Router filter exist in HCM\n    - Is Router filter at the end (filter chain ordering)\n    - Does route configuration exist (route_config or rds in HCM)\n\n    Problem: 404 Not Found (upstream exists but can't reach)\n    Solution:\n    - Does route configuration match\n    - Does virtual host domain match\n    - Is path matching correct\n\n    Problem: 503 Service Unavailable\n    Solution:\n    - Does cluster exist (specified in route)\n    - Are cluster endpoints healthy\n    - Is upstream reachable (network)\n\n16) FILTER CHAIN ORDERING:\n\n    Correct ordering:\n    1. Authentication (Basic Auth, OAuth2)\n    2. Authorization (RBAC)\n    3. Security (CORS, WAF)\n    4. Rate Limiting\n    5. Transformation (Compressor, Buffer, Lua)\n    6. Custom (Wasm)\n    7. **Router (LAST)**\n\n    Wrong ordering:\n    - Router in middle â†’ Filters after Router don't run\n    - No Router â†’ 500 error\n    - Multiple Routers â†’ Only first one runs\n\n17) BEST PRACTICES:\n    âœ… Router always at the end\n    âœ… dynamic_stats: false (if many vhosts)\n    âœ… suppress_envoy_headers: true (in production)\n    âœ… Enable upstream log (for debugging)\n    âš  Router resource usually has minimal config (defaults sufficient)\n    âš  Complexity is in route configuration (not in router)\n\n18) IMPORTANT NOTES:\n    âš  Router mandatory (for HTTP listener)\n    âš  Router must be last filter\n    âš  If multiple Routers added, only first runs\n    âš  Router depends on route configuration\n    âœ… Router filter configured minimally (routing logic in route config)\n    âœ… Router automatically handles retry, timeout, load balancing"}
{"resource":"HTTPFilter","category":"filter_chain", "instruction": "Why is HTTP filter chain ordering important and how to configure it?", "output": "HTTP FILTER CHAIN ORDERING:\n\n1) WHAT IS FILTER CHAIN:\n   - Ordered list of HTTP filters\n   - Request: Processed top â†’ bottom sequentially\n   - Response: Processed bottom â†’ top sequentially\n   - Each filter passes control to next filter (or returns response)\n\n2) IMPORTANCE OF ORDERING:\n\n   Wrong ordering example:\n   [Router] â†’ [RBAC] â†’ [CORS]\n\n   Problem:\n   - Router at the beginning â†’ Request goes directly to upstream\n   - RBAC and CORS never run (after Router)\n   - Authorization bypass!\n\n   Correct ordering:\n   [CORS] â†’ [RBAC] â†’ [Router]\n\n   Result:\n   - CORS runs first (handle preflight)\n   - RBAC does auth check\n   - Router sends to upstream\n\n3) RECOMMENDED FILTER ORDERING:\n\n   1. **CORS** (at top)\n      - Handles preflight (OPTIONS) requests\n      - Browser checks CORS (before other filters)\n\n   2. **Authentication** (Basic Auth, OAuth2)\n      - User authentication\n      - Reject unauthenticated requests\n\n   3. **Authorization** (RBAC)\n      - User authorization\n      - Reject unauthorized requests\n\n   4. **Security** (WAF, CSRF)\n      - Web attack protection\n      - Reject malicious requests\n\n   5. **Rate Limiting**\n      - Request throttling\n      - Abuse protection\n\n   6. **Admission Control**\n      - Load shedding\n      - Circuit breaking\n\n   7. **Buffer** (if needed)\n      - Body buffering\n      - For transformation\n\n   8. **Transformation** (Compressor, Lua, Wasm)\n      - Request/response manipulation\n      - Header modification\n\n   9. **Router** (LAST)\n      - Upstream routing\n      - MANDATORY\n\n4) HOW TO CHANGE FILTER ORDERING:\n\n   a) In Listener â†’ HCM â†’ HTTP Filters list\n   b) Each filter row has up/down arrow buttons\n   c) Click to move filter\n   d) Move Router to bottom\n   e) Save\n\n5) EXAMPLE 1 - E-COMMERCE API:\n\n   Filter chain:\n   1. CORS (frontend on different domain)\n   2. OAuth2 (user login)\n   3. RBAC (admin vs customer)\n   4. WAF (SQL injection protection)\n   5. Rate Limit (prevent abuse)\n   6. Compressor (gzip response)\n   7. Router\n\n6) EXAMPLE 2 - PUBLIC API:\n\n   Filter chain:\n   1. CORS (public API)\n   2. Basic Auth (API key)\n   3. Rate Limit (quota: 100 req/min)\n   4. Lua (custom header validation)\n   5. Router\n\n7) EXAMPLE 3 - INTERNAL API (No Auth):\n\n   Filter chain:\n   1. Rate Limit (DDoS prevention)\n   2. Router\n\n   Minimal chain (internal trusted network)\n\n8) FILTER EXECUTION FLOW:\n\n   Request flow (top â†’ bottom):\n   ```\n   Client Request\n     â†“\n   [CORS] â†’ Preflight OK?\n     â†“ Yes\n   [OAuth2] â†’ Authenticated?\n     â†“ Yes\n   [RBAC] â†’ Authorized?\n     â†“ Yes\n   [Rate Limit] â†’ Under limit?\n     â†“ Yes\n   [Router] â†’ Send to upstream\n     â†“\n   Upstream\n   ```\n\n   Response flow (bottom â†’ top):\n   ```\n   Upstream Response\n     â†“\n   [Router] â†’ Receive response\n     â†“\n   [Rate Limit] â†’ Add rate limit headers\n     â†“\n   [RBAC] â†’ (no action on response)\n     â†“\n   [OAuth2] â†’ (no action on response)\n     â†“\n   [CORS] â†’ Add CORS headers\n     â†“\n   Client Response\n   ```\n\n9) FILTER SHORT-CIRCUIT:\n\n   If filter returns response, chain terminates:\n\n   ```\n   [CORS] â†’ OK, continue\n   [OAuth2] â†’ 401 Unauthorized (STOP)\n   ```\n\n   Result:\n   - RBAC, Rate Limit, Router don't run\n   - Client gets 401 directly\n   - Request doesn't go to upstream\n\n10) PERFORMANCE CONSIDERATIONS:\n\n    - More filters â†’ More latency\n    - Each filter uses CPU/memory\n    - Lightweight filters first (header check)\n    - Heavy filters last (body transformation)\n\n    Example ordering (for performance):\n    1. CORS (lightweight, header-only)\n    2. RBAC (lightweight, header-only)\n    3. Rate Limit (lightweight, counter)\n    4. WAF (medium, regex matching)\n    5. Buffer (heavy, memory)\n    6. Lua (heavy, script execution)\n    7. Router\n\n11) CONDITIONAL FILTERING:\n\n    Route level filter override:\n    - typed_per_filter_config\n    - Disable/enable filter on specific routes\n\n    Example:\n    - /public â†’ CORS: enabled, Auth: disabled\n    - /admin â†’ CORS: disabled, Auth: enabled, RBAC: strict\n\n12) DEBUGGING FILTER CHAIN:\n\n    a) Increase log level:\n       ```bash\n       # Envoy admin:\n       curl -X POST http://localhost:9901/logging?filter=debug\n       ```\n\n    b) Request trace:\n       - Add x-envoy-decorator-operation header\n       - Filter execution visible in Envoy log\n\n    c) Filter-specific logs:\n       ```bash\n       tail -f /var/log/envoy/envoy.log | grep -E '(cors|rbac|router)'\n       ```\n\n13) COMMON MISTAKES:\n\n    âŒ Mistake 1: Router in middle\n    ```\n    [CORS] â†’ [Router] â†’ [RBAC]\n    ```\n    Problem: RBAC never runs (after Router)\n\n    âŒ Mistake 2: Auth at the end\n    ```\n    [CORS] â†’ [Router] â†’ [OAuth2]\n    ```\n    Problem: Auth bypass (every request passes)\n\n    âŒ Mistake 3: CORS at the end\n    ```\n    [OAuth2] â†’ [RBAC] â†’ [Router] â†’ [CORS]\n    ```\n    Problem: Preflight fails (browser checks CORS first)\n\n    âŒ Mistake 4: No Router\n    ```\n    [CORS] â†’ [RBAC]\n    ```\n    Problem: 500 error (no routing)\n\n14) TESTING FILTER CHAIN:\n\n    a) CORS test:\n       ```bash\n       curl -X OPTIONS -H \"Origin: https://example.com\" http://listener-ip:port/api\n       ```\n       Expected: 200 OK + CORS headers (auth bypass)\n\n    b) Auth test:\n       ```bash\n       curl -v http://listener-ip:port/api\n       ```\n       Expected: 401 Unauthorized (if no auth)\n\n    c) Rate limit test:\n       ```bash\n       for i in {1..200}; do curl http://listener-ip:port/api; done\n       ```\n       Expected: First N: 200, rest: 429\n\n    d) Router test:\n       ```bash\n       curl -v -u user:pass http://listener-ip:port/api\n       ```\n       Expected: 200 OK + upstream response\n\n15) FILTER CHAIN VALIDATION:\n\n    Elchi UI validation:\n    - Is Router at the end â†’ âš  Warning\n    - Is Router missing â†’ âŒ Error\n    - Duplicate filter â†’ âš  Warning\n\n    Envoy validation:\n    - Config parse error â†’ Startup fail\n    - Unknown filter â†’ Error\n\n16) BEST PRACTICES:\n    âœ… CORS at top (for preflight)\n    âœ… Auth/RBAC at top (security early fail)\n    âœ… Router at end (MANDATORY)\n    âœ… Lightweight filters first (performance)\n    âœ… Heavy filters last (buffer, transformation)\n    âš  Minimize filter count (latency)\n    âš  Test filter chain in test environment\n\n17) TROUBLESHOOTING:\n\n    Problem: Filter not working\n    Solution:\n    - Check filter ordering (before Router?)\n    - Is filter enabled (route override?)\n    - Is filter execution visible in logs\n\n    Problem: Auth bypass happening\n    Solution:\n    - Is Auth filter before Router\n    - Is Auth filter config correct\n    - Is auth disabled at route level\n\n18) IMPORTANT NOTES:\n    âš  Filter ordering CRITICAL (for security)\n    âš  Router MUST be at end\n    âš  CORS MUST be at top (for SPAs)\n    âœ… Minimize filter count for performance\n    âœ… Test before going to production"}
{"resource":"Bootstrap","category":"basics","instruction":"What is Bootstrap configuration in Envoy and how do I create it in Elchi?","output":"BOOTSTRAP CONFIGURATION OVERVIEW:\n\nBootstrap is Envoy's initial startup configuration that defines:\n- Admin interface settings\n- Node identity\n- Static resources (clusters, listeners)\n- Dynamic resource configuration (ADS/xDS)\n- Logging and tracing settings\n\nCREATING BOOTSTRAP IN ELCHI:\n\n1) Navigate to 'Bootstrap' from the left menu\n2) Click the blue '+' button at the top\n3) Enter a name for your Bootstrap configuration\n4) Select Envoy version from the dropdown\n\nMAIN CONFIGURATION SECTIONS:\n\n1) **Admin Interface**:\n   - Configure admin port and access log path\n   - Set socket address (IP and port)\n\n2) **Node Configuration**:\n   - Set node ID and cluster name\n   - Define locality (region, zone, sub-zone)\n\n3) **Static Resources**:\n   - Define static clusters (if any)\n   - Define static listeners (if any)\n\n4) **Dynamic Config Source**:\n   - Configure ADS (Aggregated Discovery Service)\n   - Set API type and cluster name\n   - Elchi acts as the xDS server\n\n5) **Other Settings**:\n   - Stats sinks\n   - Tracing configuration\n   - Layered runtime\n\nCLICK 'SAVE' when done configuring.\n\nIMPORTANT: Bootstrap is required for Envoy to start. It's the entry point for all Envoy configuration."}
{"resource":"Service","category":"basics","instruction":"What is a Service in Elchi and how do I create one?","output":"SERVICE CONCEPT IN ELCHI:\n\nA Service in Elchi represents an Envoy proxy instance deployment that:\n- Groups together all Envoy resources (Listeners, Clusters, Routes, Secrets)\n- Manages deployment to physical servers via elchi-client\n- Tracks configuration versions and changes\n- Monitors service health and status\n\nCREATING A SERVICE:\n\n1) Navigate to 'Services' from the left menu under 'Operations'\n2) Click the blue '+' button at the top\n3) Fill in the form:\n\n   **Basic Information**:\n   - Service name (required)\n   - Description (optional)\n   - Select Envoy version\n   - Select Bootstrap configuration (required)\n\n   **Resource Selection**:\n   - Select Listeners to include\n   - Select Clusters to include\n   - Select Routes to include\n   - Select Secrets/TLS contexts to include\n\n4) Click 'SAVE' to create the service\n\nSERVICE STATUS INDICATORS:\n- **Live** (Green): All clients are healthy and running\n- **Partial** (Yellow): Some clients are unhealthy or not responding\n- **Offline** (Red): No clients are responding\n\nNEXT STEPS:\n- Deploy the service to elchi-clients\n- Start the Envoy process\n- Monitor service health and metrics"}
{"resource":"Service","category":"deployment","instruction":"How do I deploy a Service to servers and start Envoy?","output":"SERVICE DEPLOYMENT PROCESS:\n\n**STEP 1: SELECT CLIENTS**\n\n1) Go to 'Services' from the left menu\n2) Click on your service name to open details\n3) Navigate to the 'Deployment' tab or section\n4) You'll see a list of available elchi-clients\n5) Select the clients (servers) where you want to deploy\n\n**STEP 2: DEPLOY CONFIGURATION**\n\n1) Click the 'Deploy' button\n2) A deployment dialog appears showing:\n   - Selected clients\n   - Current configuration snapshot\n   - Resources to be deployed (Listeners, Clusters, Routes, Secrets)\n3) Review the deployment summary\n4) Click 'CONFIRM' to deploy\n\n**WHAT HAPPENS DURING DEPLOYMENT:**\n- Elchi sends the Envoy configuration to selected clients via SSH\n- Configuration is written to YAML files on the server\n- Bootstrap file is generated\n- Static resources are configured\n- Dynamic resources are set up to connect to Elchi's xDS server\n\n**STEP 3: START ENVOY**\n\n1) After deployment, use the 'Start' button on the service detail page\n2) Or use the operations dropdown and select 'Start'\n3) Envoy process will start on all deployed clients\n\n**MONITORING:**\n- Service status changes to 'Live' when Envoy is running\n- Check the 'Clients' tab to see individual client status\n- View logs from the 'Logs' section\n- Monitor metrics on the dashboard\n\nTROUBLESHOOTING:\n- If deployment fails, check client connectivity\n- Verify SSH access to servers\n- Check elchi-client service is running on target servers"}
{"resource":"Service","category":"operations","instruction":"What's the difference between Start, Stop, Reload, and Restart operations for a Service?","output":"SERVICE OPERATIONS EXPLAINED:\n\n**1) START**\n- **What it does**: Launches the Envoy process on all deployed clients\n- **When to use**: First time starting after deployment, or after a Stop\n- **Requirements**: Service must be deployed to clients first\n- **Result**: Envoy starts with the current configuration\n- **Downtime**: None for new deployments, traffic starts flowing\n\n**2) STOP**\n- **What it does**: Gracefully shuts down the Envoy process\n- **When to use**: Maintenance, decommissioning, or before major changes\n- **Result**: Envoy process terminates on all clients\n- **Downtime**: YES - Service becomes offline, traffic stops\n- **Note**: Configuration remains on the server, just the process stops\n\n**3) RELOAD**\n- **What it does**: Hot-reloads Envoy configuration WITHOUT stopping the process\n- **When to use**: After making configuration changes (new routes, clusters, filters)\n- **How it works**: \n  - Envoy uses its hot restart mechanism\n  - New configuration is loaded while old process continues\n  - Graceful draining of old connections\n  - Seamless transition to new configuration\n- **Downtime**: MINIMAL - Connections drain gracefully\n- **Best for**: Dynamic config updates, route changes, cluster modifications\n\n**4) RESTART**\n- **What it does**: Stops Envoy completely, then starts it again\n- **When to use**: \n  - Bootstrap configuration changes\n  - Major structural changes\n  - When hot reload doesn't work\n  - Troubleshooting issues\n- **Downtime**: YES - Brief interruption while process restarts\n- **Process**: Stop â†’ Wait â†’ Start\n\n**OPERATION BUTTONS LOCATION:**\n- Service detail page â†’ Top action bar\n- Or use the operations dropdown menu\n- Operations can be performed on individual clients or all at once\n\n**BEST PRACTICES:**\n- Use **Reload** for most configuration changes (zero downtime)\n- Use **Restart** only when Bootstrap changes\n- Use **Stop** only for intentional service shutdown\n- Always check service status after operations"}
{"resource":"Service","category":"snapshot","instruction":"What is a Snapshot and how does configuration change flow work in Elchi?","output":"SNAPSHOT CONCEPT:\n\nA Snapshot is a complete, versioned export of all Envoy resources for a service at a specific point in time. It includes:\n- All Listeners\n- All Clusters\n- All Routes\n- All Secrets/TLS contexts\n- Bootstrap configuration\n\nFormatted as a single YAML file that can be used to start Envoy.\n\n**CONFIGURATION CHANGE FLOW:**\n\n**STEP 1: MODIFY RESOURCES**\n1) Edit Listener, Cluster, Route, or other resources\n2) Click 'SAVE' on the resource edit page\n3) Changes are saved in Elchi database but NOT yet deployed\n\n**STEP 2: GENERATE NEW SNAPSHOT**\n1) Go to Service detail page\n2) Click 'Generate Snapshot' or 'Create Snapshot'\n3) Elchi creates a new YAML configuration file\n4) Snapshot is versioned (v1, v2, v3, etc.)\n5) You can view the YAML diff between snapshots\n\n**STEP 3: DEPLOY SNAPSHOT**\n1) Click 'Deploy' on the service page\n2) Select which snapshot version to deploy\n3) Choose target clients (servers)\n4) Confirm deployment\n5) Elchi pushes configuration to elchi-clients via SSH\n\n**STEP 4: APPLY CHANGES**\n- **For dynamic resources** (Routes, Clusters, Endpoints):\n  - Use 'Reload' operation\n  - Envoy hot-reloads configuration via xDS\n  - Zero downtime\n\n- **For static resources** (Bootstrap, some Listeners):\n  - Use 'Restart' operation\n  - Envoy restarts with new configuration\n  - Brief downtime\n\n**SNAPSHOT MANAGEMENT:**\n- View all snapshots in 'Snapshots' tab\n- Compare snapshots (diff view)\n- Rollback to previous snapshot if needed\n- Each snapshot is immutable (cannot be changed)\n\n**ELCHI AS XDS SERVER:**\n- Elchi acts as ADS (Aggregated Discovery Service) server\n- Envoy connects to Elchi for dynamic configuration\n- Changes to Routes, Clusters, Endpoints push automatically\n- No restart needed for dynamic resources\n\n**TRACKING CHANGES:**\n- Every configuration change is tracked\n- Audit log shows who changed what and when\n- Snapshots provide rollback capability\n- Jobs track deployment progress"}
{"resource":"Bootstrap","category":"admin_interface","instruction":"How do I configure the Admin Interface in Bootstrap?","output":"ADMIN INTERFACE CONFIGURATION:\n\nThe Admin Interface is Envoy's built-in HTTP endpoint for:\n- Runtime statistics\n- Configuration dumps\n- Health checks\n- Logging level changes\n- Cluster and listener status\n\n**CONFIGURATION STEPS:**\n\n1) Open your Bootstrap configuration in Elchi\n2) Navigate to the 'Admin' section (use horizontal tags or left anchor menu)\n3) Configure the following fields:\n\n**ADDRESS CONFIGURATION:**\n- **Socket Address**:\n  - IP Address: Usually \"0.0.0.0\" (all interfaces) or \"127.0.0.1\" (localhost only)\n  - Port: Common ports are 9901, 9000, 8001\n  - Example: 0.0.0.0:9901\n\n**ACCESS LOG PATH:**\n- Path to admin access log file\n- Example: \"/var/log/envoy/admin_access.log\"\n- Leave empty to disable admin access logging\n\n**PROFILE PATH (optional):**\n- Path for profiling data\n- Used for performance analysis\n\n**SECURITY CONSIDERATIONS:**\n\nFor production environments:\n1) Bind to localhost only (127.0.0.1) if possible\n2) Use firewall rules to restrict access\n3) Consider using Unix domain sockets instead of TCP\n4) Enable access logging for audit trails\n\n**COMMON ADMIN ENDPOINTS:**\nOnce Envoy is running, access these via HTTP:\n- `/stats` - All statistics\n- `/config_dump` - Current configuration\n- `/clusters` - Cluster status\n- `/listeners` - Listener status\n- `/server_info` - Envoy version and uptime\n- `/ready` - Readiness check\n- `/health_check/fail` - Force health check to fail\n\n**TESTING:**\nAfter starting Envoy:\n```\ncurl http://localhost:9901/stats\ncurl http://localhost:9901/config_dump\n```\n\n4) Click 'SAVE' after configuring admin interface"}
{"resource":"Service","category":"status","instruction":"What do the different Service status indicators mean and how do I troubleshoot issues?","output":"SERVICE STATUS INDICATORS:\n\n**1) LIVE (Green)**\n- **Meaning**: Service is fully operational\n- **Criteria**: All deployed clients are healthy and responding\n- **Envoy Status**: Running and serving traffic\n- **Client Health**: All clients report healthy status\n- **Action Required**: None - service is working correctly\n\n**2) PARTIAL (Yellow/Orange)**\n- **Meaning**: Service is partially operational\n- **Criteria**: Some clients are healthy, some are not\n- **Possible Causes**:\n  - Some servers are down or unreachable\n  - Network connectivity issues to some clients\n  - Envoy process crashed on some servers\n  - Configuration issues on specific clients\n- **Action Required**: Investigate unhealthy clients\n\n**3) OFFLINE (Red)**\n- **Meaning**: Service is not operational\n- **Criteria**: No clients are responding or all are unhealthy\n- **Possible Causes**:\n  - Envoy is stopped on all servers\n  - All servers are down or unreachable\n  - elchi-client service is not running\n  - Configuration error preventing Envoy startup\n- **Action Required**: Immediate investigation required\n\n**TROUBLESHOOTING STEPS:**\n\n**For PARTIAL Status:**\n1) Go to Service detail page â†’ 'Clients' tab\n2) Identify which clients are unhealthy (red status)\n3) Click on unhealthy client to see details\n4) Check:\n   - Client last seen timestamp\n   - Error messages\n   - Envoy process status\n5) Common fixes:\n   - Restart Envoy on unhealthy clients\n   - Check network connectivity\n   - Verify elchi-client is running\n   - Review Envoy logs for errors\n\n**For OFFLINE Status:**\n1) Check 'Logs' section for error messages\n2) Verify elchi-client service is running on all servers:\n   ```\n   systemctl status elchi-client\n   ```\n3) Check Envoy process status on servers:\n   ```\n   ps aux | grep envoy\n   ```\n4) Review Envoy error logs (path configured in Bootstrap)\n5) Try redeploying the service\n6) Verify configuration is valid (check for syntax errors)\n7) Ensure all dependencies are available (clusters, secrets)\n\n**CLIENT HEALTH CHECK:**\n- Elchi performs periodic health checks to clients\n- Checks if elchi-client agent is responding\n- Verifies Envoy process is running\n- Monitors resource usage\n\n**MONITORING BEST PRACTICES:**\n- Set up alerts for status changes\n- Monitor service status on the dashboard\n- Check client connectivity regularly\n- Review logs periodically\n- Use the Jobs section to track deployment issues"}
{"resource":"Bootstrap","category":"dynamic_config","instruction":"What's the difference between Static Resources and Dynamic Resources in Bootstrap configuration?","output":"STATIC VS DYNAMIC RESOURCES IN BOOTSTRAP:\n\n**STATIC RESOURCES:**\n\nDefined directly in the Bootstrap configuration file:\n\n**Characteristics:**\n- Loaded when Envoy starts\n- Cannot be changed without restarting Envoy\n- Defined in YAML/JSON format\n- Part of the Bootstrap file\n\n**Use Cases:**\n- Initial clusters needed for xDS connectivity\n- Simple, unchanging configurations\n- Development and testing setups\n- Fallback clusters\n\n**Configuration in Bootstrap:**\n```yaml\nstatic_resources:\n  listeners:\n    - name: static_listener\n      address: {...}\n      filter_chains: [...]\n  clusters:\n    - name: static_cluster\n      connect_timeout: 1s\n      endpoints: [...]\n```\n\n**In Elchi:**\n1) Open Bootstrap configuration\n2) Navigate to 'Static Resources' section\n3) Add static clusters or listeners\n4) These are embedded in the Bootstrap YAML\n\n---\n\n**DYNAMIC RESOURCES (via xDS/ADS):**\n\nLoaded from a management server (like Elchi) via xDS protocol:\n\n**Characteristics:**\n- Loaded and updated dynamically at runtime\n- Can be changed without restarting Envoy (hot reload)\n- Fetched from xDS server (Elchi acts as ADS server)\n- Changes push automatically or via polling\n\n**xDS API Types:**\n- **LDS** (Listener Discovery Service) - Listeners\n- **RDS** (Route Discovery Service) - Routes\n- **CDS** (Cluster Discovery Service) - Clusters\n- **EDS** (Endpoint Discovery Service) - Endpoints\n- **SDS** (Secret Discovery Service) - TLS certificates\n- **ADS** (Aggregated Discovery Service) - All of the above in one stream\n\n**Configuration in Bootstrap:**\n```yaml\ndynamic_resources:\n  lds_config:\n    ads: {}\n  cds_config:\n    ads: {}\n  ads_config:\n    api_type: GRPC\n    grpc_services:\n      - envoy_grpc:\n          cluster_name: xds_cluster\n```\n\n**In Elchi:**\n1) Open Bootstrap configuration\n2) Navigate to 'Dynamic Resources' section\n3) Configure ADS:\n   - Set API type (GRPC recommended)\n   - Set cluster name (this cluster must exist in static resources)\n   - Elchi's xDS server address is configured here\n4) Envoy will connect to Elchi for dynamic updates\n\n---\n\n**ELCHI'S APPROACH:**\n\n**Typical Setup:**\n1) **Static Resources**: Minimal Bootstrap cluster to connect to Elchi\n   - One static cluster: xds_cluster (points to Elchi's xDS server)\n   - Admin interface configuration\n\n2) **Dynamic Resources**: Everything else managed by Elchi\n   - All application Listeners (managed/unmanaged)\n   - All Clusters (your backend services)\n   - All Routes (HTTP routing)\n   - All Endpoints (load balancing)\n   - All Secrets (TLS certificates)\n\n**Benefits of Dynamic Configuration:**\n- âœ… Zero-downtime updates (hot reload)\n- âœ… Centralized management via Elchi\n- âœ… Version control and rollback\n- âœ… Automatic propagation to all Envoy instances\n- âœ… Consistent configuration across fleet\n\n**When to Use Static:**\n- Initial xDS cluster (required to bootstrap dynamic config)\n- Simple setups without management server\n- Fallback configuration\n- Development/testing environments\n\n**RESTART vs RELOAD:**\n- **Static resource changes**: Require Envoy restart\n- **Dynamic resource changes**: Hot reload via xDS (zero downtime)\n\n**IN PRACTICE:**\nWhen you create a Service in Elchi:\n1) Elchi generates Bootstrap with minimal static resources\n2) All your configured Listeners, Clusters, Routes become dynamic\n3) Envoy connects to Elchi's xDS server on startup\n4) Configuration updates push automatically\n5) Use 'Reload' operation for zero-downtime updates"}
{"resource":"Service","category":"client_management","instruction":"How does the elchi-client work and how do I manage clients for a Service?","output":"ELCHI-CLIENT OVERVIEW:\n\n**What is elchi-client?**\n- Python agent that runs on servers where Envoy is deployed\n- Communicates with Elchi central server via SSH and API\n- Manages Envoy process lifecycle (start, stop, restart)\n- Receives configuration updates from Elchi\n- Reports health status and metrics back to Elchi\n\n**Architecture:**\n```\nElchi (Central) --SSH/API--> elchi-client (Agent) --Controls--> Envoy Process\n```\n\n---\n\n**SETTING UP ELCHI-CLIENT:**\n\n**Installation on Target Server:**\n1) Install elchi-client package on the server\n2) Configure connection to Elchi central server\n3) Set up SSH keys for authentication\n4) Start elchi-client service:\n   ```bash\n   systemctl start elchi-client\n   systemctl enable elchi-client\n   ```\n\n**Configuration:**\n- Client ID (unique identifier)\n- Elchi server address\n- API credentials\n- Envoy binary path\n- Configuration file paths\n- Log directories\n\n---\n\n**MANAGING CLIENTS IN ELCHI:**\n\n**Viewing Clients:**\n1) Navigate to 'Clients' from the left menu\n2) See all registered elchi-clients\n3) View client status:\n   - **Online** (Green): Client is healthy and responding\n   - **Offline** (Red): Client is not responding\n   - Last seen timestamp\n   - Assigned services\n\n**Client Details:**\nClick on a client to see:\n- Hostname and IP address\n- Operating system information\n- Envoy version installed\n- Deployed services\n- Resource usage (CPU, memory, connections)\n- Recent logs\n- Configuration files\n\n---\n\n**ASSIGNING CLIENTS TO SERVICES:**\n\n**Method 1: During Service Deployment**\n1) Open Service detail page\n2) Go to 'Deployment' tab\n3) Select clients from the available list\n4) Click 'Deploy'\n5) Elchi pushes configuration to selected clients\n\n**Method 2: From Client Management**\n1) Go to 'Clients' page\n2) Click on a client\n3) Use 'Assign Service' button\n4) Select service from dropdown\n5) Confirm assignment\n\n---\n\n**CLIENT OPERATIONS:**\n\n**Individual Client Operations:**\nOn Service detail â†’ Clients tab:\n- **Start**: Start Envoy on this client only\n- **Stop**: Stop Envoy on this client only\n- **Restart**: Restart Envoy on this client only\n- **Reload**: Hot reload configuration on this client\n- **Undeploy**: Remove service from this client\n\n**Bulk Operations:**\nUse the main service operations to affect all clients:\n- Start All\n- Stop All\n- Restart All\n- Reload All\n\n---\n\n**CLIENT HEALTH MONITORING:**\n\n**Health Check Mechanism:**\n- Elchi sends periodic heartbeat requests to elchi-client\n- Client responds with status information\n- Timeout = client marked as offline\n- Health check interval: typically 30-60 seconds\n\n**What's Monitored:**\n- Client agent responsiveness\n- Envoy process status (running/stopped)\n- Resource metrics (CPU, memory, disk)\n- Network connectivity\n- Configuration version deployed\n\n**Troubleshooting Offline Clients:**\n1) Check if server is reachable (ping, SSH)\n2) Verify elchi-client service is running\n3) Check firewall rules\n4) Review elchi-client logs on the server\n5) Verify SSH key authentication\n6) Check Elchi server logs for connection errors\n\n---\n\n**DEPLOYMENT WORKFLOW:**\n\n**Step-by-Step:**\n1) **Register Client**: elchi-client registers with Elchi on startup\n2) **Select Service**: Choose which service to deploy to client\n3) **Deploy Config**: Elchi sends YAML configuration via SSH\n4) **Write Files**: elchi-client writes Bootstrap and config files\n5) **Start Envoy**: elchi-client starts Envoy process\n6) **Monitor**: Client reports status back to Elchi\n7) **Updates**: Configuration changes push automatically\n8) **Reload**: elchi-client triggers hot reload when config changes\n\n**Configuration File Locations (on client server):**\n- Bootstrap: `/etc/envoy/bootstrap.yaml`\n- Dynamic config: Fetched from Elchi's xDS server\n- Logs: `/var/log/envoy/`\n- Admin socket: Configured in Bootstrap\n\n---\n\n**BEST PRACTICES:**\n\nâœ… **High Availability:**\n- Deploy service to multiple clients\n- Use load balancer in front of Envoy instances\n- Monitor all clients continuously\n\nâœ… **Security:**\n- Use SSH key authentication (not passwords)\n- Restrict elchi-client to specific IP ranges\n- Run elchi-client as dedicated user (not root)\n- Encrypt communication between Elchi and clients\n\nâœ… **Monitoring:**\n- Set up alerts for client offline events\n- Monitor resource usage trends\n- Track deployment success/failure rates\n- Review logs regularly\n\nâœ… **Maintenance:**\n- Keep elchi-client updated\n- Rotate logs to prevent disk filling\n- Test failover scenarios\n- Document client-to-service mappings\n\n---\n\n**CLIENT STATUS IN SERVICE VIEW:**\n\nOn Service detail page:\n- **Clients Tab**: Shows all assigned clients\n- **Status Indicator**: Green (healthy) / Red (unhealthy)\n- **Last Seen**: Timestamp of last heartbeat\n- **Version**: Configuration version deployed\n- **Actions**: Individual client operations\n\n**Overall Service Status:**\n- **Live**: All clients healthy\n- **Partial**: Some clients healthy, some not\n- **Offline**: No clients responding"}
{"resource":"Jobs","category":"basics","instruction":"What are background jobs in Elchi and how do I view them?","output":"BACKGROUND JOBS OVERVIEW:\n\n**What are Background Jobs?**\n\nBackground jobs are asynchronous tasks that Elchi creates when you perform operations that:\n- Update Envoy configurations (creating/modifying listeners, clusters, routes, etc.)\n- Deploy configuration snapshots to elchi-clients\n- Synchronize Kubernetes discovery\n- Propagate WAF (Web Application Firewall) configurations\n- Upgrade resources across versions\n\n**Common Job Types:**\n\n1. **SNAPSHOT_UPDATE**: Created when you modify any Envoy resource (listener, cluster, route, etc.). This job:\n   - Analyzes which listeners are affected by your change\n   - Creates new configuration snapshots\n   - Sends snapshots to elchi-clients via xDS protocol\n   - Tracks success/failure for each client\n\n2. **DISCOVERY_UPDATE**: Created when Kubernetes service/pod changes are detected. Updates endpoints automatically.\n\n3. **WAF_PROPAGATION**: Created when you modify a WAF profile. Updates all Wasm filters that reference that profile.\n\n4. **RESOURCE_UPGRADE** / **RESOURCE_UPGRADE(DRY)**: Created when upgrading resources from one Envoy version to another.\n\n---\n\n**VIEWING JOBS:**\n\n**STEP 1: NAVIGATE TO JOBS PAGE**\n\n1) Click 'Jobs' from the left menu under 'OPERATIONS'\n2) The Jobs page opens showing all background jobs\n\n**STEP 2: UNDERSTAND THE JOBS LIST**\n\nThe table shows:\n- **Job ID**: Human-friendly ID (e.g., EC-1, EC-2, EC-3)\n- **Type**: Job type (Snapshot Update, Discovery Update, WAF Propagation, Resource Upgrade)\n- **Status**: Current state with color-coded tags:\n  - **PENDING** (blue): Waiting in queue\n  - **CLAIMED** (orange): Picked up by a worker\n  - **RUNNING** (green, animated): Currently executing\n  - **COMPLETED** (green): Successfully finished\n  - **FAILED** (red): Encountered errors\n  - **NO_WORK_NEEDED** (gray): Completed but no updates were required\n- **Resource**: Which resource triggered the job (e.g., Listener name, Cluster name)\n- **Progress**: Visual progress bar showing completion percentage\n- **Triggered By**: User who initiated the action\n- **Created**: How long ago the job was created (e.g., \"2 hours ago\")\n- **Duration**: How long the job took (or is taking) to run\n\n**STEP 3: FILTER AND SEARCH JOBS**\n\nAt the top of the page, you'll find filter options:\n\n1) **Date Range Filter** (RangePicker):\n   - Default: Last 1 month\n   - Click to select custom date range\n\n2) **Status Filter** (dropdown):\n   - Filter by: PENDING, RUNNING, COMPLETED, FAILED, NO_WORK_NEEDED\n\n3) **Type Filter** (dropdown):\n   - Filter by: SNAPSHOT_UPDATE, DISCOVERY_UPDATE, WAF_PROPAGATION, RESOURCE_UPGRADE\n\n4) **Resource Name** (text input):\n   - Search for jobs related to a specific resource name\n\n5) **Username** (text input):\n   - Filter jobs by who triggered them\n\n6) After adjusting filters, click the blue **\"Apply Filters\"** button (search icon)\n7) To reset all filters, click the **\"Clear All\"** button (clear icon)\n\n**STEP 4: VIEW STATISTICS**\n\nAt the top, you'll see statistics cards:\n- **Total Jobs**: Total number of jobs in the selected time range\n- **Queue Size**: How many jobs are waiting to be processed\n- **Active Workers**: Number of worker processes handling jobs\n- **Processing Jobs**: Jobs currently being executed\n- **Jobs by Status**: Breakdown by PENDING, RUNNING, COMPLETED, FAILED\n\n---\n\n**QUICK TIPS:**\n\n- Click on a **Job ID** to view detailed information about that job\n- Jobs are sorted by creation date (newest first) by default\n- The three-dot menu (â‹®) on each row provides actions:\n  - **View Details**: Opens job detail page\n  - **Cancel Job**: For PENDING/CLAIMED jobs\n  - **Retry Job**: For FAILED/COMPLETED jobs\n  - **Retry Failed Only**: For jobs with some failed snapshots\n\n- If you see a red **\"Stuck Jobs\"** alert, it means some jobs are abandoned (worker crashed). Use the \"Clean Up Stuck Jobs\" button to resolve."}
{"resource":"Jobs","category":"job_detail","instruction":"How do I view detailed information about a specific job and understand what it did?","output":"VIEWING JOB DETAILS:\n\n**STEP 1: NAVIGATE TO JOB DETAIL PAGE**\n\n**Option A: From Jobs List**\n1) Go to 'Jobs' from left menu\n2) Click on the **Job ID** (e.g., EC-123) in the table\n3) Job detail page opens\n\n**Option B: From Actions Menu**\n1) On the Jobs page, click the three-dot menu (â‹®) on the row\n2) Select \"View Details\"\n\n---\n\n**STEP 2: UNDERSTAND THE JOB DETAIL PAGE**\n\nThe job detail page is divided into several sections:\n\n**A) HEADER SECTION** (top of page)\n\nShows:\n- **Status icon** (clock/play/checkmark/X icon with color)\n- **Job ID** and **Type** tag (e.g., \"Job EC-123\" with \"Snapshot Update\" tag)\n- **Created time** (e.g., \"Created 2 hours ago\")\n\n**Action buttons:**\n- **\"Refresh\"** button: Manually refresh job status\n- **\"Auto Refresh\"** toggle: When enabled (blue), automatically refreshes every 3 seconds while job is running\n- **\"Cancel Job\"** (red, for PENDING/CLAIMED jobs): Stops the job before it runs\n\n---\n\n**B) JOB STATUS OVERVIEW CARD** (main card, left side)\n\nShows:\n\n1. **Current Status** tag with icon (PENDING, RUNNING, COMPLETED, FAILED, NO_WORK_NEEDED)\n\n2. **Completion percentage** (large number, e.g., 85%)\n\n3. **Progress bar** (blue/green if running, red if failed)\n\n4. **Timing Information** (3 colored boxes):\n   - **Started At**: When job execution began (purple gradient)\n   - **Duration**: How long it took/is taking (blue gradient)\n   - **Completed At**: When it finished (green gradient) or \"Running\" if still active\n\n5. **Error Details** (if job failed): Red alert box showing the error message\n\n---\n\n**C) JOB DETAILS CARD** (below status overview)\n\nProvides metadata:\n\n- **Resource**: Name and type of resource that triggered the job\n  - Example: \"my-api-listener\" (Listeners â€¢ CREATE)\n\n- **Triggered By**: User information\n  - Username, display name, role\n\n- **Project**: Which project this job belongs to\n\n- **Duration**: Total execution time\n\n**For WAF_PROPAGATION jobs:**\n- **WAF Config**: Name of WAF profile\n- **Affected Wasm Filters**: List of Wasm filter names that were updated\n\n**For RESOURCE_UPGRADE jobs:**\n- **Current Version / Target Version**: Version upgrade path (e.g., v1.36.2 â†’ v1.37.0)\n- **Affected Listeners**: Number of listeners being upgraded\n- **Auto Create Missing**: Whether dependencies are auto-created (Yes/No tag)\n- **Mode**: \"Dry Run\" (preview only) or \"Live Upgrade\" (actually upgrades)\n\n---\n\n**D) QUICK STATS CARD** (right side, top)\n\nShows progress statistics:\n- **Total Listeners** (or Total Wasm Filters for WAF jobs): How many items need processing\n- **Completed**: Successfully processed items (green background)\n- **Failed**: Items that failed (red background)\n- **Analysis Time**: How long it took to analyze dependencies (in milliseconds)\n\n---\n\n**E) TIMELINE CARD** (right side, middle)\n\nShows chronological events:\n1. **Job Created**: Timestamp when job was created\n2. **Job Started**: When worker began processing\n3. **Job Completed/Failed**: Final outcome with timestamp\n\nEach event shows:\n- Absolute time (YYYY-MM-DD HH:mm:ss)\n- Relative time (e.g., \"2 hours ago\")\n\n---\n\n**F) ACTIONS CARD** (right side, if job is COMPLETED or FAILED)\n\nProvides action buttons:\n\n1. **\"Retry All\"**: Re-runs the entire job from scratch\n   - Creates a new job with retry_count incremented\n\n2. **\"Retry Failed Only\"**: Only retries snapshots that failed\n   - Skips already-successful snapshots\n   - Useful for transient network errors\n\n3. **\"Force Restart\"**: Completely restarts the job (warning: destructive)\n   - Shows confirmation modal before proceeding\n\n---\n\n**G) WORKER INFO CARD** (right side, if job was claimed by a worker)\n\nShows which worker is/was processing the job:\n- **Worker ID**: Unique identifier of the worker pod\n- **Claimed At**: When worker picked up the job\n- **Last Heartbeat**: Last time worker sent a heartbeat (e.g., \"5 seconds ago\")\n\n---\n\n**H) UPGRADE ANALYSIS CARD** (for RESOURCE_UPGRADE jobs only)\n\nShows detailed dependency analysis:\n\n**Summary Alert**: High-level overview of what will be upgraded\n\n**Overall Stats** (3 colored boxes):\n- **Total Dependencies**: All upstream resources needed\n- **Already Exist**: Resources that already exist in target version (green)\n- **Need to Create**: Missing resources that must be created (orange)\n\n**Listener Details** (expandable sections for each listener):\n\nFor each listener being upgraded:\n- **Listener Name** with dependency count\n- **Missing Resources**: Resources that don't exist in target version (orange boxes)\n- **Existing Resources**: Resources already present in target version (green boxes)\n\nEach resource shows:\n- Type tag (e.g., Cluster, Route, Secret)\n- Resource name\n\n**Skipped Resources**: Resources that couldn't be upgraded (gray tags)\n\n**Created Resources** (shown after job completes):\n- List of all resources successfully created during upgrade\n- Each shows: type, name, collection\n- Gray boxes indicate skipped resources\n\n---\n\n**I) SNAPSHOT EXECUTIONS TABLE** (bottom, for SNAPSHOT_UPDATE jobs)\n\nShows per-listener, per-client execution status:\n\n**Table Columns:**\n- **Listener Name**: Which listener's snapshot was sent\n- **Node ID**: Envoy node ID (client identifier)\n- **Status**: Tag showing PENDING, SUCCESS, or FAILED\n- **Sent At**: Timestamp when snapshot was sent via xDS\n- **Error**: Error message (if failed), truncated with tooltip on hover\n\n**Table Features:**\n- **Filtering**: Click column filter icons to filter by status (Success/Failed/Pending)\n- **Sorting**: Click column headers to sort\n- **Pagination**: Default 50 per page, adjustable to 20/50/100/200\n- **Search**: Shows \"X-Y of Z snapshots\" at bottom\n\n---\n\n**UNDERSTANDING JOB LIFECYCLE:**\n\n1. **PENDING**: Job created, waiting for available worker\n2. **CLAIMED**: Worker picked up the job, analyzing dependencies\n3. **RUNNING**: Worker is executing snapshots/updates\n4. **COMPLETED**: All snapshots succeeded\n5. **FAILED**: One or more snapshots failed\n6. **NO_WORK_NEEDED**: Job completed but no configuration changes were needed\n\n---\n\n**COMMON SCENARIOS:**\n\n**Scenario 1: Some snapshots failed**\n- Check \"SNAPSHOT EXECUTIONS\" table\n- Filter by \"Failed\" status\n- Look at error messages (hover over truncated text)\n- Use \"Retry Failed Only\" button to retry just those snapshots\n\n**Scenario 2: Job stuck in RUNNING**\n- Check \"Last Heartbeat\" in Worker Info\n- If heartbeat is old (>1 minute), worker may have crashed\n- Admin can clean up stuck jobs from Jobs list page\n\n**Scenario 3: Upgrade job shows missing dependencies**\n- Look at \"Missing Resources\" in Upgrade Analysis\n- If \"Auto Create Missing\" is enabled, job will create them automatically\n- If disabled, you must manually create those resources first"}
{"resource":"Jobs","category":"snapshot_workflow","instruction":"What is a snapshot and how does it work when I modify a listener or cluster?","output":"UNDERSTANDING SNAPSHOTS:\n\n**What is a Snapshot?**\n\nA **snapshot** is a complete, point-in-time copy of an Envoy configuration for a specific listener and all its dependencies. When you create or modify any Envoy resource in Elchi, the system:\n\n1. Analyzes which listeners are affected\n2. Gathers all dependencies (clusters, routes, endpoints, secrets, filters)\n3. Creates a snapshot (complete config dump)\n4. Sends it to elchi-clients via xDS (Envoy Discovery Service)\n5. Envoy hot-reloads the new configuration without downtime\n\n---\n\n**SNAPSHOT WORKFLOW - STEP BY STEP:**\n\n**Example: You modify a cluster**\n\n**STEP 1: YOU MAKE A CHANGE**\n\nYou edit a cluster resource (e.g., change health check settings) and click \"Update\".\n\n**STEP 2: ELCHI ANALYZES DEPENDENCIES**\n\nThe system determines:\n- Which **routes** reference this cluster?\n- Which **listeners** use those routes?\n- What other resources do those listeners need (secrets, endpoints, filters)?\n\nThis analysis typically takes 50-200ms (shown as \"Analysis Time\" in job details).\n\n**STEP 3: BACKGROUND JOB IS CREATED**\n\nElchi creates a **SNAPSHOT_UPDATE** job:\n- Type: SNAPSHOT_UPDATE\n- Status: PENDING\n- Metadata: Records which resource changed (e.g., \"my-backend-cluster\" â€¢ UPDATE)\n- Affected Listeners: List of listener names\n\nYou'll see a notification: \"Job EC-123 created\"\n\n**STEP 4: WORKER PICKS UP THE JOB**\n\nA background worker (Elchi server pod) claims the job:\n- Status changes: PENDING â†’ CLAIMED â†’ RUNNING\n- Worker analyzes dependency graph\n- For each affected listener, builds a complete snapshot containing:\n  - Listener configuration\n  - Routes (virtual hosts, route entries)\n  - Clusters (with your updated health check settings)\n  - Endpoints (load assignments)\n  - Secrets (TLS certificates)\n  - Extensions (access logs, filters)\n\n**STEP 5: SNAPSHOTS ARE SENT TO CLIENTS**\n\nFor each listener, for each elchi-client:\n\n1. Worker checks which clients are running this listener (from Service deployment)\n2. Worker sends snapshot via **xDS protocol** (gRPC stream)\n3. Client receives snapshot, validates it, applies it to Envoy\n4. Client sends ACK (acknowledgment) or NACK (reject) back\n5. Status is recorded:\n   - **SUCCESS**: Envoy accepted and applied the config\n   - **FAILED**: Envoy rejected (validation error, missing dependency, etc.)\n   - **PENDING**: Still waiting for response\n\n**STEP 6: JOB COMPLETES**\n\nOnce all snapshots are sent and responses received:\n- Status changes: RUNNING â†’ COMPLETED (if all succeeded) or FAILED (if any failed)\n- Progress shows 100%\n- You can view results in SNAPSHOT EXECUTIONS table\n\n---\n\n**VIEWING SNAPSHOT EXECUTION DETAILS:**\n\n**Method 1: From Job Detail Page**\n\n1) Click 'Jobs' from left menu\n2) Click on a job ID (e.g., EC-123)\n3) Scroll to bottom to see **\"SNAPSHOT EXECUTIONS\"** table\n4) Table shows:\n   - **Listener Name**: Which listener was updated\n   - **Node ID**: Envoy's unique identifier (usually pod name + hash)\n   - **Status**: SUCCESS (green), FAILED (red), or PENDING (blue)\n   - **Sent At**: Timestamp when snapshot was pushed\n   - **Error**: If failed, shows error message (e.g., \"cluster 'my-cluster' not found\")\n\n**Method 2: Filter by Status**\n\nIn the SNAPSHOT EXECUTIONS table:\n- Click the **filter icon** in \"Status\" column\n- Select \"Failed\" to see only failed snapshots\n- Check error messages to diagnose issues\n\n---\n\n**DEPENDENCY GRAPH EXAMPLE:**\n\nImagine you have:\n- Listener: \"api-gateway\" (port 443, HTTPS)\n- Route: \"api-routes\" (matches /v1/*)\n- Cluster: \"backend-cluster\" (your target)\n- Endpoint: \"backend-endpoints\"\n- Secret: \"api-tls-cert\"\n\nWhen you modify **\"backend-cluster\"**:\n\n```\nYou modify: backend-cluster\n     â†“\nAffects route: api-routes (references backend-cluster)\n     â†“\nAffects listener: api-gateway (uses api-routes)\n     â†“\nSnapshot includes:\n  - api-gateway config\n  - api-routes config\n  - backend-cluster config (with your changes)\n  - backend-endpoints config\n  - api-tls-cert config\n     â†“\nSent to all clients running \"api-gateway\"\n```\n\n---\n\n**SNAPSHOT UPDATE vs. SNAPSHOT RELOAD:**\n\n**Snapshot Update** (what we described above):\n- Triggered by resource changes in Elchi\n- Pushes new config to clients\n- Clients apply via xDS hot-reload\n- **Zero downtime** - Envoy swaps config atomically\n\n**Snapshot Reload** (manual operation):\n- You can manually trigger via Service page\n- Useful for:\n  - Recovering from failed snapshots\n  - Testing configuration\n  - Applying changes after client restarts\n\n---\n\n**COMMON SNAPSHOT SCENARIOS:**\n\n**Scenario 1: All snapshots succeed**\n- Job status: COMPLETED\n- Progress: 100%\n- All rows in SNAPSHOT EXECUTIONS show SUCCESS\n- **Action**: None needed, changes are live\n\n**Scenario 2: Some snapshots fail**\n- Job status: FAILED\n- Progress: e.g., 75% (3 of 4 succeeded)\n- Some rows show FAILED with error messages\n- **Common errors**:\n  - \"cluster 'X' not found\": Missing dependency\n  - \"validation failed\": Invalid configuration\n  - \"connection refused\": Client offline/unreachable\n- **Action**: Fix the issue, then use \"Retry Failed Only\" button\n\n**Scenario 3: No work needed**\n- Job status: NO_WORK_NEEDED\n- Progress: 100%\n- Means: Your change didn't actually affect any active listeners\n- Example: You modified a cluster not referenced by any route\n\n**Scenario 4: Client is offline**\n- SNAPSHOT EXECUTIONS shows PENDING forever\n- Error: \"timeout waiting for ACK\"\n- **Action**: Check if client is running (Service page â†’ Live/Offline status)\n\n---\n\n**SNAPSHOT VERSIONING (xDS Version):**\n\nEach snapshot has a version string (e.g., \"1234567890\"):\n- Incremented with each update\n- Sent to Envoy in xDS DiscoveryRequest/DiscoveryResponse\n- Envoy tracks which version it has\n- If client reconnects, Elchi sends latest snapshot\n\n---\n\n**TROUBLESHOOTING SNAPSHOT ISSUES:**\n\n**Problem**: Snapshot failed with \"validation error\"\n- **Cause**: Invalid Envoy configuration (typo, wrong field, incompatible settings)\n- **Solution**: Check error message, review resource configuration, fix and retry\n\n**Problem**: Snapshot stuck in PENDING\n- **Cause**: Client not responding, network issue, Envoy crashed\n- **Solution**: Check client status on Service page, verify network connectivity, check Envoy logs\n\n**Problem**: Job analysis takes too long (>5 seconds)\n- **Cause**: Very complex dependency graph (100+ resources)\n- **Solution**: Normal for large setups, just wait. Consider breaking into smaller listeners.\n\n**Problem**: Want to force re-send snapshot even if nothing changed\n- **Solution**: Go to Service page â†’ find service â†’ click \"Reload\" button (manually triggers snapshot push)"}
{"resource":"Jobs","category":"job_retry","instruction":"How do I retry a failed job or retry only the snapshots that failed?","output":"RETRYING FAILED JOBS:\n\nWhen a job fails (or completes with some failed snapshots), you have three retry options:\n\n1. **Retry All**: Re-runs the entire job from scratch\n2. **Retry Failed Only**: Only retries snapshots that failed\n3. **Force Restart**: Nuclear option - completely restarts (use with caution)\n\n---\n\n**METHOD 1: RETRY FROM JOB DETAIL PAGE**\n\n**STEP 1: NAVIGATE TO THE FAILED JOB**\n\n1) Click 'Jobs' from left menu\n2) Find the failed job (red \"FAILED\" tag or partial completion)\n3) Click on the **Job ID** to open detail page\n\n**STEP 2: REVIEW WHAT FAILED**\n\nScroll down to **\"SNAPSHOT EXECUTIONS\"** table:\n1) Click the **filter icon** in \"Status\" column\n2) Select \"Failed\" checkbox\n3) Review the error messages in the \"Error\" column\n4) Hover over truncated errors to see full text\n\n**Common error patterns:**\n- **\"cluster 'X' not found\"**: Missing dependency - create the cluster first\n- **\"validation failed: port already in use\"**: Configuration conflict\n- **\"connection refused\"**: Client offline or network issue\n- **\"timeout\"**: Client too slow or unresponsive\n\n**STEP 3: FIX THE UNDERLYING ISSUE (if applicable)**\n\nBased on the error:\n- If missing dependency: Create the required resource\n- If validation error: Fix the resource configuration\n- If connection issue: Check client status on Service page\n- If timeout: Check client resources (CPU/memory), check Envoy logs\n\n**STEP 4: CHOOSE RETRY OPTION**\n\nOn the right side, you'll see the **\"ACTIONS\"** card with buttons:\n\n**Option A: Retry Failed Only** (RECOMMENDED for partial failures)\n\n1) Click the blue **\"Retry Failed Only\"** button (ghost primary style)\n2) Elchi creates a NEW job that:\n   - Only processes snapshots that failed\n   - Skips snapshots that succeeded\n   - Inherits retry_info metadata (original_job_id, retry_count, retry_reason: \"manual_failed_only\")\n3) You're redirected to Jobs list\n4) New job appears with incremented job ID (e.g., EC-124 if original was EC-123)\n5) Job status shows as PENDING â†’ CLAIMED â†’ RUNNING\n\n**When to use:**\n- Some snapshots succeeded, some failed\n- You fixed the issue (e.g., created missing cluster)\n- Network issues that affected some clients\n\n**Option B: Retry All** (for complete re-run)\n\n1) Click the **\"Retry All\"** button\n2) Elchi creates a NEW job that:\n   - Re-processes ALL snapshots (even successful ones)\n   - Performs fresh dependency analysis\n   - Has retry_reason: \"manual\"\n3) You're redirected to Jobs list\n4) New job appears\n\n**When to use:**\n- You changed the resource configuration significantly\n- Dependency graph may have changed\n- You want a clean slate\n\n**Option C: Force Restart** (DANGER: destructive)\n\n1) Click the red **\"Force Restart\"** button\n2) A **confirmation modal** appears:\n   - Title: \"Force Restart Job\"\n   - Warning icon (âš )\n   - Message: \"This will completely restart the job from the beginning. Continue?\"\n3) Click **\"OK\"** to confirm (or \"Cancel\" to abort)\n4) Job is completely reset and restarted\n\n**When to use:**\n- Job is in a weird state (stuck in RUNNING but worker died)\n- Admin cleanup operation\n- **WARNING**: This is destructive and should rarely be needed\n\n---\n\n**METHOD 2: RETRY FROM JOBS LIST PAGE**\n\n**STEP 1: NAVIGATE TO JOBS**\n\n1) Click 'Jobs' from left menu\n2) Find the failed job in the table\n\n**STEP 2: OPEN ACTIONS MENU**\n\n1) Click the **three-dot menu (â‹®)** on the job row\n2) Available options appear in dropdown\n\n**STEP 3: SELECT RETRY ACTION**\n\n**For all jobs that are FAILED or COMPLETED:**\n- **\"Retry Job\"** option available â†’ same as \"Retry All\" above\n\n**For jobs with failed snapshots:**\n- **\"Retry Failed Only\"** option available â†’ same as \"Retry Failed Only\" above\n\n**For jobs that are PENDING or CLAIMED:**\n- **\"Cancel Job\"** option available â†’ stops the job before it completes\n\n---\n\n**UNDERSTANDING RETRY METADATA:**\n\nWhen you retry a job, the new job has **retry_info** metadata:\n\n```json\n{\n  \"original_job_id\": \"EC-123\",\n  \"retry_count\": 1,\n  \"retry_reason\": \"manual_failed_only\",\n  \"retry_type\": \"failed_only\"\n}\n```\n\n- **original_job_id**: The job you retried from\n- **retry_count**: How many times this job has been retried (increments each retry)\n- **retry_reason**: Why it was retried:\n  - `\"manual\"`: User clicked \"Retry All\"\n  - `\"manual_failed_only\"`: User clicked \"Retry Failed Only\"\n  - `\"pod_failure\"`: Worker pod crashed\n  - `\"timeout\"`: Job timed out\n- **retry_type**: \n  - `\"full\"`: Re-runs everything\n  - `\"failed_only\"`: Only failed snapshots\n  - `\"pending_only\"`: Only pending snapshots\n\nThis helps with debugging and audit trails.\n\n---\n\n**RETRY WORKFLOW DIAGRAM:**\n\n```\nOriginal Job (EC-123):\n  Listener A â†’ Client 1: SUCCESS âœ“\n  Listener A â†’ Client 2: FAILED âœ— (connection refused)\n  Listener B â†’ Client 1: SUCCESS âœ“\n  Listener B â†’ Client 2: FAILED âœ— (connection refused)\n  \n  Status: FAILED (50% success)\n\nâ†“ You fix the network issue, then click \"Retry Failed Only\"\n\nRetry Job (EC-124):\n  Listener A â†’ Client 2: SUCCESS âœ“ (skipped Client 1)\n  Listener B â†’ Client 2: SUCCESS âœ“ (skipped Client 1)\n  \n  Status: COMPLETED (100% success)\n```\n\n---\n\n**CANCELING A JOB (before it runs):**\n\nIf a job is stuck in **PENDING** or **CLAIMED** and you want to stop it:\n\n**STEP 1: OPEN ACTIONS**\n\n- From Jobs list: Click three-dot menu (â‹®)\n- From Job detail: Click red **\"Cancel Job\"** button in header\n\n**STEP 2: CONFIRM CANCELLATION**\n\n- Job status changes to FAILED\n- Error message: \"Cancelled by user\"\n- No snapshots are processed\n\n**When to use:**\n- You created a job by mistake\n- You want to fix the resource before the job runs\n- Job is stuck in PENDING for too long\n\n---\n\n**BEST PRACTICES:**\n\n1. **Always review errors first**: Check SNAPSHOT EXECUTIONS table to understand what failed before retrying\n\n2. **Fix root cause**: If error is \"missing cluster\", create the cluster before retrying\n\n3. **Use \"Retry Failed Only\" when possible**: Faster, more efficient, less load on system\n\n4. **Monitor retry_count**: If a job is retried 3+ times, something is seriously wrong - investigate deeply\n\n5. **Check client status**: Before retrying connection errors, verify clients are online (Service page)\n\n6. **Avoid Force Restart**: Only use when absolutely necessary (job is in impossible state)\n\n---\n\n**TROUBLESHOOTING RETRY ISSUES:**\n\n**Problem**: Retry job also fails with same error\n- **Cause**: Root cause not fixed\n- **Solution**: Carefully read error message, fix the actual issue (missing resource, invalid config, client down)\n\n**Problem**: Can't find \"Retry Failed Only\" button\n- **Cause**: Job has no failed snapshots (all succeeded or all failed completely)\n- **Solution**: Use \"Retry All\" instead\n\n**Problem**: Retry job creates a new job but it's stuck in PENDING\n- **Cause**: No available workers, or queue is full\n- **Solution**: Wait a few minutes, check worker status in stats at top of Jobs page\n\n**Problem**: Want to retry just specific snapshots (e.g., only one listener)\n- **Cause**: UI doesn't support granular retry (all or failed-only)\n- **Solution**: Workaround - manually trigger reload for that specific listener from Service page"}
{"resource":"Jobs","category":"job_types","instruction":"What are the different job types in Elchi and when are they created?","output":"JOB TYPES IN ELCHI:\n\nElchi has 5 main background job types, each triggered by different actions:\n\n---\n\n**1. SNAPSHOT_UPDATE**\n\n**Tag Color:** Blue\n**When Created:**\n- You create, update, or delete ANY Envoy resource:\n  - Listener\n  - Cluster\n  - Route\n  - Endpoint\n  - Secret\n  - Extension (access log, filter, etc.)\n  - Filter (HTTP, network, listener)\n\n**What It Does:**\n1. Analyzes dependency graph\n2. Identifies which listeners are affected\n3. For each affected listener:\n   - Gathers all dependencies (clusters, routes, endpoints, secrets)\n   - Creates a complete configuration snapshot\n   - Sends snapshot to elchi-clients via xDS\n4. Tracks success/failure per client\n\n**Example Triggers:**\n- Create a new listener â†’ SNAPSHOT_UPDATE for that listener\n- Modify a cluster â†’ SNAPSHOT_UPDATE for all listeners using routes that reference that cluster\n- Delete a route â†’ SNAPSHOT_UPDATE for listeners using that route\n\n**Metadata Includes:**\n- `source_resource`: Which resource changed (name, collection, action: CREATE/UPDATE/DELETE)\n- `affected_listeners`: List of listener names\n- `total_affected`: Number of listeners\n- `analysis_duration_ms`: How long dependency analysis took\n\n**Job Detail Shows:**\n- SNAPSHOT EXECUTIONS table with per-listener, per-client status\n- Progress bar (e.g., \"3 of 4 snapshots succeeded\")\n\n---\n\n**2. DISCOVERY_UPDATE**\n\n**Tag Color:** Green\n**When Created:**\n- Kubernetes service/pod/endpoint changes are detected\n- Discovery sync runs (periodic background task)\n- You manually trigger discovery refresh\n\n**What It Does:**\n1. Queries Kubernetes API for Service/Deployment/StatefulSet resources\n2. Finds matching Endpoint resources in Elchi (by discovery selector)\n3. Updates lb_endpoints with current pod IPs and ports\n4. Triggers SNAPSHOT_UPDATE for listeners using those endpoints\n\n**Example Triggers:**\n- Pod scales up/down in Kubernetes\n- Service selector changes\n- Pod IP changes (restart)\n- You click \"Refresh Discovery\" button on Discovery page\n\n**Metadata Includes:**\n- `source_resource`: Which discovery configuration triggered the update\n- `affected_listeners`: Listeners using the updated endpoints\n- Discovery-specific fields (namespace, service name, selector)\n\n**Job Detail Shows:**\n- How many endpoints were updated\n- Which listeners were affected\n- SNAPSHOT EXECUTIONS table\n\n---\n\n**3. WAF_PROPAGATION**\n\n**Tag Color:** Purple (or custom)\n**When Created:**\n- You create or update a WAF (Web Application Firewall) profile\n- You modify directive sets in a WAF profile\n- You change CRS (Core Rule Set) rules\n\n**What It Does:**\n1. Finds all Wasm filters that reference this WAF profile\n2. For each Wasm filter:\n   - Updates the inline_bytes or filename with new WAF config\n   - Identifies which listeners use this Wasm filter\n3. Triggers snapshot updates for affected listeners\n\n**Example Triggers:**\n- Update WAF profile \"production-waf\" â†’ all listeners with Wasm filters referencing it are updated\n- Add a new CRS rule to directive set â†’ WAF config regenerated and propagated\n\n**Metadata Includes:**\n- `waf_config`: { name, project } of WAF profile\n- `affected_wasm`: List of Wasm filter names that were updated\n- `affected_listeners`: Listeners using those Wasm filters\n\n**Job Detail Shows:**\n- **WAF Config** name\n- **Affected Wasm Filters** (blue tags)\n- SNAPSHOT EXECUTIONS table\n- Progress bar for snapshot propagation\n\n---\n\n**4. RESOURCE_UPGRADE**\n\n**Tag Color:** Orange\n**When Created:**\n- You upgrade a resource from one Envoy version to another\n- Example: Upgrade listener from v1.36.2 to v1.37.0\n- Triggered from Resource upgrade modal or bulk upgrade page\n\n**What It Does:**\n\n**Phase 1: Dependency Analysis**\n1. Analyzes resource dependency graph\n2. Lists all upstream dependencies (clusters, routes, secrets, etc.)\n3. Checks which dependencies exist in target version\n4. Identifies missing dependencies\n5. Generates analysis report\n\n**Phase 2: Resource Creation** (if auto_create_missing = true)\n1. For each missing dependency:\n   - Fetches source resource from current version\n   - Converts to target version (protobuf transformation)\n   - Creates new resource in target version\n   - Records in `created_resources` list\n\n**Phase 3: Snapshot Update**\n1. Upgrades the main resource (listener, cluster, etc.)\n2. Triggers SNAPSHOT_UPDATE for affected listeners\n\n**Example Triggers:**\n- Upgrade listener \"api-gateway\" from v1.36.2 to v1.37.0\n- Bulk upgrade all v1.36.2 listeners to v1.37.0\n\n**Metadata Includes:**\n- `upgrade_config`:\n  - `target_version`: Target Envoy version\n  - `auto_create_missing`: Whether to auto-create dependencies (true/false)\n  - `validate_clients`: Whether to validate client compatibility (true/false)\n  - `update_bootstrap`: Whether to update bootstrap reference (true/false)\n  - `dry_run`: Preview mode (true) or actual upgrade (false)\n  - `analysis`: Detailed dependency analysis (see below)\n  - `created_resources`: List of resources created during upgrade\n\n**Analysis Structure:**\n```json\n{\n  \"listeners_to_upgrade\": [\"api-gateway\", \"web-frontend\"],\n  \"listener_details\": [\n    {\n      \"listener_name\": \"api-gateway\",\n      \"exists_in_target\": false,\n      \"upstream_dependencies\": 5,\n      \"missing_resources\": [\n        { \"gtype\": \"Cluster\", \"name\": \"backend-cluster\", \"collection\": \"clusters\" }\n      ],\n      \"existing_resources\": [\n        { \"gtype\": \"Secret\", \"name\": \"tls-cert\", \"collection\": \"secrets\" }\n      ],\n      \"bootstrap_required\": true\n    }\n  ],\n  \"upstream_dependencies\": 10,\n  \"missing_in_target\": 3,\n  \"existing_in_target\": 7,\n  \"bootstrap_required\": true,\n  \"clients_validated\": 4,\n  \"summary\": \"Upgrade requires creating 3 missing resources across 2 listeners.\"\n}\n```\n\n**Job Detail Shows:**\n- **Current Version / Target Version** tags (blue â†’ green)\n- **Affected Listeners** count\n- **Auto Create Missing** tag (Yes/No)\n- **Mode** tag (Dry Run / Live Upgrade)\n- **UPGRADE ANALYSIS** card:\n  - Total Dependencies\n  - Already Exist (green)\n  - Need to Create (orange)\n  - Per-listener breakdown\n  - Missing/Existing resources with type tags\n  - Skipped resources\n  - Created resources (after completion)\n\n---\n\n**5. RESOURCE_UPGRADE(DRY)**\n\n**Tag Color:** Yellow/Warning\n**When Created:**\n- You run an upgrade in **preview mode** (dry_run = true)\n- Same as RESOURCE_UPGRADE but doesn't actually create resources or update configs\n\n**What It Does:**\n1. Performs full dependency analysis (same as RESOURCE_UPGRADE)\n2. Simulates resource creation\n3. Reports what WOULD happen\n4. **Does NOT**:\n   - Create any resources\n   - Update any configurations\n   - Trigger snapshot updates\n\n**Use Cases:**\n- Preview upgrade impact before committing\n- Check if dependencies exist\n- Validate compatibility\n- Plan upgrade strategy\n\n**Metadata:**\n- Same structure as RESOURCE_UPGRADE\n- `dry_run: true` in upgrade_config\n\n**Job Detail Shows:**\n- Same analysis cards as RESOURCE_UPGRADE\n- **Mode** tag shows \"Dry Run\" (yellow)\n- No actual snapshot executions (preview only)\n\n---\n\n**JOB TYPE COMPARISON TABLE:**\n\n| Job Type | Trigger | Purpose | Creates Snapshots? | Modifies Resources? |\n|----------|---------|---------|-------------------|--------------------|\n| SNAPSHOT_UPDATE | Resource change | Push config to Envoy | âœ… Yes | âŒ No |\n| DISCOVERY_UPDATE | K8s change | Update endpoints | âœ… Yes (via snapshot) | âœ… Yes (endpoints) |\n| WAF_PROPAGATION | WAF profile change | Update WAF configs | âœ… Yes | âœ… Yes (Wasm filters) |\n| RESOURCE_UPGRADE | Manual upgrade | Upgrade to new version | âœ… Yes | âœ… Yes (creates resources) |\n| RESOURCE_UPGRADE(DRY) | Preview upgrade | Analyze upgrade impact | âŒ No | âŒ No |\n\n---\n\n**VIEWING JOB TYPE IN UI:**\n\n**Jobs List Page:**\n- **Type** column shows colored tag (e.g., \"Snapshot Update\", \"WAF Propagation\")\n- Filter by type using \"Type Filter\" dropdown at top\n\n**Job Detail Page:**\n- Job type shown in header (e.g., \"Job EC-123\" with \"Resource Upgrade\" tag)\n- Different cards appear based on type:\n  - WAF jobs show \"WAF Config\" and \"Affected Wasm Filters\"\n  - Upgrade jobs show \"Upgrade Analysis\" card\n  - Snapshot jobs show \"SNAPSHOT EXECUTIONS\" table"}
{"resource":"Jobs","category":"monitoring","instruction":"How do I monitor job progress in real-time and see statistics?","output":"MONITORING JOBS AND STATISTICS:\n\n---\n\n**PART 1: REAL-TIME JOB MONITORING**\n\n**MONITORING A SPECIFIC JOB:**\n\n**STEP 1: OPEN JOB DETAIL PAGE**\n\n1) Click 'Jobs' from left menu\n2) Find the running job (blue \"RUNNING\" tag with animated progress)\n3) Click on the **Job ID**\n\n**STEP 2: ENABLE AUTO-REFRESH**\n\n1) In the header area, you'll see a **\"Auto Refresh\"** button\n2) Click it to enable (button turns **blue** when active)\n3) When enabled:\n   - Job refreshes automatically every **3 seconds**\n   - You see a **dot (â€¢)** next to \"Auto Refresh\" text\n   - No need to manually click \"Refresh\" button\n4) Auto-refresh automatically **disables** when job completes (COMPLETED, FAILED, or NO_WORK_NEEDED)\n\n**STEP 3: WATCH REAL-TIME UPDATES**\n\nYou'll see live updates to:\n\n**A) Progress Percentage**\n- Large number (e.g., 45%, 67%, 92%)\n- Updates as snapshots complete\n\n**B) Progress Bar**\n- Blue/green animated bar\n- Fills left-to-right as job progresses\n- Turns red if failures occur\n- Shows striped animation while running\n\n**C) Quick Stats Card** (right side)\n- **Total**: Total snapshots to process\n- **Completed**: âœ“ count (green background)\n- **Failed**: âœ— count (red background)\n- Numbers update in real-time\n\n**D) Duration Timer**\n- \"Duration\" box shows elapsed time\n- Updates continuously (e.g., \"2m 15s\", \"5m 42s\")\n- Shows in human-readable format\n\n**E) SNAPSHOT EXECUTIONS Table** (bottom)\n- New rows appear as snapshots are processed\n- **Sent At** column shows timestamps\n- **Status** tags change from PENDING (blue) â†’ SUCCESS (green) or FAILED (red)\n- **Error** column populates if failures occur\n\n**STEP 4: DISABLE AUTO-REFRESH (optional)**\n\n1) Click **\"Auto Refresh\"** button again to turn off\n2) Button returns to default (not blue)\n3) Useful if you want to pause and read error messages\n\n---\n\n**MONITORING MULTIPLE JOBS:**\n\n**STEP 1: OPEN JOBS LIST PAGE**\n\n1) Click 'Jobs' from left menu\n2) You see all jobs in a table\n\n**STEP 2: FILTER FOR ACTIVE JOBS**\n\n1) Click **\"Status Filter\"** dropdown at top\n2) Select:\n   - â˜‘ PENDING\n   - â˜‘ CLAIMED  \n   - â˜‘ RUNNING\n3) Click **\"Apply Filters\"** button (search icon)\n4) Table now shows only active jobs\n\n**STEP 3: WATCH PROGRESS COLUMN**\n\nThe **\"Progress\"** column shows:\n- **Progress bar** (horizontal, colored)\n- **Percentage text** (e.g., \"45%\")\n- **Status indicator**:\n  - Blue stripes: Running\n  - Red stripes: Failed\n  - Green solid: Completed\n\n**STEP 4: MANUALLY REFRESH**\n\n1) Click the **\"Refresh\"** button (top right, reload icon)\n2) Or press **F5** to refresh page\n3) Jobs list updates with latest status\n\n**Pro Tip:** Sort by \"Created\" column (newest first) to see latest jobs at top.\n\n---\n\n**PART 2: JOB STATISTICS**\n\n**VIEWING OVERALL STATISTICS:**\n\n**STEP 1: GO TO JOBS PAGE**\n\n1) Click 'Jobs' from left menu\n2) Statistics cards appear at the **top of the page**\n\n**STEP 2: UNDERSTAND STATISTICS CARDS**\n\n**Card 1: TOTAL JOBS**\n- Icon: Bar chart icon (ðŸ“Š)\n- Shows: Total number of jobs in selected date range\n- Example: \"347\" jobs\n- Color: Blue\n\n**Card 2: QUEUE SIZE**\n- Icon: Clock icon (ðŸ•)\n- Shows: Number of jobs waiting to be processed (PENDING status)\n- Example: \"5\" jobs in queue\n- Color: Orange\n- **Interpretation:**\n  - 0-10: Normal\n  - 10-50: Moderate load\n  - 50+: High load, jobs may be delayed\n\n**Card 3: ACTIVE WORKERS**\n- Icon: Thunder icon (âš¡)\n- Shows: Number of worker processes currently running\n- Example: \"3\" workers\n- Color: Green\n- **Interpretation:**\n  - More workers = faster job processing\n  - If 0 workers, jobs won't run (critical issue!)\n\n**Card 4: PROCESSING JOBS**\n- Icon: Play icon (â–¶)\n- Shows: Jobs currently being executed (CLAIMED or RUNNING status)\n- Example: \"2\" jobs processing\n- Color: Blue\n- **Interpretation:**\n  - Should be â‰¤ Active Workers\n  - If stuck at same number for long time, check for stuck jobs\n\n**Card 5: JOBS BY STATUS** (breakdown)\n- Shows counts for each status:\n  - PENDING: Blue tag\n  - RUNNING: Green tag  \n  - COMPLETED: Green checkmark tag\n  - FAILED: Red X tag\n  - NO_WORK_NEEDED: Gray tag\n- Example: \"COMPLETED: 312, FAILED: 15, PENDING: 5\"\n\n---\n\n**FILTERING STATISTICS BY DATE RANGE:**\n\n**STEP 1: USE DATE RANGE PICKER**\n\n1) At top of Jobs page, find **RangePicker** (calendar icon)\n2) Default: Last 1 month (last 30 days)\n3) Click to open calendar\n\n**STEP 2: SELECT CUSTOM RANGE**\n\n1) Click **start date** on left calendar\n2) Click **end date** on right calendar\n3) Click **\"OK\"** or press Enter\n4) Click **\"Apply Filters\"** button\n\n**STEP 3: VIEW UPDATED STATISTICS**\n\n- Statistics cards update to show counts for selected date range\n- Jobs table updates to show only jobs in that range\n\n**Quick Date Ranges:**\n- Last 24 hours: Select today â†’ today\n- Last week: Select 7 days ago â†’ today\n- Last month: Select 30 days ago â†’ today\n- Custom: Any arbitrary range\n\n---\n\n**ADVANCED STATISTICS (from Job Stats API):**\n\nWhile not directly visible in UI, the system tracks:\n\n**Jobs by Resource:**\n- How many jobs were triggered by Listeners vs. Clusters vs. Routes\n- Useful for understanding which resources change most frequently\n\n**Jobs by User:**\n- Which users trigger the most jobs\n- Useful for auditing and understanding team activity\n\n**Recent Jobs:**\n- Latest 10-20 jobs\n- Shown in Jobs list table\n\n**Last Updated:**\n- Timestamp when statistics were last calculated\n- Typically updated every few seconds\n\n---\n\n**MONITORING STUCK JOBS:**\n\n**STEP 1: CHECK FOR STUCK JOBS ALERT**\n\nAt top of Jobs page, if stuck jobs exist:\n- **Red Alert** appears: \"âš  Warning: X stuck/abandoned jobs detected\"\n- Shows count of stuck jobs\n\n**STEP 2: UNDERSTAND STUCK JOBS**\n\n**What is a stuck job?**\n- Job status is CLAIMED or RUNNING\n- But worker that claimed it has crashed or disappeared\n- Last heartbeat was >1 minute ago\n- Job won't complete on its own\n\n**Common causes:**\n- Worker pod crashed (OOMKilled, evicted)\n- Worker pod restarted/deployed\n- Network partition\n- System crash\n\n**STEP 3: CLEAN UP STUCK JOBS**\n\n1) Click **\"Clean Up Stuck Jobs\"** button in alert\n2) Confirmation modal appears:\n   - Title: \"Clean Up Stuck Jobs\"\n   - Message: \"This will clean up X stuck/abandoned jobs. This action cannot be undone.\"\n3) Click **\"Clean Up\"** to proceed\n4) System:\n   - Marks stuck jobs as FAILED\n   - Sets error: \"Job abandoned (worker died)\"\n   - Releases them for retry\n5) Alert disappears\n6) Jobs list refreshes\n\n---\n\n**MONITORING BEST PRACTICES:**\n\n**1. Watch Queue Size:**\n- If queue grows >20, investigate:\n  - Are workers running?\n  - Are jobs taking too long?\n  - Is system overloaded?\n\n**2. Monitor Failed Jobs:**\n- Check FAILED count daily\n- If failures spike, investigate root cause\n- Common causes:\n  - Invalid configurations\n  - Network issues\n  - Client offline\n\n**3. Use Auto-Refresh for Long Jobs:**\n- Enable for upgrade jobs (5+ minutes)\n- Disable for quick jobs (< 30 seconds) to reduce load\n\n**4. Check Worker Count:**\n- If 0 workers, jobs won't run (critical!)\n- Typical setup: 3-5 workers\n- Scale workers based on job volume\n\n**5. Set Up Alerts (external monitoring):**\n- Alert if queue size >50 for >5 minutes\n- Alert if stuck jobs >0\n- Alert if active workers = 0\n- Alert if failed job rate >10% over 1 hour\n\n---\n\n**TROUBLESHOOTING MONITORING ISSUES:**\n\n**Problem**: Statistics don't update\n- **Solution**: Refresh page (F5), check network connection\n\n**Problem**: Auto-refresh not working\n- **Solution**: Check if job is still RUNNING (auto-refresh disables when job completes)\n\n**Problem**: Progress bar stuck at 99%\n- **Solution**: Check SNAPSHOT EXECUTIONS table for pending/failed snapshots, may need manual intervention\n\n**Problem**: Worker count shows 0\n- **Solution**: Critical issue! Check if Elchi worker pods are running (kubectl get pods), restart workers\n\n**Problem**: Queue size keeps growing\n- **Solution**: Check worker logs for errors, verify workers are processing jobs, may need to scale up workers"}
{"resource":"Jobs","category":"dependencies","instruction":"How do I understand job dependencies and what resources will be affected by a change?","output":"UNDERSTANDING JOB DEPENDENCIES:\n\nWhen you modify an Envoy resource in Elchi, the system automatically analyzes dependencies to determine:\n1. Which other resources are affected?\n2. Which listeners need new snapshots?\n3. What order should updates happen?\n\nThis is called **dependency analysis**.\n\n---\n\n**PART 1: DEPENDENCY GRAPH BASICS**\n\n**Envoy Resource Hierarchy:**\n\n```\nBootstrap (top-level)\n  â†“\nListener (entry point)\n  â†“ references\nRoute Configuration (routing rules)\n  â†“ references\nCluster (backend service)\n  â†“ references\nEndpoint (actual servers/IPs)\n\n+ Cross-cutting:\n  - Secrets (TLS certificates) â†’ used by Listeners, Clusters\n  - Filters (HTTP/network/listener) â†’ used by Listeners, Routes\n  - Extensions (access logs, etc.) â†’ used by multiple resources\n```\n\n**Dependency Directions:**\n\n**Downstream dependencies** (what uses this resource):\n- Example: \"Which listeners use cluster X?\"\n- Used when you MODIFY a resource\n- Determines which snapshots to update\n\n**Upstream dependencies** (what this resource needs):\n- Example: \"What does listener X need to run? (routes, clusters, secrets)\"\n- Used when you CREATE or UPGRADE a resource\n- Determines what must exist first\n\n---\n\n**PART 2: VIEWING DEPENDENCIES BEFORE CREATING A JOB**\n\n**Scenario: You're about to modify a cluster**\n\n**STEP 1: CHECK AFFECTED LISTENERS (before saving)**\n\nUnfortunately, the UI doesn't show a preview BEFORE you save. But you can infer:\n\n**Method A: Check Route References**\n1) Go to 'Route' page\n2) Use search/filter to find routes referencing your cluster name\n3) Note down route names\n4) Go to 'Listener' page  \n5) Filter for listeners using those routes\n6) **These listeners will be affected** by your cluster change\n\n**Method B: Use Registry Info** (if available)\n1) On the Cluster edit page, some versions show \"Used by\" info\n2) Shows which routes reference this cluster\n3) Click to navigate to those routes\n\n**STEP 2: SAVE AND CREATE JOB**\n\n1) Click \"Update\" button on cluster\n2) Job is created (e.g., EC-125)\n3) Notification appears: \"Job EC-125 created\"\n\n**STEP 3: VIEW DEPENDENCY ANALYSIS IN JOB**\n\n1) Click on notification or go to Jobs page\n2) Click on **Job ID** (EC-125)\n3) Job detail page shows:\n\n**In JOB DETAILS card:**\n- **Resource**: \"my-backend-cluster\" (Clusters â€¢ UPDATE)\n- **Affected Listeners**: Shows count (e.g., \"3 listeners\")\n\n**In Quick Stats:**\n- **Total**: Total snapshots that will be sent\n- Formula: `affected_listeners Ã— clients_per_listener`\n- Example: 3 listeners Ã— 2 clients each = 6 total snapshots\n\n**In metadata** (visible in API, not UI):\n```json\n{\n  \"affected_listeners\": [\"api-gateway\", \"web-frontend\", \"internal-service\"],\n  \"total_affected\": 3,\n  \"analysis_duration_ms\": 87\n}\n```\n\n---\n\n**PART 3: DEPENDENCY ANALYSIS FOR UPGRADES**\n\n**Scenario: You're upgrading a listener from v1.36.2 to v1.37.0**\n\n**STEP 1: INITIATE UPGRADE**\n\n1) Go to Listener page\n2) Find listener in v1.36.2\n3) Click Actions menu (â‹®) â†’ \"Upgrade\"\n4) Upgrade modal opens\n\n**STEP 2: CONFIGURE UPGRADE**\n\nIn the modal:\n1) **Target Version**: Select v1.37.0\n2) **Auto Create Missing**: â˜‘ Enable (recommended)\n3) **Dry Run**: â˜‘ Enable (IMPORTANT for first time)\n4) Click **\"Analyze\"** or **\"Preview Upgrade\"** button\n\n**STEP 3: VIEW DEPENDENCY ANALYSIS**\n\nA **RESOURCE_UPGRADE(DRY)** job is created. Open job detail page.\n\n**UPGRADE ANALYSIS Card Shows:**\n\n**A) Overall Stats** (3 colored boxes)\n\n**Total Dependencies** (blue box):\n- Example: \"12\"\n- Means: This listener needs 12 other resources to function\n- Includes: Routes, Clusters, Endpoints, Secrets, Filters, Extensions\n\n**Already Exist** (green box):\n- Example: \"9\"\n- Means: 9 of those 12 resources already exist in v1.37.0\n- Good news: These won't need to be created\n\n**Need to Create** (orange box):\n- Example: \"3\"\n- Means: 3 resources are missing in v1.37.0\n- If \"Auto Create Missing\" is enabled, these will be created automatically\n- If disabled, you must create them manually first\n\n**B) Listener Details** (per-listener breakdown)\n\nFor each listener being upgraded:\n\n**Section Title:**\n- Listener name: \"api-gateway\"\n- Dependency count tag: \"12 dependencies\"\n\n**Missing Resources** (left column, orange background):\n- Shows resources that DON'T exist in target version\n- Each resource displays:\n  - **Type tag** (orange): Cluster, Route, Secret, etc.\n  - **Name**: Resource name (e.g., \"backend-v2-cluster\")\n- Example:\n  ```\n  [Cluster] backend-v2-cluster\n  [Route] api-routes-v2\n  [Secret] wildcard-tls-cert\n  ```\n\n**Existing Resources** (right column, green background):\n- Shows resources that ALREADY exist in target version\n- Each resource displays:\n  - **Type tag** (green): Cluster, Route, Secret, etc.\n  - **Name**: Resource name\n- Example:\n  ```\n  [Cluster] auth-cluster\n  [Endpoint] backend-endpoints\n  [Secret] internal-ca-cert\n  ```\n\n**C) Skipped Resources** (bottom)\n\n- Resources that can't be auto-created\n- Reasons:\n  - Unsupported type\n  - Circular dependency\n  - Manual intervention required\n- Shows as gray tags\n- Example: `bootstrap-config (bootstraps)`, `custom-extension (extensions)`\n\n**STEP 4: INTERPRET ANALYSIS**\n\n**Green light to upgrade:**\n- \"Need to Create\" = 0 OR \"Auto Create Missing\" = Yes\n- No critical errors\n- All dependencies resolvable\n\n**Yellow caution:**\n- \"Need to Create\" > 0 and \"Auto Create Missing\" = No\n- **Action**: Manually create missing resources first, then upgrade\n\n**Red stop:**\n- Skipped resources present\n- Bootstrap required but \"Update Bootstrap\" = No\n- Circular dependencies detected\n- **Action**: Resolve issues before upgrading\n\n**STEP 5: PROCEED WITH REAL UPGRADE**\n\n1) If dry run looks good, go back to upgrade modal\n2) **Uncheck** \"Dry Run\"\n3) Click **\"Upgrade\"**\n4) New **RESOURCE_UPGRADE** job created (not DRY)\n5) Job will:\n   - Create missing resources (if enabled)\n   - Upgrade the listener\n   - Trigger snapshot updates\n\n**STEP 6: VIEW CREATED RESOURCES**\n\nAfter job completes:\n1) Scroll down in job detail page\n2) **CREATED RESOURCES** section appears (green alert)\n3) Shows all resources that were created:\n   - Green boxes: Successfully created\n   - Gray boxes: Skipped (already existed)\n   - Each shows: type tag, name, collection\n\n---\n\n**PART 4: DEPENDENCY ANALYSIS FOR WAF JOBS**\n\n**Scenario: You modify a WAF profile**\n\n**STEP 1: UPDATE WAF PROFILE**\n\n1) Go to 'WAF' page under INFRASTRUCTURE\n2) Edit a WAF profile (e.g., change CRS rules)\n3) Click \"Save\"\n\n**STEP 2: WAF_PROPAGATION JOB CREATED**\n\n1) Go to Jobs page\n2) Find the WAF_PROPAGATION job\n3) Click Job ID to open detail\n\n**STEP 3: VIEW WAF DEPENDENCIES**\n\n**In JOB DETAILS card:**\n\n**WAF Config** (shows which WAF profile was modified):\n- Name: \"production-waf\"\n- Project: \"default\"\n\n**Affected Wasm Filters** (blue tags):\n- Shows Wasm filter names that reference this WAF\n- Example: `waf-filter-api`, `waf-filter-web`\n- Count: \"2 filters\"\n\n**Affected Listeners** (not directly shown, but inferred):\n- Listeners using those Wasm filters will receive snapshot updates\n- Check SNAPSHOT EXECUTIONS table to see listener names\n\n**STEP 4: TRACE FULL DEPENDENCY CHAIN**\n\nWAF profile â†’ Wasm filters â†’ HTTP filter chains â†’ Listeners â†’ Clients\n\n1. **WAF Profile**: production-waf (you modified this)\n2. **Wasm Filters**: waf-filter-api, waf-filter-web (reference the profile)\n3. **Listeners**: api-gateway, web-frontend (use those Wasm filters in HTTP filter chains)\n4. **Clients**: All elchi-clients running those listeners\n5. **Snapshots**: One per listener per client\n\n---\n\n**PART 5: COMMON DEPENDENCY PATTERNS**\n\n**Pattern 1: Cluster Change**\n```\nYou modify: Cluster \"backend-cluster\"\n  â†“ used by\nRoute: \"api-routes\" (references backend-cluster in route action)\n  â†“ used by\nListener: \"api-gateway\" (uses api-routes)\n  â†“ deployed to\nClients: client-1, client-2\n  â†“ results in\nSnapshots: 2 (one per client)\n```\n\n**Pattern 2: Secret Change** (TLS certificate rotation)\n```\nYou modify: Secret \"wildcard-cert\"\n  â†“ used by\nListeners: \"https-listener-1\", \"https-listener-2\", \"https-listener-3\"\n  (all use wildcard-cert in downstream_tls_context)\n  â†“ deployed to\nClients: 4 clients per listener\n  â†“ results in\nSnapshots: 12 (3 listeners Ã— 4 clients)\n```\n\n**Pattern 3: Filter Change**\n```\nYou modify: CORS filter \"api-cors\"\n  â†“ used in HTTP filter chain of\nListener: \"api-gateway\"\n  â†“ deployed to\nClients: 2 clients\n  â†“ results in\nSnapshots: 2\n```\n\n---\n\n**PART 6: TROUBLESHOOTING DEPENDENCY ISSUES**\n\n**Problem**: Job shows 0 affected listeners but I expected some\n- **Cause**: Resource is not actually referenced by any listener\n- **Solution**: Check if routes/filters are correctly configured to use this resource\n\n**Problem**: Upgrade analysis shows unexpected missing resources\n- **Cause**: Resource was renamed or deleted in target version\n- **Solution**: Review \"Missing Resources\" list, create them manually or enable \"Auto Create Missing\"\n\n**Problem**: Job fails with \"cluster 'X' not found\"\n- **Cause**: Dependency exists in Elchi but wasn't included in snapshot\n- **Solution**: Check if cluster name matches exactly (case-sensitive), verify cluster exists in correct version\n\n**Problem**: Circular dependency detected in upgrade\n- **Cause**: Route A references Cluster B, which references Endpoint C, which references Route A (invalid)\n- **Solution**: Refactor configuration to break cycle\n\n**Problem**: Too many snapshots triggered by one change\n- **Cause**: Resource is shared by many listeners (e.g., shared secret)\n- **Solution**: Normal behavior, just wait for job to complete. Consider reducing sharing if performance is an issue."}
{"resource":"Jobs","category":"troubleshooting","instruction":"What do I do when a job fails or gets stuck? How do I debug job errors?","output":"TROUBLESHOOTING FAILED AND STUCK JOBS:\n\n---\n\n**PART 1: DIAGNOSING A FAILED JOB**\n\n**STEP 1: IDENTIFY THE FAILURE**\n\n1) Go to 'Jobs' from left menu\n2) Look for jobs with:\n   - **Red \"FAILED\" tag** in Status column\n   - **Red progress bar** (indicates errors)\n   - **Progress < 100%** with FAILED status\n\n**STEP 2: OPEN JOB DETAIL**\n\n1) Click on the **Job ID**\n2) Job detail page opens\n\n**STEP 3: CHECK ERROR SUMMARY**\n\nIn the **JOB STATUS OVERVIEW** card:\n\n**If there's a top-level error:**\n- Red **Alert box** appears below progress bar\n- Title: \"Error Details\"\n- Description: Error message\n- **Common top-level errors:**\n  - `\"Analysis failed: circular dependency detected\"`\n  - `\"Worker timeout: job exceeded maximum duration\"`\n  - `\"Invalid configuration: listener name cannot be empty\"`\n  - `\"Permission denied: user cannot access resource\"`\n\n**If no top-level error:**\n- Job started but individual snapshots failed\n- Proceed to Step 4\n\n**STEP 4: EXAMINE SNAPSHOT FAILURES**\n\nScroll to **SNAPSHOT EXECUTIONS** table at bottom:\n\n1) Click **filter icon** in \"Status\" column\n2) Check â˜‘ \"Failed\" to show only failed snapshots\n3) Review **Error** column for each failed row\n\n**STEP 5: CATEGORIZE THE ERROR**\n\nMatch error message to category below:\n\n---\n\n**ERROR CATEGORY 1: MISSING DEPENDENCY**\n\n**Error Messages:**\n- `\"cluster 'backend-cluster' not found\"`\n- `\"route configuration 'api-routes' does not exist\"`\n- `\"secret 'tls-cert' not found in version v1.37.0\"`\n- `\"endpoint 'backend-endpoints' is required but missing\"`\n\n**What It Means:**\n- Your listener/route references a resource that doesn't exist\n- Dependency was deleted or never created\n- Version mismatch (resource exists in v1.36.2 but not v1.37.0)\n\n**How to Fix:**\n\n1) **Identify the missing resource:**\n   - Resource type: Cluster, Route, Secret, Endpoint\n   - Resource name: From error message\n   - Version: Which version is it missing from?\n\n2) **Check if resource exists:**\n   - Go to that resource page (e.g., 'Cluster')\n   - Filter by version (if applicable)\n   - Search for resource name\n\n3) **Create the missing resource:**\n   - If it doesn't exist: Create it\n   - If it's in wrong version: Upgrade it or create in target version\n   - If it was deleted: Recreate or update listener to not reference it\n\n4) **Retry the job:**\n   - Go back to job detail page\n   - Click **\"Retry Failed Only\"** button\n   - New job will retry with fixed configuration\n\n---\n\n**ERROR CATEGORY 2: VALIDATION ERROR**\n\n**Error Messages:**\n- `\"validation failed: port 443 already in use by listener 'other-listener'\"`\n- `\"invalid header name: 'X-Invalid Header'\"`\n- `\"cluster connect_timeout must be greater than 0\"`\n- `\"route match path cannot be empty\"`\n- `\"TLS context requires certificate chain\"`\n\n**What It Means:**\n- Configuration is invalid according to Envoy's validation rules\n- Field value is out of range, wrong format, or conflicts with another resource\n- Protobuf validation failed\n\n**How to Fix:**\n\n1) **Read error message carefully** - it usually says exactly what's wrong\n\n2) **Go to the resource** that triggered the job:\n   - From job detail, check \"Resource\" in JOB DETAILS card\n   - Click to navigate to that resource\n\n3) **Fix the invalid field:**\n   - Example: If \"port 443 already in use\", change port to 8443\n   - Example: If \"timeout must be > 0\", set timeout to \"5s\"\n   - Example: If \"certificate chain required\", configure downstream_tls_context\n\n4) **Save the resource**\n   - This creates a new SNAPSHOT_UPDATE job\n   - Original failed job can be ignored (it's now obsolete)\n\n---\n\n**ERROR CATEGORY 3: CONNECTION / NETWORK ERROR**\n\n**Error Messages:**\n- `\"connection refused: dial tcp 10.0.1.5:19000: connection refused\"`\n- `\"timeout waiting for ACK from client\"`\n- `\"client disconnected during snapshot transfer\"`\n- `\"no route to host\"`\n- `\"i/o timeout\"`\n\n**What It Means:**\n- elchi-client is unreachable\n- Envoy admin interface is down\n- Network partition or firewall blocking xDS port\n- Client crashed during update\n\n**How to Fix:**\n\n1) **Check client status:**\n   - Go to 'Services' page under ADMINISTRATION\n   - Find the service\n   - Look at **Status indicator**:\n     - **Live** (green): All clients connected\n     - **Partial** (yellow): Some clients offline\n     - **Offline** (red): All clients offline\n\n2) **Identify which client failed:**\n   - From SNAPSHOT EXECUTIONS table, note the **Node ID**\n   - Node ID format: `<client-name>~<envoy-node-id>`\n   - Example: `prod-client-1~api-gateway-7f4d9b8c-abcd`\n\n3) **Check client health:**\n   - SSH to client machine: `ssh elchi-client-1`\n   - Check if elchi-client process is running: `ps aux | grep elchi-client`\n   - Check if Envoy is running: `ps aux | grep envoy`\n   - Check network connectivity: `telp elchi-server 18000` (xDS port)\n\n4) **Restart client if needed:**\n   - On Service page, click **\"Restart\"** button for that client\n   - Or SSH to client and restart: `systemctl restart elchi-client`\n\n5) **Retry the job:**\n   - Once client is back online, click **\"Retry Failed Only\"**\n   - Snapshot will be re-sent\n\n---\n\n**ERROR CATEGORY 4: ENVOY REJECTION (NACK)**\n\n**Error Messages:**\n- `\"Envoy rejected configuration (NACK): Proto constraint validation failed\"`\n- `\"Config rejected: duplicate filter name 'http_router'\"`\n- `\"Update rejected: invalid cluster type UNKNOWN\"`\n- `\"NACK: listener validation failed\"`\n\n**What It Means:**\n- Snapshot was sent successfully\n- Envoy received it but **rejected** it (NACK = Negative Acknowledgment)\n- Configuration is syntactically valid but semantically wrong\n- Envoy's internal validation caught an issue\n\n**How to Fix:**\n\n1) **Check Envoy logs:**\n   - SSH to client machine\n   - View Envoy logs: `journalctl -u envoy -f` or `docker logs envoy-container`\n   - Look for detailed error messages around the timestamp of snapshot failure\n\n2) **Common NACK reasons:**\n   - **Duplicate filter name**: HTTP filter chain has two filters with same name\n     - Fix: Rename one of the filters\n   - **Invalid enum value**: Field has unsupported value\n     - Fix: Check Envoy docs for valid values\n   - **Proto constraint**: Field violates protobuf validation rule (e.g., min/max)\n     - Fix: Adjust field value to meet constraint\n\n3) **Fix the resource configuration**\n\n4) **Save and trigger new snapshot**\n\n---\n\n**ERROR CATEGORY 5: INTERNAL SERVER ERROR**\n\n**Error Messages:**\n- `\"Internal server error: panic in snapshot builder\"`\n- `\"Database connection lost\"`\n- `\"Worker crashed unexpectedly\"`\n- `\"Unexpected error: <stack trace>\"`\n\n**What It Means:**\n- Bug in Elchi server code\n- Infrastructure issue (database down, out of memory)\n- Unhandled edge case\n\n**How to Fix:**\n\n1) **Check Elchi server logs:**\n   - `kubectl logs elchi-server-pod` (if running in Kubernetes)\n   - Look for stack traces, panic messages\n\n2) **Report the bug:**\n   - Copy error message and stack trace\n   - Report to Elchi support/development team\n   - Include: Job ID, resource configuration, Envoy version\n\n3) **Workaround (if urgent):**\n   - Try simplifying the configuration\n   - Break into smaller changes\n   - Use different Envoy version\n\n---\n\n**PART 2: HANDLING STUCK JOBS**\n\n**IDENTIFYING STUCK JOBS:**\n\n**Symptoms:**\n- Job status: CLAIMED or RUNNING\n- Progress bar hasn't changed in 5+ minutes\n- \"Last Heartbeat\" in Worker Info card shows \" minutes ago\" or \"hours ago\"\n- Auto-refresh shows no updates\n\n**STEP 1: CHECK WORKER HEARTBEAT**\n\n1) On job detail page, scroll to **WORKER INFO** card (right side)\n2) Check **Last Heartbeat**:\n   - **Normal**: \"a few seconds ago\" or \"30 seconds ago\"\n   - **Problem**: \"5 minutes ago\" or older\n\n**STEP 2: VERIFY WORKER IS DEAD**\n\n1) Note the **Worker ID** (e.g., `worker-abc123`)\n2) Check if worker pod is running:\n   ```\n   kubectl get pods | grep worker-abc123\n   ```\n3) If pod doesn't exist or is in CrashLoopBackOff: Worker died\n\n**STEP 3: CLEAN UP STUCK JOB**\n\n**Method A: From Jobs List Page**\n\n1) Go to Jobs page\n2) Look for **red alert** at top: \"âš  Warning: X stuck/abandoned jobs detected\"\n3) Click **\"Clean Up Stuck Jobs\"** button\n4) Confirmation modal appears\n5) Click **\"Clean Up\"**\n6) All stuck jobs are marked as FAILED\n\n**Method B: Manual Force Restart** (for single job)\n\n1) On job detail page, scroll to **ACTIONS** card\n2) Click red **\"Force Restart\"** button\n3) Confirmation modal:\n   - \"This will completely restart the job from the beginning. Continue?\"\n4) Click **\"OK\"**\n5) Job is reset and re-queued\n\n---\n\n**PART 3: DEBUGGING UPGRADE JOB FAILURES**\n\n**Special Case: RESOURCE_UPGRADE Jobs**\n\n**STEP 1: CHECK UPGRADE ANALYSIS**\n\nScroll to **UPGRADE ANALYSIS** card:\n\n**Red Flags:**\n- **Missing in Target** > 0 and **Auto Create Missing** = No\n  - Fix: Enable auto-create or manually create missing resources\n- **Skipped Resources** list is long\n  - Fix: Review why resources were skipped, resolve issues\n- **Bootstrap Required** = true but **Update Bootstrap** = No\n  - Fix: Enable \"Update Bootstrap\" option\n\n**STEP 2: CHECK CREATED RESOURCES** (if job completed)\n\nIf job completed but something is wrong:\n\n1) Scroll to **CREATED RESOURCES** section\n2) Look for **gray \"Skipped\" tags**\n3) These resources were NOT created (already existed or error)\n4) Check if critical resources are in \"Skipped\" list\n\n**STEP 3: VERIFY DEPENDENCIES**\n\nFor each listener in **Listener Details**:\n\n1) Expand the section\n2) Check **Missing Resources** (orange boxes)\n3) Manually create any that are critical\n4) Retry upgrade\n\n---\n\n**PART 4: BEST PRACTICES FOR AVOIDING FAILURES**\n\n**1. Use Dry Run for Upgrades:**\n- Always enable \"Dry Run\" first\n- Review analysis\n- Fix issues\n- Then run real upgrade\n\n**2. Test in Staging First:**\n- Apply changes to staging environment\n- Verify job succeeds\n- Then apply to production\n\n**3. Monitor Client Health:**\n- Regularly check Service page\n- Ensure all clients are \"Live\"\n- Fix offline clients before making changes\n\n**4. Validate Before Saving:**\n- Double-check field values\n- Ensure referenced resources exist\n- Test with small changes first\n\n**5. Review Dependency Impact:**\n- Before modifying shared resources (secrets, clusters), check how many listeners use them\n- Expect large snapshot jobs for shared resources\n\n**6. Keep Workers Healthy:**\n- Monitor worker pod health\n- Ensure sufficient resources (CPU, memory)\n- Scale workers based on job volume\n\n---\n\n**PART 5: COMMON ERROR QUICK REFERENCE**\n\n| Error Pattern | Likely Cause | Fix |\n|---------------|--------------|-----|\n| \"cluster 'X' not found\" | Missing dependency | Create cluster X |\n| \"connection refused\" | Client offline | Restart client |\n| \"validation failed: port in use\" | Port conflict | Change port number |\n| \"timeout waiting for ACK\" | Slow/dead client | Check client, restart |\n| \"duplicate filter name\" | Filter name collision | Rename filter |\n| \"Proto constraint\" | Invalid field value | Fix value per error msg |\n| \"NACK: ...\" | Envoy rejected config | Check Envoy logs |\n| Stuck in RUNNING | Worker died | Clean up stuck jobs |\n| \"missing in target\" | Upgrade dependency issue | Enable auto-create |"}
