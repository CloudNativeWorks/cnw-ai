<!DOCTYPE html><html lang="en" class="light scroll-smooth" style="color-scheme:light"><script>(function(){try{window.__cfbm=Object.freeze({"score":1,"verified":false,"category":"","bucket":"automated"});window.sessionStorage.setItem('__cfbm', JSON.stringify(window.__cfbm));}catch(e){}})();</script><head><meta charSet="utf-8"/><base href="/"/><meta content="width=device-width, initial-scale=1" name="viewport"/><meta content="telephone=no, address=no, email=no" name="format-detection"/><meta name="apple-mobile-web-app-title" content="ClickHouse"/><link rel="manifest" href="/site.webmanifest"/><link href="/favicon.ico" rel="icon" sizes="48x48" type="image/x-icon"/><link rel="shortcut icon" href="/favicon.ico"/><link rel="icon" type="image/png" href="/favicons/favicon-96x96.png" sizes="96x96"/><link rel="icon" type="image/svg+xml" href="/favicons/favicon.svg"/><link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png"/><title>ClickHouse and PostgreSQL</title><meta name="description" content="Discover why our customers are relying on ClickHouse to power these analytics use cases while freeing Postgres to do what it does best."/><meta name="author" content="ClickHouse"/><meta name="keywords" content=""/><link rel="alternate" type="application/rss+xml" title="ClickHouse Blog" href="https://clickhouse.com/rss.xml"/><meta name="last-modified" content="2024-08-19T10:13:15.469Z"/><link rel="canonical" href="https://clickhouse.com/comparison/postgresql"/><link rel="alternate" hrefLang="x-default" href="https://clickhouse.com/comparison/postgresql"/><meta property="og:title" content="ClickHouse and PostgreSQL"/><meta property="og:description" content="Discover why our customers are relying on ClickHouse to power these analytics use cases while freeing Postgres to do what it does best."/><meta property="og:type" content="website"/><meta property="og:image" content="https://clickhouse.com/_next/image?url=%2Fimages%2Fsocial_share.png&amp;w=1200&amp;h=630&amp;q=80"/><meta property="og:site_name" content="ClickHouse"/><meta property="og:locale" content="en_US"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@ClickHouseDB"/><meta name="twitter:creator" content="@ClickHouseDB"/><meta name="twitter:title" content="ClickHouse and PostgreSQL"/><meta name="twitter:description" content="Discover why our customers are relying on ClickHouse to power these analytics use cases while freeing Postgres to do what it does best."/><meta name="twitter:image" content="https://clickhouse.com/_next/image?url=%2Fimages%2Fsocial_share.png&amp;w=1200&amp;h=630&amp;q=80"/><meta name="twitter:image:alt" content="ClickHouse and PostgreSQL"/><meta name="twitter:domain" content="clickhouse.com"/><link rel="preload" href="/_next/static/media/logo-full.ac8102d5.svg" as="image" fetchpriority="high"/><meta name="next-head-count" content="34"/><link rel="preload" href="/_next/static/media/27388ed889759f5f-s.p.woff" as="font" type="font/woff" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/6e8200c122e80191-s.p.woff" as="font" type="font/woff" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/f500045cc492a7fa-s.p.woff" as="font" type="font/woff" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/379890f8e67beaab.css" as="style"/><link rel="stylesheet" href="/_next/static/css/379890f8e67beaab.css" data-n-g=""/><link rel="preload" href="/_next/static/css/2263c7c0ca01726b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/2263c7c0ca01726b.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-27e193401f0c2128.js" defer=""></script><script src="/_next/static/chunks/framework-7b9e6922c3bd411b.js" defer=""></script><script src="/_next/static/chunks/main-54819e0f1121d8ba.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bc5f72f18d1850db.js" defer=""></script><script src="/_next/static/chunks/fec483df-91a51f18f1588b11.js" defer=""></script><script src="/_next/static/chunks/8857-7a0657f182e63777.js" defer=""></script><script src="/_next/static/chunks/7072-8d215ed022b3f422.js" defer=""></script><script src="/_next/static/chunks/5476-f00ed308de867cd1.js" defer=""></script><script src="/_next/static/chunks/pages/comparison/postgresql-8a4a6042135ffbea.js" defer=""></script><script src="/_next/static/zmUZJ4yILYdetQg3c5Mna/_buildManifest.js" defer=""></script><script src="/_next/static/zmUZJ4yILYdetQg3c5Mna/_ssgManifest.js" defer=""></script></head><body class="antialiased"><div id="__next"><div id="main-site-container" class="__variable_d1b8ee font-inter __variable_a25f62 __variable_a58b65"><div class="flex min-h-screen flex-col"><div style="height:calc(var(--header-height, 72px) + 1px)"></div><header class="bg-neutral-900/10 md-mid:bg-neutral-900/10 fixed top-0 z-50 w-full border-b border-white/5 backdrop-blur transition-colors"><div class="no-wrap section-container relative flex items-center py-4"><div class="relative mr-auto"><a href="/"><img alt="ClickHouse logo" fetchpriority="high" width="135" height="40" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/logo-full.ac8102d5.svg"/></a><div class="absolute left-0 top-full z-50 w-56 origin-top-left pt-2 transition-all pointer-events-none scale-95 opacity-0"><div class="rounded-lg border border-white/10 bg-neutral-750 p-1.5 shadow-lg"><button class="flex w-full rounded-lg px-3 py-2.5 text-left text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300">Copy logo as SVG</button><a href="/brand-assets/clickhouse-logo.zip" download="clickhouse-logo.zip" class="flex w-full rounded-lg px-3 py-2.5 text-left text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300">Download full logo</a><a href="/brand-assets/clickhouse-logomark.zip" download="clickhouse-logomark.zip" class="flex w-full rounded-lg px-3 py-2.5 text-left text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300">Download logomark</a></div></div></div><button type="button" class="md-mid:hidden"><span class="sr-only">Open search</span><span class="flex aspect-square w-10 items-center justify-center rounded-lg transition-colors hover:bg-white/5 hover:text-primary-300"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true" class="h-4 w-4"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></span></button><div class="relative z-10 mx-4 md-mid:hidden"><button class="flex items-center gap-2 "><span class="sr-only">Open region selector</span><svg xmlns="http://www.w3.org/2000/svg" width="15" height="15" fill="none" viewBox="0 0 15 15" class="flex-shrink-0 flex-grow-0"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M13.75 7.5c0 3.45-2.8 6.25-6.25 6.25m6.25-6.25c0-3.45-2.8-6.25-6.25-6.25m6.25 6.25H1.25m6.25 6.25A6.25 6.25 0 0 1 1.25 7.5m6.25 6.25A9.56 9.56 0 0 0 10 7.5a9.56 9.56 0 0 0-2.5-6.25m0 12.5A9.56 9.56 0 0 1 5 7.5a9.56 9.56 0 0 1 2.5-6.25M1.25 7.5c0-3.45 2.8-6.25 6.25-6.25"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="6" height="10" fill="none" viewBox="0 0 6 10" class="flex w-2.5 flex-shrink-0 flex-grow-0 origin-center rotate-90 items-center justify-center transition-all opacity-50"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m1 9 4-4-4-4"></path></svg></button><div class="absolute right-0 top-full origin-top-right pt-4 transition pointer-events-none scale-90 opacity-0"><ul class="relative min-w-44 rounded-lg bg-neutral-750 p-4 text-sm text-white shadow transition-all"><li><a href="/?country=en" class="block w-full rounded-lg px-2 py-2.5 transition-colors hover:bg-neutral-700/25 hover:text-primary-300">English</a></li><li><a href="/jp?country=jp" class="block w-full rounded-lg px-2 py-2.5 transition-colors hover:bg-neutral-700/25 hover:text-primary-300">Japanese</a></li></ul></div></div><button class="inline-flex items-center justify-center rounded-md bg-slate p-2 text-neutral-200 hover:text-neutral-0 focus:outline-none md-mid:hidden"><span class="sr-only">Open menu</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="h-4 w-4"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div style="top:var(--header-height, 72px);height:calc(100dvh - var(--header-height, 72px))" class="pointer-events-none opacity-0 fixed inset-0 flex h-dvh flex-1 flex-col overflow-y-auto bg-neutral-900 p-4 transition-opacity md-mid:pointer-events-auto md-mid:relative md-mid:!top-0 md-mid:ml-0 md-mid:!h-auto md-mid:flex-row md-mid:items-center md-mid:overflow-y-visible md-mid:bg-transparent md-mid:p-0 md-mid:opacity-100 lg:ml-8 xl:ml-20"><nav class="w-full md-mid:w-auto md-mid:flex-shrink-0"><div class="relative"><ul class="grid grid-cols-1 md-mid:flex md-mid:flex-row"><li><div class="relative "><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/navItem items-center md-mid:!px-4  md-mid:pointer-events-none  undefined " href="/comparison/postgresql"><span class="flex-1">Products</span><span class="md-mid:ml-2"><svg xmlns="http://www.w3.org/2000/svg" width="6" height="10" fill="none" viewBox="0 0 6 10" class="flex w-2.5 flex-shrink-0 flex-grow-0 origin-center items-center justify-center transition-all    md-mid:hidden text-neutral-500"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m1 9 4-4-4-4"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="6" height="10" fill="none" viewBox="0 0 6 10" class="flex w-2.5 flex-shrink-0 flex-grow-0 origin-center items-center justify-center transition-all rotate-90   hidden md-mid:block text-neutral-500 group-hover/navItem:text-white"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m1 9 4-4-4-4"></path></svg></span></a><div class="md-mid:absolute md-mid:-left-12 md-mid:top-full md-mid:-z-50 md-mid:block md-mid:w-max md-mid:min-w-60 md-mid:whitespace-nowrap md-mid:pt-6 pointer-events-none hidden"><div class="origin-[top_center] transition-all md-mid:rounded-lg md-mid:bg-neutral-750 md-mid:shadow md-mid:scale-90 md-mid:opacity-0"><div class="grid grid-cols-1 md-mid:grid-cols-2"><div class="flex flex-col"><div class="px-4 md-mid:grid-cols-5 md-mid:grid-rows-1 md-mid:gap-x-4 md-mid:py-2"><p class="col-span-full px-2 py-2 text-sm"><strong>Products</strong></p><ul class="col-span-2"><li class="flex items-center"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/nav-with-icon !flex w-full !flex-nowrap items-center gap-3 " href="/cloud"><img alt="ClickHouse Cloud" loading="lazy" width="24" height="24" decoding="async" data-nimg="1" class="flex-grow-1 size-6 flex-shrink-0 object-scale-down" style="color:transparent" src="/images/nav/icon-clickhouse-cloud.svg"/><span>ClickHouse Cloud<div class="text-xs text-slate-300 transition-colors group-hover/nav-with-icon:text-white">The best way to use ClickHouse.<br/>Available on AWS, GCP, and Azure.</div></span></a></li><li class="flex items-center"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/nav-with-icon !flex w-full !flex-nowrap items-center gap-3 " href="/cloud/bring-your-own-cloud"><img alt="ClickHouse BYOC" loading="lazy" width="24" height="24" decoding="async" data-nimg="1" class="flex-grow-1 size-6 flex-shrink-0 object-scale-down" style="color:transparent" src="/images/nav/icon-byoc.svg"/><span>Bring Your Own Cloud<div class="text-xs text-slate-300 transition-colors group-hover/nav-with-icon:text-white">A fully managed ClickHouse service,<br/> deployed in your own AWS and GCP account.</div></span></a></li><li class="flex items-center"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/nav-with-icon !flex w-full !flex-nowrap items-center gap-3 " href="/cloud/postgres"><img alt="Postgres ClickHouse Cloud" loading="lazy" width="24" height="24" decoding="async" data-nimg="1" class="flex-grow-1 size-6 flex-shrink-0 object-scale-down" style="color:transparent" src="/images/nav/icon-postgres.svg"/><span>Postgres managed by ClickHouse<div class="text-xs text-slate-300 transition-colors group-hover/nav-with-icon:text-white">Unified data stack for transactions<br/> and analytics.</div></span></a></li><li class="flex items-center"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/nav-with-icon !flex w-full !flex-nowrap items-center gap-3 " href="/cloud/clickstack"><img alt="Managed ClickStack" loading="lazy" width="24" height="24" decoding="async" data-nimg="1" class="flex-grow-1 size-6 flex-shrink-0 object-scale-down" style="color:transparent" src="/images/nav/icon-managed-clickstack.svg"/><span>Managed ClickStack<div class="text-xs text-slate-300 transition-colors group-hover/nav-with-icon:text-white">Managed observability with high-performance<br/> queries and long-term retention.</div></span></a></li></ul></div></div><div class="flex flex-col border-t border-neutral-700 md-mid:border-l md-mid:border-t-0"><div class="px-4 md-mid:grid-cols-5 md-mid:grid-rows-1 md-mid:gap-x-4 md-mid:py-2"><p class="col-span-full px-2 py-2 text-sm"><strong>Open source</strong></p><ul class="col-span-2"><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/nav-with-icon !flex w-full !flex-nowrap items-center gap-3 " href="/clickhouse"><img alt="ClickHouse" loading="lazy" width="24" height="24" decoding="async" data-nimg="1" class="flex-grow-1 size-6 flex-shrink-0 object-scale-down" style="color:transparent" src="/images/nav/icon-clickhouse.svg"/><span>ClickHouse<div class="text-xs text-slate-300 transition-colors group-hover/nav-with-icon:text-white">Fast open-source OLAP database for <br/>real-time analytics.</div></span></a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/nav-with-icon !flex w-full !flex-nowrap items-center gap-3 " href="/clickstack"><img alt="ClickStack" loading="lazy" width="24" height="24" decoding="async" data-nimg="1" class="flex-grow-1 size-5 flex-shrink-0 object-scale-down" style="color:transparent" src="/images/nav/icon-clickstack.svg"/><span>ClickStack<div class="text-xs text-slate-300 transition-colors group-hover/nav-with-icon:text-white">Open-source observability stack for logs,<br/>metrics, traces, and session replays.</div></span></a></li><li class="flex items-center"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/nav-with-icon !flex w-full !flex-nowrap items-center gap-3 " href="/ai"><img alt="Agentic Data Stack" loading="lazy" width="24" height="24" decoding="async" data-nimg="1" class="flex-grow-1 size-6 flex-shrink-0 object-scale-down" style="color:transparent" src="/images/nav/icon-agentic-data-stack.svg"/><span>Agentic Data Stack<div class="text-xs text-slate-300 transition-colors group-hover/nav-with-icon:text-white">Build AI-powered applications <br/>with ClickHouse.</div></span></a></li></ul></div></div></div></div></div></div></li><li><div class="relative "><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/navItem items-center md-mid:!px-4  md-mid:pointer-events-none  undefined " href="/comparison/postgresql"><span class="flex-1">Solutions</span><span class="md-mid:ml-2"><svg xmlns="http://www.w3.org/2000/svg" width="6" height="10" fill="none" viewBox="0 0 6 10" class="flex w-2.5 flex-shrink-0 flex-grow-0 origin-center items-center justify-center transition-all    md-mid:hidden text-neutral-500"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m1 9 4-4-4-4"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="6" height="10" fill="none" viewBox="0 0 6 10" class="flex w-2.5 flex-shrink-0 flex-grow-0 origin-center items-center justify-center transition-all rotate-90   hidden md-mid:block text-neutral-500 group-hover/navItem:text-white"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m1 9 4-4-4-4"></path></svg></span></a><div class="md-mid:absolute md-mid:-left-12 md-mid:top-full md-mid:-z-50 md-mid:block md-mid:w-max md-mid:min-w-60 md-mid:whitespace-nowrap md-mid:pt-6 pointer-events-none hidden"><div class="origin-[top_center] transition-all md-mid:rounded-lg md-mid:bg-neutral-750 md-mid:shadow md-mid:scale-90 md-mid:opacity-0"><div class="grid grid-cols-1 md-mid:grid-cols-2"><div class="flex flex-col"><div class="px-4 md-mid:grid-cols-5 md-mid:grid-rows-1 md-mid:gap-x-4 md-mid:py-2"><p class="col-span-full px-2 py-2 text-sm"><strong>Use cases</strong></p><ul class="col-span-2"><li class="col-span-2"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/use-cases/real-time-analytics">Real-time analytics</a></li><li class="col-span-2"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/cloud/clickstack">Observability</a></li><li class="col-span-2"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/use-cases/data-warehousing">Data warehousing</a></li><li class="col-span-2"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/use-cases/machine-learning-and-data-science">Machine learning and GenAI</a></li><li class="col-span-2 md-mid:hidden"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/use-cases">All use cases</a></li></ul></div><a class="group/linkWithArrow mt-auto hidden w-full rounded-b-lg border-t border-neutral-700 px-6 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:block" href="/use-cases">All use cases<!-- --> <span class="relative whitespace-nowrap"><span class="opacity-0">-&gt;</span><span class="absolute left-0 top-1/2 block -translate-y-1/2 transition-all group-hover/linkWithArrow:indent-1 ">-&gt;</span></span></a></div><div class="flex flex-col border-t border-neutral-700 md-mid:border-l md-mid:border-t-0"><div class="px-4 md-mid:grid-cols-5 md-mid:grid-rows-1 md-mid:gap-x-4 md-mid:py-2"><p class="col-span-full px-2 py-2 text-sm"><strong>Industries</strong></p><ul class="col-span-2"><li class="col-span-2"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/industries/cybersecurity">Cybersecurity</a></li><li class="col-span-2"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/industries/gaming">Gaming and entertainment</a></li><li class="col-span-2"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/industries/retail">E-commerce and retail</a></li><li class="col-span-2"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/industries/automotive">Automotive</a></li><li class="col-span-2"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/industries/energy">Energy</a></li><li class="col-span-2 md-mid:hidden"><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/industries">All industries</a></li></ul></div><a class="group/linkWithArrow mt-auto hidden w-full rounded-b-lg border-t border-neutral-700 px-6 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:block" href="/industries">All industries<!-- --> <span class="relative whitespace-nowrap"><span class="opacity-0">-&gt;</span><span class="absolute left-0 top-1/2 block -translate-y-1/2 transition-all group-hover/linkWithArrow:indent-1 ">-&gt;</span></span></a></div></div></div></div></div></li><li><div class="relative "><a target="_blank" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/navItem items-center md-mid:!px-4    undefined " href="https://clickhouse.com/docs"><span class="flex-1">Docs</span></a></div></li><li><div class="relative "><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/navItem items-center md-mid:!px-4  md-mid:pointer-events-none  undefined " href="/comparison/postgresql"><span class="flex-1">Resources</span><span class="md-mid:ml-2"><svg xmlns="http://www.w3.org/2000/svg" width="6" height="10" fill="none" viewBox="0 0 6 10" class="flex w-2.5 flex-shrink-0 flex-grow-0 origin-center items-center justify-center transition-all    md-mid:hidden text-neutral-500"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m1 9 4-4-4-4"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="6" height="10" fill="none" viewBox="0 0 6 10" class="flex w-2.5 flex-shrink-0 flex-grow-0 origin-center items-center justify-center transition-all rotate-90   hidden md-mid:block text-neutral-500 group-hover/navItem:text-white"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m1 9 4-4-4-4"></path></svg></span></a><div class="md-mid:absolute md-mid:-left-12 md-mid:top-full md-mid:-z-50 md-mid:block md-mid:w-max md-mid:min-w-60 md-mid:whitespace-nowrap md-mid:pt-6 pointer-events-none hidden"><div class="origin-[top_center] transition-all md-mid:rounded-lg md-mid:bg-neutral-750 md-mid:shadow md-mid:scale-90 md-mid:opacity-0"><ul class="relative px-4 md-mid:py-2"><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/user-stories">User stories</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/blog">Blog</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/company/events">Events</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/company/news">News</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/learn">Learning and certification</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex w-full items-center justify-between  " href="/comparison/postgresql#"><span>Comparisons</span><svg xmlns="http://www.w3.org/2000/svg" width="6" height="10" fill="none" viewBox="0 0 6 10" class="flex w-2.5 flex-shrink-0 flex-grow-0 origin-center items-center justify-center transition-all    text-neutral-500"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m1 9 4-4-4-4"></path></svg></a><ul class="h-auto w-full px-4 text-white transition-all md-mid:absolute md-mid:left-full md-mid:top-0 md-mid:-ml-4 md-mid:min-h-full md-mid:w-auto md-mid:min-w-full md-mid:rounded-lg md-mid:bg-neutral-750 md-mid:py-2 pointer-events-none hidden md-mid:opacity-0"><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/benchmarks">Benchmark hub</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/comparison/bigquery">BigQuery</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/comparison/postgresql">PostgreSQL</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/comparison/redshift">Redshift</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/comparison/snowflake">Snowflake</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/comparison/elastic-for-observability">Elastic Observability</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/comparison/splunk-for-observability">Splunk</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full md-mid:min-w-max md-mid:whitespace-nowrap " href="/comparison/opensearch-for-observability">OpenSearch<!-- --> <small class="ml-2 inline-block rounded-sm bg-white/10 px-2 text-neutral-200">For observability</small></a></li></ul></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/videos">Videos</a></li><li><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex block w-full " href="/demos">Demos</a></li></ul></div></div></div></li><li><div class="relative "><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/navItem items-center md-mid:!px-4    undefined " href="/pricing"><span class="flex-1">Pricing</span></a></div></li><li><div class="relative "><a target="_self" class="flex flex-wrap rounded-lg px-2 py-2.5 text-sm font-medium transition-colors hover:bg-neutral-700/25 hover:text-primary-300 md-mid:inline-flex group/navItem items-center md-mid:!px-4    undefined " href="/company/contact?loc=nav"><span class="flex-1">Contact us</span></a></div></li></ul></div></nav><div class="mt-auto flex flex-col-reverse flex-nowrap items-center gap-4 md-mid:ml-auto md-mid:mt-0 md-mid:flex-row lg:gap-6"><button type="button"><span class="sr-only">Open search</span><span class="flex aspect-square w-10 items-center justify-center rounded-lg transition-colors hover:bg-white/5 hover:text-primary-300"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true" class="h-4 w-4"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></span></button><div class="relative hidden md-mid:block"><button class="flex items-center gap-2 "><span class="sr-only">Open region selector</span><svg xmlns="http://www.w3.org/2000/svg" width="15" height="15" fill="none" viewBox="0 0 15 15" class="flex-shrink-0 flex-grow-0"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M13.75 7.5c0 3.45-2.8 6.25-6.25 6.25m6.25-6.25c0-3.45-2.8-6.25-6.25-6.25m6.25 6.25H1.25m6.25 6.25A6.25 6.25 0 0 1 1.25 7.5m6.25 6.25A9.56 9.56 0 0 0 10 7.5a9.56 9.56 0 0 0-2.5-6.25m0 12.5A9.56 9.56 0 0 1 5 7.5a9.56 9.56 0 0 1 2.5-6.25M1.25 7.5c0-3.45 2.8-6.25 6.25-6.25"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="6" height="10" fill="none" viewBox="0 0 6 10" class="flex w-2.5 flex-shrink-0 flex-grow-0 origin-center rotate-90 items-center justify-center transition-all opacity-50"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m1 9 4-4-4-4"></path></svg></button><div class="absolute right-0 top-full origin-top-right pt-4 transition pointer-events-none scale-90 opacity-0"><ul class="relative min-w-44 rounded-lg bg-neutral-750 p-4 text-sm text-white shadow transition-all"><li><a href="/?country=en" class="block w-full rounded-lg px-2 py-2.5 transition-colors hover:bg-neutral-700/25 hover:text-primary-300">English</a></li><li><a href="/jp?country=jp" class="block w-full rounded-lg px-2 py-2.5 transition-colors hover:bg-neutral-700/25 hover:text-primary-300">Japanese</a></li></ul></div></div><a class=" hidden items-center gap-2 text-sm font-medium hover:text-primary-300 lg-mid:flex" target="_blank" href="https://github.com/ClickHouse/ClickHouse?utm_source=clickhouse&amp;utm_medium=website&amp;utm_campaign=website-nav"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 1.75C4.27062 1.75 1.25 4.77062 1.25 8.5C1.25 11.4869 3.18219 14.0097 5.86531 14.9041C6.20281 14.9631 6.32937 14.7606 6.32937 14.5834C6.32937 14.4231 6.32094 13.8916 6.32094 13.3263C4.625 13.6384 4.18625 12.9128 4.05125 12.5331C3.97531 12.3391 3.64625 11.74 3.35938 11.5797C3.12312 11.4531 2.78562 11.1409 3.35094 11.1325C3.8825 11.1241 4.26219 11.6219 4.38875 11.8244C4.99625 12.8453 5.96656 12.5584 6.35469 12.3813C6.41375 11.9425 6.59094 11.6472 6.785 11.4784C5.28312 11.3097 3.71375 10.7275 3.71375 8.14563C3.71375 7.41156 3.97531 6.80406 4.40563 6.33156C4.33812 6.16281 4.10187 5.47094 4.47312 4.54281C4.47312 4.54281 5.03844 4.36563 6.32937 5.23469C6.86937 5.08281 7.44313 5.00687 8.01688 5.00687C8.59063 5.00687 9.16438 5.08281 9.70438 5.23469C10.9953 4.35719 11.5606 4.54281 11.5606 4.54281C11.9319 5.47094 11.6956 6.16281 11.6281 6.33156C12.0584 6.80406 12.32 7.40312 12.32 8.14563C12.32 10.7359 10.7422 11.3097 9.24031 11.4784C9.485 11.6894 9.69594 12.0944 9.69594 12.7272C9.69594 13.63 9.6875 14.3556 9.6875 14.5834C9.6875 14.7606 9.81406 14.9716 10.1516 14.9041C12.8178 14.0097 14.75 11.4784 14.75 8.5C14.75 4.77062 11.7294 1.75 8 1.75Z" fill="currentColor"></path></svg>46.0k</a><a class=" w-full rounded border border-neutral-500 py-3 text-center text-sm font-medium leading-none hover:text-primary-300 md-mid:hidden md-mid:w-auto md-mid:border-0 md-mid:py-0 lg-mid:inline-block" href="https://console.clickhouse.cloud/signIn">Sign in</a><a class=" w-full md-mid:w-auto" href="https://console.clickhouse.cloud/signUp?loc=nav-get-started"><button class="styles_button__3smpn w-full md-mid:w-auto  font-medium" data-type="primary"><span class="flex items-center whitespace-nowrap"><span id="nav-bar-cta-button">Get started</span></span></button></a></div></div></div></header><main class="readable-content"><div class="homepage bg-grid"><div class="relative pt-16 lg:pb-6"><div class="mx-auto max-w-7xl px-4 md:px-8 2xl:px-0"><div class="w-full items-start gap-10 lg:grid lg:grid-cols-8 lg:gap-20"><div class="lg:col-span-5"><div class="mb-8 items-center md:flex md:justify-between md:gap-x-10"><div><h1 class="mb-6 text-center font-basier text-4xl font-semibold leading-tight text-neutral-0 md:mb-0 md:text-left md:text-5.5xl">ClickHouse and PostgreSQL</h1></div><div><img alt="" loading="eager" width="156" height="153" decoding="async" data-nimg="1" class="mx-auto lg:mx-0" style="color:transparent" src="/uploads/ch_postgres_0406bb34cf.png"/></div></div><div class="rich_content mb-12 mt-4 text-center text-base text-neutral-0 md:text-left"><div class="rich_content text-lg"><p>Are your analytical queries in Postgres hitting performance limitations, scalability challenges, or becoming operationally complex? Discover why our customers are relying on ClickHouse to power these analytics use cases while freeing Postgres to do what it does best.</p></div></div><div class="mb-12 h-full"><div class="cui-card flex flex-col items-stretch gap-y-5 rounded-lg border border-neutral-700/80 bg-neutral-900/50 p-3 shadow-card hover:shadow-lg lg:flex-row lg:divide-x lg:divide-neutral-700/80"><div class="flex-1 p-3 text-center"><p class="mb-2 text-5xl">1000x</p><p class="text-md text-primary-300">Faster queries</p></div><div class="flex-1 p-3 text-center"><p class="mb-2 text-5xl">-50%</p><p class="text-md text-primary-300">Disk space</p></div><div class="flex-1 p-3 text-center"><p class="mb-2 text-5xl">5x</p><p class="text-md text-primary-300">Cost savings</p></div></div></div></div><div class="lg:col-span-3"><div class="mb-12 lg:mb-0"><div class="lg:max-w-lg"><h3 class="mb-6 text-center font-basier text-xl font-light text-neutral-0">Contact us for help with your migration</h3><div class="text-center">Loading form...</div></div></div></div></div></div></div></div><section class="mb-16 bg-primary-300 py-10 text-neutral-900 lg:mb-24"><div class="section-container flex flex-col gap-x-4 gap-y-6 md:flex-row md:items-center md:justify-between"><div class="space-y-4 md:max-w-xl"><h2 class="text-inherit undefined Typography_suiTitleh2__deFQc  undefined">Postgres managed by ClickHouse</h2><p>A native Postgres service integrated with ClickHouse. Build on a Unified Data Stack with Postgres for transactions and ClickHouse for analytics.</p></div><a class=" " href="/cloud/postgres"><button class="styles_button__3smpn group mx-auto w-full !px-10 md:w-auto font-medium" data-type="primary-dark" data-size="lg"><span class="flex items-center whitespace-nowrap">Find out more</span></button></a></div></section><div class="mx-auto mt-6 max-w-7xl px-4 md:px-8 2xl:px-0"><div class="section-container bg-shadow-element yellow-shadow align-shadow-right container mx-auto flex flex-col items-center"><img alt="" loading="lazy" width="73" height="72" decoding="async" data-nimg="1" class="mb-4 fill-none" style="color:transparent" src="/uploads/people_icon_b6c8c61d7c.svg"/><h2 class="text-center font-basier text-3xl font-semibold">Why do developers choose ClickHouse?</h2><div class="mt-10 lg:mt-20"><div class="grid grid-cols-1 gap-8"><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg p-6"><div class="cui-card-body w-full flex flex-col items-start justify-center gap-2"><div class="flex flex-col items-start gap-10 lg:flex-row"><div class="w-full lg:w-2/3"><h3 class="mb-4 flex-grow text-center font-basier text-3xl font-semibold leading-tight text-neutral-100 lg:text-left">PostgreSQL performance limitations</h3><div class="rich_content text-neutral-0"><div class="rich_content "><p>Developers report challenges with query run time and inflated disk sizes as big drains on the performance of their analytical queries running on Postgres.</p>
<p><strong>ClickHouse is the fastest and most resource-efficient database for analytics.</strong><br/>
Whether you’re aggregating large volumes of data in real-time, interactively slicing and dicing on the fly, or powering customer-facing applications, ClickHouse is blazingly fast, overcoming the performance limitations often seen with Postgres.</p>
<p>OONI, for example, were able to reduce their analytical query times from 20 minutes in PostgreSQL to milliseconds in ClickHouse while halving their storage requirements.</p></div></div></div><div class="h-full w-full lg:w-1/3"><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg p-6"><div class="cui-card-body w-full flex flex-col items-start justify-center gap-2"><div class="rich_content text-neutral-0"><img alt="Quote" loading="lazy" width="37" height="28" decoding="async" data-nimg="1" class="mb-4" style="color:transparent" src="/images/Quote.svg"/> <p>&quot;Having all the data in ClickHouse means we can quickly answer questions without having to wait hours for queries to converge, significantly improving our internal data analysis tasks.&quot;</p>
<p><a href="/blog/ooni-analyzes-internet-censorship-data-with-clickhouse">Read more</a></p><img alt="" loading="lazy" width="154" height="44" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/ooni_logo_d709527b16.svg"/></div></div></div></div></div></div></div></div></div><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg p-6"><div class="cui-card-body w-full flex flex-col items-start justify-center gap-2"><div class="flex flex-col items-start gap-10 lg:flex-row"><div class="w-full lg:w-2/3"><h3 class="mb-4 flex-grow text-center font-basier text-3xl font-semibold leading-tight text-neutral-100 lg:text-left">PostgreSQL scalability challenges</h3><div class="rich_content text-neutral-0"><div class="rich_content "><p>Scalability is an important consideration for any database system, including PostgreSQL. While PostgreSQL is known for its robustness and performance, it does face scalability challenges.</p>
<p><strong>ClickHouse is designed to efficiently manage huge volumes of data.</strong> <br/>
ClickHouse scales both vertically and horizontally, ensuring the effective utilization of available resources. ClickHouse is relied on at scale by companies all over the world to process and store hundreds of petabytes of compressed data.</p>
<p>Cloudflare’s old data pipeline conceived in 2014, centered around scaling out Postgres for their analytics. “The pipeline had served us and our customers well over the years, but began to split at the seams.” They needed to find a scalable solution built for tomorrow.</p></div></div></div><div class="h-full w-full lg:w-1/3"><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg p-6"><div class="cui-card-body w-full flex flex-col items-start justify-center gap-2"><div class="rich_content text-neutral-0"><img alt="Quote" loading="lazy" width="37" height="28" decoding="async" data-nimg="1" class="mb-4" style="color:transparent" src="/images/Quote.svg"/> <p>“It is [ClickHouse] blazing fast, linearly scalable, hardware efficient, fault tolerant, feature rich, highly reliable, simple and handy.”</p>
<p><a href="https://blog.cloudflare.com/http-analytics-for-6m-requests-per-second-using-clickhouse">Read more</a></p><img alt="" loading="lazy" width="103" height="35" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Cloudflare_Logo_1_1_9ea1e1bc38.png"/></div></div></div></div></div></div></div></div></div><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg p-6"><div class="cui-card-body w-full flex flex-col items-start justify-center gap-2"><div class="flex flex-col items-start gap-10 lg:flex-row"><div class="w-full lg:w-2/3"><h3 class="mb-4 flex-grow text-center font-basier text-3xl font-semibold leading-tight text-neutral-100 lg:text-left">PostgreSQL operational complexity</h3><div class="rich_content text-neutral-0"><div class="rich_content "><p>Optimizing query execution plans, indexing strategies, and database configuration parameters requires expertise and ongoing monitoring to address performance bottlenecks.</p>
<p><strong>ClickHouse is purpose-built for real-time, large-volume, data analytics.</strong><br/>
With ClickHouse, there is no need for the operational complexity that exists when retrofitting another system for these real-time workloads. With ClickHouse, real-time just works.</p>
<p>MUX’s old Postgres-based pipelines required manual oversight. “If too many jobs that landed on the same Postgres shard happened to run at the same time, the cluster could grind to a halt. This required manually stopping all of the other jobs and babysitting them one-at-a-time until they all completed.” ClickHouse solved these issues and more.</p></div></div></div><div class="h-full w-full lg:w-1/3"><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg p-6"><div class="cui-card-body w-full flex flex-col items-start justify-center gap-2"><div class="rich_content text-neutral-0"><img alt="Quote" loading="lazy" width="37" height="28" decoding="async" data-nimg="1" class="mb-4" style="color:transparent" src="/images/Quote.svg"/> <p>“With all of this in mind, we started by keeping the [ClickHouse] architecture as simple as possible: just dump all of the data into one table called ‘views’. No Airflow. No aggregation. No stored procedures. Any bucketing logic would be written in the SQL queries at read-time and computed on the fly. To our surprise, this worked extremely well.”</p>
<p><a href="https://www.mux.com/blog/from-russia-with-love-how-clickhouse-saved-our-data">Read more</a></p><img alt="" loading="lazy" width="120" height="38" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Mux_Logo_Small_White_1_a9508596c4.svg"/></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="mx-auto w-full max-w-screen-md border-t border-neutral-725 px-7 my-16 lg:my-24"></div><div class="mx-auto max-w-7xl px-4 md:px-8 2xl:px-0"><div class="section-container bg-shadow-element red-shadow align-shadow-left container mx-auto flex flex-col items-center"><img alt="" loading="lazy" width="73" height="72" decoding="async" data-nimg="1" class="mb-4 fill-none" style="color:transparent" src="/uploads/devsays_icon_5e43a8f909.svg"/><h2 class="text-center font-basier text-3xl font-semibold">What developers say about ClickHouse and PostgreSQL</h2></div><div class="mt-10 gap-3 md:columns-2 lg:mt-20 lg:columns-3"><div class="mb-3 w-full break-inside-avoid rounded-lg border border-neutral-700/80 bg-neutral-900/50 object-cover p-6 shadow-card hover:bg-neutral-750"><a href="/blog/helicones-migration-from-postgres-to-clickhouse-for-advanced-llm-monitoring"><div class="flex h-full w-full flex-col justify-between space-y-12"><div class="text-left"><img alt="" loading="lazy" width="120" height="25" decoding="async" data-nimg="1" class="color-swap-no-hover mb-4 h-16 fill-none" style="color:transparent" src="/uploads/helicone_logo_1f0bfd432c.svg"/><div class="space-y-4 text-neutral-0"><p>“We were using Postgres and Postgres just wasn&#x27;t scaling for those nice dashboards. In order to get these nice dashboards, you need to do all these aggregation calls. Aggregations were taking more than 30 seconds and things were just timing out.”</p></div></div></div></a></div><div class="mb-3 w-full break-inside-avoid rounded-lg border border-neutral-700/80 bg-neutral-900/50 object-cover p-6 shadow-card hover:bg-neutral-750"><a href="/blog/how-quickcheck-uses-clickhouse-to-bring-banking-to-the-unbanked"><div class="flex h-full w-full flex-col justify-between space-y-12"><div class="text-left"><img alt="" loading="lazy" width="173" height="56" decoding="async" data-nimg="1" class="color-swap-no-hover mb-4 h-16 fill-none" style="color:transparent" src="/uploads/logo_quickcheck_daeb6bafaa.svg"/><div class="space-y-4 text-neutral-0"><p>“We realized we had so much data in Postgres, which was taking forever to process, so we started moving it to ClickHouse. It is instant in ClickHouse vs forever in Postgres.”</p></div></div></div></a></div><div class="mb-3 w-full break-inside-avoid rounded-lg border border-neutral-700/80 bg-neutral-900/50 object-cover p-6 shadow-card hover:bg-neutral-750"><a href="https://posthog.com/blog/clickhouse-vs-postgres"><div class="flex h-full w-full flex-col justify-between space-y-12"><div class="text-left"><img alt="" loading="lazy" width="157" height="30" decoding="async" data-nimg="1" class="color-swap-no-hover mb-4 h-16 fill-none" style="color:transparent" src="/uploads/posthog_clipped_9275fb0f26.svg"/><div class="space-y-4 text-neutral-0"><p>“Eventually, [our] all-purpose Postgres database was tasked to store millions of rows of data. It was obvious Postgres couldn&#x27;t handle the scale necessary for an analytics platform like PostHog. At first, the team tried a ton of hack-y and wacky solutions in attempts to get Postgres to work. Turns out, that wasn’t sustainable (who would’ve thought!). Eventually, PostHog migrated client data to ClickHouse. Boom!”</p></div></div></div></a></div><div class="mb-3 w-full break-inside-avoid rounded-lg border border-neutral-700/80 bg-neutral-900/50 object-cover p-6 shadow-card hover:bg-neutral-750"><a href="/blog/plausible-analytics-uses-click-house-to-power-their-privacy-friendly-google-analytics-alternative"><div class="flex h-full w-full flex-col justify-between space-y-12"><div class="text-left"><img alt="" loading="lazy" width="123" height="57" decoding="async" data-nimg="1" class="color-swap-no-hover mb-4 h-16 fill-none" style="color:transparent" src="/uploads/logo_plausible_9bede01d72.svg"/><div class="space-y-4 text-neutral-0"><p>“It became clear early on that the original architecture using Postgres to store analytics data could not handle the platform’s future growth.”</p></div></div></div></a></div><div class="mb-3 w-full break-inside-avoid rounded-lg border border-neutral-700/80 bg-neutral-900/50 object-cover p-6 shadow-card hover:bg-neutral-750"><a href="/blog/hifis-migration-from-bigquery-to-clickhouse"><div class="flex h-full w-full flex-col justify-between space-y-12"><div class="text-left"><img alt="" loading="lazy" width="75" height="56" decoding="async" data-nimg="1" class="color-swap-no-hover mb-4 h-16 fill-none" style="color:transparent" src="/uploads/logo_hifi_c9f874cec8.svg"/><div class="space-y-4 text-neutral-0"><p>“We still use PG [Postgres] for non-royalty data such as customer account data and metadata. Fortunately, ClickHouse makes it relatively easy to connect to PG databases.”</p></div></div></div></a></div><div class="mb-3 w-full break-inside-avoid rounded-lg border border-neutral-700/80 bg-neutral-900/50 object-cover p-6 shadow-card hover:bg-neutral-750"><a href="/blog/trillabit-utilizes-the-power-of-clickhouse-for-fast-scalable-results-within-their-self-service-search-driven-analytics-offering"><div class="flex h-full w-full flex-col justify-between space-y-12"><div class="text-left"><img alt="" loading="lazy" width="126" height="56" decoding="async" data-nimg="1" class="color-swap-no-hover mb-4 h-16 fill-none" style="color:transparent" src="/uploads/logo_trillabit_ac88335b70.svg"/><div class="space-y-4 text-neutral-0"><p>“The [ClickHouse] table engines for integrations are great features that allow for direct connections to other relational stores like MySQL or Postgres.”</p></div></div></div></a></div><div class="mb-3 w-full break-inside-avoid rounded-lg border border-neutral-700/80 bg-neutral-900/50 object-cover p-6 shadow-card hover:bg-neutral-750"><a href="/blog/how-we-used-clickhouse-to-store-opentelemetry-traces"><div class="flex h-full w-full flex-col justify-between space-y-12"><div class="text-left"><img alt="" loading="lazy" width="115" height="57" decoding="async" data-nimg="1" class="color-swap-no-hover mb-4 h-16 fill-none" style="color:transparent" src="/uploads/logo_resmo_bbacb94bf4.svg"/><div class="space-y-4 text-neutral-0"><p>“Another useful feature of ClickHouse is that it can be easily connected to Postgres, allowing us to use it in our observability queries … We can join the user and tenant IDs in our spans to the actual account names and account status in the Postgres database.”</p></div></div></div></a></div><div class="mb-3 w-full break-inside-avoid rounded-lg border border-neutral-700/80 bg-neutral-900/50 object-cover p-6 shadow-card hover:bg-neutral-750"><a href="https://blog.sentry.io/introducing-snuba-sentrys-new-search-infrastructure"><div class="flex h-full w-full flex-col justify-between space-y-12"><div class="text-left"><img alt="" loading="lazy" width="141" height="32" decoding="async" data-nimg="1" class="color-swap-no-hover mb-4 h-16 fill-none" style="color:transparent" src="/uploads/sentry_logo_136a2b3bc0.svg"/><div class="space-y-4 text-neutral-0"><p>“We scaled [Postgres] out to a fleet of machines but were burdened with a suite of problems that throwing hardware at just could not resolve. We needed a way to reduce infrastructural work whenever a new dimension of data was discovered, not a way to scale the current dataset.”</p></div></div></div></a></div><div class="mb-3 w-full break-inside-avoid rounded-lg border border-neutral-700/80 bg-neutral-900/50 object-cover p-6 shadow-card hover:bg-neutral-750"><a href="https://about.gitlab.com/blog/2022/04/29/two-sizes-fit-most-postgresql-and-clickhouse/"><div class="flex h-full w-full flex-col justify-between space-y-12"><div class="text-left"><img alt="" loading="lazy" width="139" height="30" decoding="async" data-nimg="1" class="color-swap-no-hover mb-4 h-16 fill-none" style="color:transparent" src="/uploads/Git_Lab_clipped_40fc3cb093.svg"/><div class="space-y-4 text-neutral-0"><p>On ClickHouse’s performance: “Both the engineering and the benchmark results are impressive, including our own tests (video0).”</p>
<p>“It is significantly faster than PostgreSQL extensions such as CitusDB or Timescale DB, and reportedly also faster than vertica.”</p></div></div></div></a></div></div></div><div class="mx-auto w-full max-w-screen-md border-t border-neutral-725 px-7 my-16 lg:my-24"></div><div class="section-container relative z-10 flex max-w-7xl flex-wrap place-items-center items-center justify-center gap-6 self-center overflow-hidden pb-10 md:gap-x-14"><div class="container mx-auto flex max-w-7xl flex-col px-8 2xl:px-0"><div class="flip-selection mx-auto flex flex-col text-center"><div class="mx-auto mb-8 w-fit max-w-4xl px-4 pb-4 pt-6 text-center text-xl font-semibold leading-normal text-neutral-300 md:px-0">Trusted by developers that work with data at<!-- --> <span class="tilted tilted-yellow"><span class="tilted-content leading-8">scale</span></span></div></div></div><div class="opacity-60 grayscale invert"><div class="flex overflow-hidden styles_mask__TH4CK " style="--carousel-offset:0%;--carousel-duration:0s"><div class="flex w-fit styles_animated__lK39o" style="animation-direction:forwards;animation-play-state:running;gap:3rem;padding-right:3rem"><div class="flex w-max" style="gap:3rem"><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#deepl"><img alt="" loading="lazy" width="216" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Deep_L_742d9b5be8.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#denic"><img alt="" loading="lazy" width="176" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Denic_10e1d91bb2.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#nginx"><img alt="" loading="lazy" width="195" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/nginx_fix_68147ea94e.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#minted"><img alt="" loading="lazy" width="209" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Minted_412898ae48.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#plausible"><img alt="" loading="lazy" width="234" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Plausible_0e93fd3f79.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#theguild"><img alt="" loading="lazy" width="184" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/The_Guild_5539647804.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#statsig"><img alt="" loading="lazy" width="235" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Statsig_889727dd47.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#rokt"><img alt="" loading="lazy" width="181" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Rokt_c433162707.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#servicenow"><img alt="" loading="lazy" width="272" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Servicenow_9a53382248.svg"/></a></div></div><div class="flex w-fit styles_animated__lK39o" style="animation-direction:forwards;animation-play-state:running;gap:3rem;padding-right:3rem"><div class="flex w-max" style="gap:3rem"><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#deepl"><img alt="" loading="lazy" width="216" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Deep_L_742d9b5be8.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#denic"><img alt="" loading="lazy" width="176" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Denic_10e1d91bb2.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#nginx"><img alt="" loading="lazy" width="195" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/nginx_fix_68147ea94e.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#minted"><img alt="" loading="lazy" width="209" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Minted_412898ae48.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#plausible"><img alt="" loading="lazy" width="234" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Plausible_0e93fd3f79.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#theguild"><img alt="" loading="lazy" width="184" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/The_Guild_5539647804.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#statsig"><img alt="" loading="lazy" width="235" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Statsig_889727dd47.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#rokt"><img alt="" loading="lazy" width="181" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Rokt_c433162707.svg"/></a><a class="my-auto inline-block flex-shrink-0 flex-grow-0" href="/user-stories#servicenow"><img alt="" loading="lazy" width="272" height="56" decoding="async" data-nimg="1" class="" style="color:transparent" src="/uploads/Servicenow_9a53382248.svg"/></a></div></div></div></div></div><div class="mx-auto w-full max-w-screen-md border-t border-neutral-725 px-7 my-16 lg:mb-24 lg:mt-12"></div><div class="mx-auto max-w-7xl px-4 md:px-8 2xl:px-0"><div class="mx-auto mb-10 max-w-7xl"><h3 class="mb-4 text-2xl font-semibold">Technical content</h3><div class="grid grid-cols-1 justify-center gap-8 md:grid-cols-2 lg:grid-cols-3"><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg relative overflow-hidden transition-transform hover:-translate-y-1"><div class="cui-card-header w-full undefined"><img alt="" loading="lazy" width="400" height="600" decoding="async" data-nimg="1" class="aspect-thumbnail w-full max-w-none object-cover object-center" style="color:transparent" srcSet="/_next/image?url=%2Fuploads%2FMeetup_Report_Banner_71dcd5702e.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fuploads%2FMeetup_Report_Banner_71dcd5702e.png&amp;w=828&amp;q=75 2x" src="/_next/image?url=%2Fuploads%2FMeetup_Report_Banner_71dcd5702e.png&amp;w=828&amp;q=75"/></div><div class="cui-card-body w-full mb-auto p-6"><div class="mb-2 font-inconsolata text-base font-medium text-primary-300">Community</div><h3 class="text-inherit undefined Typography_suiTitleh3__JlLe2  undefined"><a class="text-neutral-100" href="/blog/nyc-meetup-report-vantages-journey-from-redshift-and-postgres-to-clickhouse"><span class="absolute inset-0"></span>Vantage&#x27;s Journey from Redshift and Postgres to ClickHouse</a></h3></div><div class="cui-card-footer w-full mt-auto flex w-full items-center p-6 pt-0 text-sm text-neutral-300">ClickHouse Editor · Jul 13, 2023</div></div></div><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg relative overflow-hidden transition-transform hover:-translate-y-1"><div class="cui-card-header w-full undefined"><img alt="" loading="lazy" width="400" height="600" decoding="async" data-nimg="1" class="aspect-thumbnail w-full max-w-none object-cover object-center" style="color:transparent" srcSet="/_next/image?url=%2Fuploads%2Fsupa_clickhouse_1115607080.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fuploads%2Fsupa_clickhouse_1115607080.png&amp;w=828&amp;q=75 2x" src="/_next/image?url=%2Fuploads%2Fsupa_clickhouse_1115607080.png&amp;w=828&amp;q=75"/></div><div class="cui-card-body w-full mb-auto p-6"><div class="mb-2 font-inconsolata text-base font-medium text-primary-300">Engineering</div><h3 class="text-inherit undefined Typography_suiTitleh3__JlLe2  undefined"><a class="text-neutral-100" href="/blog/adding-real-time-analytics-to-a-supabase-application"><span class="absolute inset-0"></span>Adding Real Time Analytics to a Supabase Application With ClickHouse</a></h3></div><div class="cui-card-footer w-full mt-auto flex w-full items-center p-6 pt-0 text-sm text-neutral-300">Dale McDiarmid · May 15, 2023</div></div></div><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg relative overflow-hidden transition-transform hover:-translate-y-1"><div class="cui-card-header w-full undefined"><img alt="" loading="lazy" width="400" height="600" decoding="async" data-nimg="1" class="aspect-thumbnail w-full max-w-none object-cover object-center" style="color:transparent" srcSet="/_next/image?url=%2Fuploads%2Fclickhouse_postgresql_1d123677ea.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fuploads%2Fclickhouse_postgresql_1d123677ea.png&amp;w=828&amp;q=75 2x" src="/_next/image?url=%2Fuploads%2Fclickhouse_postgresql_1d123677ea.png&amp;w=828&amp;q=75"/></div><div class="cui-card-body w-full mb-auto p-6"><div class="mb-2 font-inconsolata text-base font-medium text-primary-300">Engineering</div><h3 class="text-inherit undefined Typography_suiTitleh3__JlLe2  undefined"><a class="text-neutral-100" href="/blog/migrating-data-between-clickhouse-postgres"><span class="absolute inset-0"></span>ClickHouse and PostgreSQL - a Match Made in Data Heaven - part 1</a></h3></div><div class="cui-card-footer w-full mt-auto flex w-full items-center p-6 pt-0 text-sm text-neutral-300">Dale McDiarmid · Dec 20, 2022</div></div></div><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg relative overflow-hidden transition-transform hover:-translate-y-1"><div class="cui-card-header w-full undefined"><img alt="" loading="lazy" width="400" height="600" decoding="async" data-nimg="1" class="aspect-thumbnail w-full max-w-none object-cover object-center" style="color:transparent" srcSet="/_next/image?url=%2Fuploads%2Fclickhouse_postgresql_1d123677ea.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fuploads%2Fclickhouse_postgresql_1d123677ea.png&amp;w=828&amp;q=75 2x" src="/_next/image?url=%2Fuploads%2Fclickhouse_postgresql_1d123677ea.png&amp;w=828&amp;q=75"/></div><div class="cui-card-body w-full mb-auto p-6"><div class="mb-2 font-inconsolata text-base font-medium text-primary-300">Engineering</div><h3 class="text-inherit undefined Typography_suiTitleh3__JlLe2  undefined"><a class="text-neutral-100" href="/blog/migrating-data-between-clickhouse-postgres-part-2"><span class="absolute inset-0"></span>ClickHouse and PostgreSQL - a Match Made in Data Heaven - part 2</a></h3></div><div class="cui-card-footer w-full mt-auto flex w-full items-center p-6 pt-0 text-sm text-neutral-300">Dale McDiarmid · Jan 26, 2023</div></div></div></div></div><div class="mx-auto mb-10 max-w-7xl"><h3 class="mb-4 text-2xl font-semibold">Related blogs</h3><div class="grid grid-cols-1 justify-center gap-8 md:grid-cols-2 lg:grid-cols-3"><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg relative overflow-hidden transition-transform hover:-translate-y-1"><div class="cui-card-header w-full undefined"><img alt="" loading="lazy" width="400" height="600" decoding="async" data-nimg="1" class="aspect-thumbnail w-full max-w-none object-cover object-center" style="color:transparent" srcSet="/_next/image?url=%2Fuploads%2Fprefect_og_a43484ffbc.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fuploads%2Fprefect_og_a43484ffbc.png&amp;w=828&amp;q=75 2x" src="/_next/image?url=%2Fuploads%2Fprefect_og_a43484ffbc.png&amp;w=828&amp;q=75"/></div><div class="cui-card-body w-full mb-auto p-6"><div class="mb-2 font-inconsolata text-base font-medium text-primary-300">User stories</div><h3 class="text-inherit undefined Typography_suiTitleh3__JlLe2  undefined"><a class="text-neutral-100" href="/blog/prefect-event-driven-workflow-orchestration-powered-by-clickhouse"><span class="absolute inset-0"></span>Prefect - Event-driven workflow orchestration powered by ClickHouse</a></h3></div><div class="cui-card-footer w-full mt-auto flex w-full items-center p-6 pt-0 text-sm text-neutral-300">Sarah Bedell &amp; Chris Guidry, Prefect · May 30, 2024</div></div></div></div></div><div class="mx-auto mb-10 max-w-7xl"><h3 class="mb-4 text-2xl font-semibold">Guides</h3><div class="grid grid-cols-1 justify-center gap-8 md:grid-cols-2 lg:grid-cols-3"><a target="_blank" class="hover:scale-102 blog-post-card transition ease-in-out hover:-translate-y-1 hover:no-underline" href="https://clickhouse.com/docs/en/integrations/postgresql"><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg h-full"><div class="cui-card-body w-full flex flex-col items-start justify-center gap-2"><div class="flex flex-col items-start justify-center gap-2 px-6 pt-6"><div class="mb-2 font-inconsolata text-base font-medium text-primary-300">Docs</div><div class="cursor-pointer font-basier text-xl font-medium leading-tight text-neutral-100">Connecting ClickHouse to Postgres</div></div></div><div class="cui-card-footer w-full flex w-full items-center p-6 text-sm text-neutral-300"></div></div></div></a><a target="_blank" class="hover:scale-102 blog-post-card transition ease-in-out hover:-translate-y-1 hover:no-underline" href="https://clickhouse.com/docs/en/interfaces/postgresql"><div class="h-full"><div class="cui-card flex h-full flex-col items-center justify-between rounded-lg border border-neutral-700/80 bg-neutral-900/50 shadow-card hover:shadow-lg h-full"><div class="cui-card-body w-full flex flex-col items-start justify-center gap-2"><div class="flex flex-col items-start justify-center gap-2 px-6 pt-6"><div class="mb-2 font-inconsolata text-base font-medium text-primary-300">Docs</div><div class="cursor-pointer font-basier text-xl font-medium leading-tight text-neutral-100">Using Postgres clients with ClickHouse</div></div></div><div class="cui-card-footer w-full flex w-full items-center p-6 text-sm text-neutral-300"></div></div></div></a></div></div></div><div class="mx-auto w-full max-w-screen-md border-t border-neutral-725 px-7 my-16 lg:my-24"></div><div class="mx-auto mb-24 max-w-7xl px-4 md:px-8 2xl:px-0"><div class="section-container bg-shadow-element red-shadow align-shadow-left container mx-auto flex flex-col items-center"><img alt="Migrations" loading="lazy" width="72" height="72" decoding="async" data-nimg="1" class="mb-4 fill-none" style="color:transparent" src="/images/migration.svg"/><h2 class="mb-12 text-center font-basier text-xl font-semibold lg:mb-16">Contact us for help with your migration</h2><div class="mx-auto max-w-lg"><div class="text-center">Loading form...</div></div></div></div></main><footer class="bg-neutral-900 pb-8 pt-16"><div class="section-container space-y-11"><div class="md:flex md:justify-between md:gap-8 lg:gap-10"><nav class="w-full"><ul class="-mx-3 flex flex-row flex-wrap gap-y-8 lg:flex-nowrap"><li class="flex w-1/2 flex-col px-3 lg:w-4/12"><ul class="space-y-1.5"><li class="!mb-4 font-inter text-sm font-bold text-neutral-100 ">Product</li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/cloud">ClickHouse Cloud</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/cloud/bring-your-own-cloud">Bring Your Own Cloud</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/cloud/postgres">Postgres managed by ClickHouse</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/cloud/clickstack">Managed ClickStack</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/clickhouse">ClickHouse</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/clickstack">ClickStack</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/ai">Agentic Data Stack</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/government">ClickHouse Government</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/clickhouse/keeper">ClickHouse Keeper</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/cloud/clickpipes">ClickPipes</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/integrations">Integrations</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/chdb">chDB</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/pricing">Pricing</a></li></ul></li><li class="flex w-1/2 flex-col px-3 lg:w-4/12"><ul class="space-y-1.5"><li class="!mb-4 font-inter text-sm font-bold text-neutral-100 ">Resources</li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="https://clickhouse.com/docs">Documentation</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="https://trust.clickhouse.com">Trust center</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/learn">Training</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/support/program">Support</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/benchmarks">Benchmarks</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/use-cases">Use cases</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/videos">Videos</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/demos">Demos</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="https://presentations.clickhouse.com/">Presentations</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/real-time-data-warehouse">Real-time data warehouse</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/resources/engineering">Engineering resources</a></li></ul></li><li class="flex w-1/2 flex-col px-3 lg:w-4/12"><ul class="space-y-1.5"><li class="!mb-4 font-inter text-sm font-bold text-neutral-100 ">Company</li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/blog">Blog</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/company/our-story">Our story</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/company/careers">Careers</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/company/contact?loc=footer">Contact us</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/company/events">Events</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/company/news">News</a></li><li class="leading-none"><a target="_blank" class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/media">Media</a></li></ul></li><li class="flex w-1/2 flex-col px-3 lg:w-4/12"><ul class="space-y-1.5"><li class="!mb-4 font-inter text-sm font-bold text-neutral-100 ">Join our community</li><li class="leading-none"><a target="_blank" class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="https://github.com/ClickHouse/ClickHouse">GitHub</a></li><li class="leading-none"><a target="_blank" class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/slack">Slack</a></li><li class="leading-none"><a target="_blank" class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="https://www.linkedin.com/company/clickhouseinc">LinkedIn</a></li><li class="leading-none"><a target="_blank" class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="https://x.com/ClickhouseDB">X</a></li><li class="leading-none"><a target="_blank" class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="https://bsky.app/profile/clickhouse.com">Bluesky</a></li><li class="leading-none"><a target="_blank" class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="https://telegram.me/clickhouse_en">Telegram</a></li><li class="leading-none"><a target="_blank" class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="https://www.meetup.com/pro/clickhouse">Meetup</a></li></ul></li><li class="flex w-1/2 flex-col px-3 lg:w-4/12"><ul class="space-y-1.5"><li class="!mb-4 font-inter text-sm font-bold text-neutral-100 ">Comparisons</li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/comparison/bigquery">BigQuery</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/comparison/postgresql">PostgreSQL</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/comparison/redshift">Redshift</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/comparison/snowflake">Snowflake</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/comparison/elastic-for-observability">Elastic</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/comparison/splunk-for-observability">Splunk</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/comparison/opensearch-for-observability">OpenSearch</a></li><li class="!mb-4 font-inter text-sm font-bold text-neutral-100 !mt-8">Partners</li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/partners/aws">AWS</a></li><li class="leading-none"><a class="text-sm text-neutral-400 transition-colors hover:text-neutral-0" href="/partners/azure">Azure</a></li></ul></li></ul></nav><div class="mt-12 md:mt-0 md:w-fit"><img alt="ClickHouse logo" loading="lazy" width="135" height="40" decoding="async" data-nimg="1" class="mb-4 mr-3" style="color:transparent" src="/_next/static/media/logo-full.ac8102d5.svg"/><div class="mb-4 text-sm text-neutral-400">Stay informed on feature releases, product roadmap, support, and cloud offerings!</div><div class="text-center">Loading form...</div><a class=" flex justify-end w-full" target="_blank" href="https://github.com/ClickHouse/ClickHouse"><button class="styles_button__3smpn mt-6 w-full bg-neutral-0 text-neutral-900 md:w-fit font-semibold" data-type="secondary"><span class="pr-1"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 1.75C4.27062 1.75 1.25 4.77062 1.25 8.5C1.25 11.4869 3.18219 14.0097 5.86531 14.9041C6.20281 14.9631 6.32937 14.7606 6.32937 14.5834C6.32937 14.4231 6.32094 13.8916 6.32094 13.3263C4.625 13.6384 4.18625 12.9128 4.05125 12.5331C3.97531 12.3391 3.64625 11.74 3.35938 11.5797C3.12312 11.4531 2.78562 11.1409 3.35094 11.1325C3.8825 11.1241 4.26219 11.6219 4.38875 11.8244C4.99625 12.8453 5.96656 12.5584 6.35469 12.3813C6.41375 11.9425 6.59094 11.6472 6.785 11.4784C5.28312 11.3097 3.71375 10.7275 3.71375 8.14563C3.71375 7.41156 3.97531 6.80406 4.40563 6.33156C4.33812 6.16281 4.10187 5.47094 4.47312 4.54281C4.47312 4.54281 5.03844 4.36563 6.32937 5.23469C6.86937 5.08281 7.44313 5.00687 8.01688 5.00687C8.59063 5.00687 9.16438 5.08281 9.70438 5.23469C10.9953 4.35719 11.5606 4.54281 11.5606 4.54281C11.9319 5.47094 11.6956 6.16281 11.6281 6.33156C12.0584 6.80406 12.32 7.40312 12.32 8.14563C12.32 10.7359 10.7422 11.3097 9.24031 11.4784C9.485 11.6894 9.69594 12.0944 9.69594 12.7272C9.69594 13.63 9.6875 14.3556 9.6875 14.5834C9.6875 14.7606 9.81406 14.9716 10.1516 14.9041C12.8178 14.0097 14.75 11.4784 14.75 8.5C14.75 4.77062 11.7294 1.75 8 1.75Z" fill="currentColor"></path></svg></span><span class="flex items-center whitespace-nowrap">Star us on Github</span></button></a></div></div><div class="flex flex-col items-start border-t border-neutral-400/10 pt-2 lg:pt-8"><div class="section-container flex w-full flex-col items-center gap-3 pt-4 text-center text-sm text-neutral-400 sm:gap-1 md:flex-row md:justify-between md:pt-0 md:text-left"><div>© <!-- -->2026<!-- --> ClickHouse, Inc. HQ in the Bay Area, CA and Amsterdam, NL.</div><div class="bottom_links flex flex-wrap items-center justify-center gap-4"><a class="whitespace-nowrap first:pl-0 hover:text-neutral-0" href="/legal/trademark-policy">Trademark</a><a class="whitespace-nowrap first:pl-0 hover:text-neutral-0" href="/legal/privacy-policy">Privacy</a><a target="_blank" class="whitespace-nowrap first:pl-0 hover:text-neutral-0" href="https://trust.clickhouse.com/">Security</a><a class="whitespace-nowrap first:pl-0 hover:text-neutral-0" href="/legal">Legal</a><a class="whitespace-nowrap first:pl-0 hover:text-neutral-0" href="/legal/cookie-policy">Cookie policy</a><button id="cookie-settings-button" class="cmp-revoke-consent relative bottom-auto left-auto hidden whitespace-nowrap bg-transparent p-0 hover:text-neutral-0"><img alt="Opt-out logo" loading="lazy" width="30" height="14" decoding="async" data-nimg="1" class="mr-2 inline w-8 align-middle" style="color:transparent" src="/images/opt-out-logo.svg"/>Your privacy choices</button></div></div></div></div></footer></div></div><div role="region" aria-label="Notifications (F8)" tabindex="-1" style="pointer-events:none"><ol tabindex="-1" class="sc-tmc8vl-6 fIFjxI"></ol></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"comparison":{"id":1,"Title":"ClickHouse and PostgreSQL","HeroDescription":"Are your analytical queries in Postgres hitting performance limitations, scalability challenges, or becoming operationally complex? Discover why our customers are relying on ClickHouse to power these analytics use cases while freeing Postgres to do what it does best.\n","createdAt":"2023-06-02T12:20:31.577Z","updatedAt":"2024-08-19T10:13:15.469Z","publishedAt":"2023-06-02T12:20:38.604Z","slug":"postgresql","formTitle":"Contact us for help with your migration","testimonialsTitle":"What developers say about ClickHouse and PostgreSQL","painpointsTitle":"Why do developers choose ClickHouse?","painpoint":[{"id":1,"Title":"PostgreSQL performance limitations","Description":"Developers report challenges with query run time and inflated disk sizes as big drains on the performance of their analytical queries running on Postgres. \n\n**ClickHouse is the fastest and most resource-efficient database for analytics.**\u003cbr /\u003e\nWhether you’re aggregating large volumes of data in real-time, interactively slicing and dicing on the fly, or powering customer-facing applications, ClickHouse is blazingly fast, overcoming the performance limitations often seen with Postgres.\n\nOONI, for example, were able to reduce their analytical query times from 20 minutes in PostgreSQL to milliseconds in ClickHouse while halving their storage requirements.\n","customer":{"id":1,"description":"\"Having all the data in ClickHouse means we can quickly answer questions without having to wait hours for queries to converge, significantly improving our internal data analysis tasks.\"\n\n[Read more](/blog/ooni-analyzes-internet-censorship-data-with-clickhouse)","logo":{"id":1480,"name":"ooni-logo.svg","alternativeText":null,"caption":null,"width":154,"height":44,"formats":{},"hash":"ooni_logo_d709527b16","ext":".svg","mime":"image/svg+xml","size":12.51,"url":"/uploads/ooni_logo_d709527b16.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-06-08T10:46:10.621Z","updatedAt":"2023-06-08T10:50:56.302Z"}}},{"id":2,"Title":"PostgreSQL scalability challenges","Description":"Scalability is an important consideration for any database system, including PostgreSQL. While PostgreSQL is known for its robustness and performance, it does face scalability challenges.\n\n**ClickHouse is designed to efficiently manage huge volumes of data.** \u003cbr /\u003e\nClickHouse scales both vertically and horizontally, ensuring the effective utilization of available resources. ClickHouse is relied on at scale by companies all over the world to process and store hundreds of petabytes of compressed data.\n\nCloudflare’s old data pipeline conceived in 2014, centered around scaling out Postgres for their analytics. “The pipeline had served us and our customers well over the years, but began to split at the seams.” They needed to find a scalable solution built for tomorrow.\n","customer":{"id":2,"description":"“It is [ClickHouse] blazing fast, linearly scalable, hardware efficient, fault tolerant, feature rich, highly reliable, simple and handy.”\n\n[Read more](https://blog.cloudflare.com/http-analytics-for-6m-requests-per-second-using-clickhouse)","logo":{"id":1482,"name":"Cloudflare_Logo (1) 1.png","alternativeText":null,"caption":null,"width":103,"height":35,"formats":null,"hash":"Cloudflare_Logo_1_1_9ea1e1bc38","ext":".png","mime":"image/png","size":0.79,"url":"/uploads/Cloudflare_Logo_1_1_9ea1e1bc38.png","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-06-08T10:48:50.347Z","updatedAt":"2023-06-08T10:48:50.347Z"}}},{"id":3,"Title":"PostgreSQL operational complexity","Description":"Optimizing query execution plans, indexing strategies, and database configuration parameters requires expertise and ongoing monitoring to address performance bottlenecks. \n\n**ClickHouse is purpose-built for real-time, large-volume, data analytics.**\u003cbr /\u003e\nWith ClickHouse, there is no need for the operational complexity that exists when retrofitting another system for these real-time workloads. With ClickHouse, real-time just works.\n\n\nMUX’s old Postgres-based pipelines required manual oversight. “If too many jobs that landed on the same Postgres shard happened to run at the same time, the cluster could grind to a halt. This required manually stopping all of the other jobs and babysitting them one-at-a-time until they all completed.” ClickHouse solved these issues and more.\n","customer":{"id":3,"description":"“With all of this in mind, we started by keeping the [ClickHouse] architecture as simple as possible: just dump all of the data into one table called ‘views’. No Airflow. No aggregation. No stored procedures. Any bucketing logic would be written in the SQL queries at read-time and computed on the fly. To our surprise, this worked extremely well.”\n\n[Read more](https://www.mux.com/blog/from-russia-with-love-how-clickhouse-saved-our-data)","logo":{"id":1481,"name":"Mux Logo Small White 1.svg","alternativeText":null,"caption":null,"width":120,"height":38,"formats":{},"hash":"Mux_Logo_Small_White_1_a9508596c4","ext":".svg","mime":"image/svg+xml","size":2.44,"url":"/uploads/Mux_Logo_Small_White_1_a9508596c4.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-06-08T10:48:11.104Z","updatedAt":"2023-06-09T19:43:17.262Z"}}}],"painpointsIcon":{"id":1473,"name":"people-icon.svg","alternativeText":null,"caption":null,"width":73,"height":72,"formats":null,"hash":"people_icon_b6c8c61d7c","ext":".svg","mime":"image/svg+xml","size":1.14,"url":"/uploads/people_icon_b6c8c61d7c.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-06-07T12:01:30.984Z","updatedAt":"2023-06-07T12:01:30.984Z"},"seo":{"id":12,"title":"ClickHouse and PostgreSQL","keywords":null,"description":"Discover why our customers are relying on ClickHouse to power these analytics use cases while freeing Postgres to do what it does best.","schema":null,"canonicalUrl":null,"noindex":null,"nofollow":null,"robots":null,"path":"/comparison/postgresql","languages":["en","ja"],"lastModified":"2024-08-19T10:13:15.469Z"},"Testimonials":[{"id":34,"Title":"Helicone","Description":"“We were using Postgres and Postgres just wasn't scaling for those nice dashboards. In order to get these nice dashboards, you need to do all these aggregation calls. Aggregations were taking more than 30 seconds and things were just timing out.”","href":"/blog/helicones-migration-from-postgres-to-clickhouse-for-advanced-llm-monitoring","logo":{"id":1922,"name":"helicone-logo.svg","alternativeText":null,"caption":null,"width":120,"height":25,"formats":null,"hash":"helicone_logo_1f0bfd432c","ext":".svg","mime":"image/svg+xml","size":10.49,"url":"/uploads/helicone_logo_1f0bfd432c.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-11-21T10:39:53.678Z","updatedAt":"2023-11-21T10:39:53.678Z"}},{"id":1,"Title":"QuickCheck","Description":"“We realized we had so much data in Postgres, which was taking forever to process, so we started moving it to ClickHouse. It is instant in ClickHouse vs forever in Postgres.”","href":"/blog/how-quickcheck-uses-clickhouse-to-bring-banking-to-the-unbanked","logo":{"id":1298,"name":"logo-quickcheck.svg","alternativeText":null,"caption":null,"width":173,"height":56,"formats":null,"hash":"logo_quickcheck_daeb6bafaa","ext":".svg","mime":"image/svg+xml","size":7.27,"url":"/uploads/logo_quickcheck_daeb6bafaa.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-15T16:42:59.119Z","updatedAt":"2023-06-07T15:20:30.657Z"}},{"id":2,"Title":"PostHog","Description":"“Eventually, [our] all-purpose Postgres database was tasked to store millions of rows of data. It was obvious Postgres couldn't handle the scale necessary for an analytics platform like PostHog. At first, the team tried a ton of hack-y and wacky solutions in attempts to get Postgres to work. Turns out, that wasn’t sustainable (who would’ve thought!). Eventually, PostHog migrated client data to ClickHouse. Boom!”","href":"https://posthog.com/blog/clickhouse-vs-postgres","logo":{"id":1476,"name":"posthog-clipped.svg","alternativeText":null,"caption":null,"width":157,"height":30,"formats":null,"hash":"posthog_clipped_9275fb0f26","ext":".svg","mime":"image/svg+xml","size":5.93,"url":"/uploads/posthog_clipped_9275fb0f26.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-06-07T15:25:07.451Z","updatedAt":"2023-06-07T15:25:07.451Z"}},{"id":3,"Title":"Plausible","Description":"“It became clear early on that the original architecture using Postgres to store analytics data could not handle the platform’s future growth.”","href":"/blog/plausible-analytics-uses-click-house-to-power-their-privacy-friendly-google-analytics-alternative","logo":{"id":1287,"name":"logo-plausible.svg","alternativeText":null,"caption":null,"width":123,"height":57,"formats":null,"hash":"logo_plausible_9bede01d72","ext":".svg","mime":"image/svg+xml","size":52.82,"url":"/uploads/logo_plausible_9bede01d72.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-15T16:37:52.481Z","updatedAt":"2023-05-15T16:37:52.481Z"}},{"id":4,"Title":"HiFi","Description":"“We still use PG [Postgres] for non-royalty data such as customer account data and metadata. Fortunately, ClickHouse makes it relatively easy to connect to PG databases.”","href":"/blog/hifis-migration-from-bigquery-to-clickhouse","logo":{"id":1297,"name":"logo-hifi.svg","alternativeText":null,"caption":null,"width":75,"height":56,"formats":null,"hash":"logo_hifi_c9f874cec8","ext":".svg","mime":"image/svg+xml","size":1.23,"url":"/uploads/logo_hifi_c9f874cec8.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-15T16:42:44.432Z","updatedAt":"2023-05-15T16:42:44.432Z"}},{"id":5,"Title":"Trillabit","Description":"“The [ClickHouse] table engines for integrations are great features that allow for direct connections to other relational stores like MySQL or Postgres.”","href":"/blog/trillabit-utilizes-the-power-of-clickhouse-for-fast-scalable-results-within-their-self-service-search-driven-analytics-offering","logo":{"id":1313,"name":"logo-trillabit.svg","alternativeText":null,"caption":null,"width":126,"height":56,"formats":null,"hash":"logo_trillabit_ac88335b70","ext":".svg","mime":"image/svg+xml","size":11.76,"url":"/uploads/logo_trillabit_ac88335b70.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-15T16:50:30.049Z","updatedAt":"2023-05-15T16:50:30.049Z"}},{"id":6,"Title":"Resmo","Description":"“Another useful feature of ClickHouse is that it can be easily connected to Postgres, allowing us to use it in our observability queries … We can join the user and tenant IDs in our spans to the actual account names and account status in the Postgres database.”","href":"/blog/how-we-used-clickhouse-to-store-opentelemetry-traces","logo":{"id":1310,"name":"logo-resmo.svg","alternativeText":null,"caption":null,"width":115,"height":57,"formats":null,"hash":"logo_resmo_bbacb94bf4","ext":".svg","mime":"image/svg+xml","size":6.41,"url":"/uploads/logo_resmo_bbacb94bf4.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-15T16:49:37.068Z","updatedAt":"2023-05-15T16:49:37.068Z"}},{"id":7,"Title":"Sentry","Description":"“We scaled [Postgres] out to a fleet of machines but were burdened with a suite of problems that throwing hardware at just could not resolve. We needed a way to reduce infrastructural work whenever a new dimension of data was discovered, not a way to scale the current dataset.”","href":"https://blog.sentry.io/introducing-snuba-sentrys-new-search-infrastructure","logo":{"id":1475,"name":"sentry-logo.svg","alternativeText":null,"caption":null,"width":141,"height":32,"formats":null,"hash":"sentry_logo_136a2b3bc0","ext":".svg","mime":"image/svg+xml","size":2.78,"url":"/uploads/sentry_logo_136a2b3bc0.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-06-07T14:34:40.647Z","updatedAt":"2023-06-07T14:34:40.647Z"}},{"id":8,"Title":"GitLab","Description":"On ClickHouse’s performance: “Both the engineering and the benchmark results are impressive, including our own tests (video0).”\n\n“It is significantly faster than PostgreSQL extensions such as CitusDB or Timescale DB, and reportedly also faster than vertica.”","href":"https://about.gitlab.com/blog/2022/04/29/two-sizes-fit-most-postgresql-and-clickhouse/","logo":{"id":1477,"name":"GitLab-clipped.svg","alternativeText":null,"caption":null,"width":139,"height":30,"formats":null,"hash":"Git_Lab_clipped_40fc3cb093","ext":".svg","mime":"image/svg+xml","size":3.65,"url":"/uploads/Git_Lab_clipped_40fc3cb093.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-06-07T15:26:39.377Z","updatedAt":"2023-06-07T15:26:39.377Z"}}],"customerStories":{"id":2,"title":"Trusted by developers that work with data at","description":"Don't take our word for it","popText":"scale","logos":[{"id":39,"href":"/user-stories#deepl","target":"_self","darkLogoPng":{"id":1349,"name":"DeepL.svg","alternativeText":null,"caption":null,"width":216,"height":56,"formats":null,"hash":"Deep_L_742d9b5be8","ext":".svg","mime":"image/svg+xml","size":5.44,"url":"/uploads/Deep_L_742d9b5be8.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-18T09:39:01.083Z","updatedAt":"2023-05-18T09:39:01.083Z"}},{"id":40,"href":"/user-stories#denic","target":"_self","darkLogoPng":{"id":1350,"name":"Denic.svg","alternativeText":null,"caption":null,"width":176,"height":56,"formats":null,"hash":"Denic_10e1d91bb2","ext":".svg","mime":"image/svg+xml","size":2.18,"url":"/uploads/Denic_10e1d91bb2.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-18T09:39:11.927Z","updatedAt":"2023-05-18T09:39:11.927Z"}},{"id":41,"href":"/user-stories#nginx","target":"_self","darkLogoPng":{"id":1382,"name":"nginx-fix.svg","alternativeText":null,"caption":null,"width":195,"height":56,"formats":null,"hash":"nginx_fix_68147ea94e","ext":".svg","mime":"image/svg+xml","size":1.49,"url":"/uploads/nginx_fix_68147ea94e.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-18T15:00:35.912Z","updatedAt":"2023-05-18T15:00:35.912Z"}},{"id":42,"href":"/user-stories#minted","target":"_self","darkLogoPng":{"id":1354,"name":"Minted.svg","alternativeText":null,"caption":null,"width":209,"height":56,"formats":null,"hash":"Minted_412898ae48","ext":".svg","mime":"image/svg+xml","size":2.36,"url":"/uploads/Minted_412898ae48.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-18T09:40:15.750Z","updatedAt":"2023-06-07T11:07:14.322Z"}},{"id":43,"href":"/user-stories#plausible","target":"_self","darkLogoPng":{"id":1357,"name":"Plausible.svg","alternativeText":null,"caption":null,"width":234,"height":56,"formats":null,"hash":"Plausible_0e93fd3f79","ext":".svg","mime":"image/svg+xml","size":52.03,"url":"/uploads/Plausible_0e93fd3f79.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-18T09:40:51.748Z","updatedAt":"2023-05-18T09:40:51.748Z"}},{"id":44,"href":"/user-stories#theguild","target":"_self","darkLogoPng":{"id":1373,"name":"TheGuild.svg","alternativeText":null,"caption":null,"width":184,"height":56,"formats":null,"hash":"The_Guild_5539647804","ext":".svg","mime":"image/svg+xml","size":5.45,"url":"/uploads/The_Guild_5539647804.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-18T10:43:12.896Z","updatedAt":"2023-05-18T10:43:12.896Z"}},{"id":45,"href":"/user-stories#statsig","target":"_self","darkLogoPng":{"id":1389,"name":"Statsig.svg","alternativeText":null,"caption":null,"width":235,"height":56,"formats":null,"hash":"Statsig_889727dd47","ext":".svg","mime":"image/svg+xml","size":5.09,"url":"/uploads/Statsig_889727dd47.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-19T08:23:54.155Z","updatedAt":"2023-05-19T08:23:54.155Z"}},{"id":47,"href":"/user-stories#rokt","target":"_self","darkLogoPng":{"id":1360,"name":"Rokt.svg","alternativeText":null,"caption":null,"width":181,"height":56,"formats":null,"hash":"Rokt_c433162707","ext":".svg","mime":"image/svg+xml","size":1.58,"url":"/uploads/Rokt_c433162707.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-18T09:41:23.447Z","updatedAt":"2023-06-23T13:57:18.950Z"}},{"id":48,"href":"/user-stories#servicenow","target":"_self","darkLogoPng":{"id":1361,"name":"Servicenow.svg","alternativeText":null,"caption":null,"width":272,"height":56,"formats":null,"hash":"Servicenow_9a53382248","ext":".svg","mime":"image/svg+xml","size":12.31,"url":"/uploads/Servicenow_9a53382248.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-18T09:41:36.231Z","updatedAt":"2023-05-18T09:41:36.231Z"}}]},"image":{"id":1472,"name":"ch-postgres.png","alternativeText":null,"caption":null,"width":156,"height":153,"formats":null,"hash":"ch_postgres_0406bb34cf","ext":".png","mime":"image/png","size":2.46,"url":"/uploads/ch_postgres_0406bb34cf.png","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-06-07T10:26:33.206Z","updatedAt":"2023-06-07T10:26:33.206Z"},"testimonialsIcon":{"id":1474,"name":"devsays-icon.svg","alternativeText":null,"caption":null,"width":73,"height":72,"formats":null,"hash":"devsays_icon_5e43a8f909","ext":".svg","mime":"image/svg+xml","size":0.98,"url":"/uploads/devsays_icon_5e43a8f909.svg","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-06-07T13:33:09.723Z","updatedAt":"2023-06-07T13:33:09.723Z"},"Content":[{"id":1,"SectionTitle":"Technical content","Category":null,"Footer":null,"Description":"","RelatedBlogs":[{"id":1,"blog_posts":[{"id":215,"category":"Community","title":"Vantage's Journey from Redshift and Postgres to ClickHouse","shortDescription":"Discover Vantage's move from Redshift and Postgres to ClickHouse. Learn about their challenges, decision to switch, and the benefits gained, including improved performance, cost reduction, and enhanced data analysis capabilities.","content":"\u003ciframe width=\"764\" height=\"430\" src=\"https://www.youtube.com/embed/gBgXcHM_ldc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003cbr/\u003e\n\nBrooke McKim, co-founder and CTO of Vantage shares their experience of transitioning from Redshift and Postgres to ClickHouse. In their talk they took us through Vantage's journey, discussing the challenges with their previous architecture, the decision to switch to ClickHouse, and the benefits they've seen since making the move.\n\n[Vantage](https://vantage.sh/) is a cloud cost optimization platform enabling teams to manage and optimize their cloud costs across ten cloud infrastructure and service providers, such as AWS, Azure, Google Cloud, Datadog, New Relic, Snowflake, Databricks, Fastly, MongoDB Atlas, and Kubernetes. Their Autopilot managed service optimizes AWS bills by automatically buying and selling financial commitments, resulting in up to 72% savings. \n\nThe Vantage user interface (UI) offers a comprehensive view of all relevant data, with features for filtering, aggregation, and reporting. A standout feature is the ability to drill down into specific dimensions. For instance, if you're looking at the cost for Amazon's S3 service, you can click into that category and break it down further. Even with larger accounts, which can have billions of records spanning six to twelve months, you can delve into specific resources, providing an in-depth perspective on cost data at scale.\n\n![Vantage UI.png](/uploads/Vantage_UI_5eba58e23e.png)\n_The Vantage UI provides a detailed view of cloud costs with unique drill-down capabilities for in-depth data analysis._\n\n## Challenges with Redshift and Postgres\n\nVantage initially started with Postgres, which seemed adequate at first. However, McKim explained they quickly encountered performance issues as they began to scale. “We were in this growth phase and it seemed like every week or month we were getting a customer that was an order of magnitude larger than the one we had the previous. A lot of that time was spent keeping up with the performance issues. Eventually we just hit a wall with Postgres and had to figure out a different solution.”\n\nPostgres uses a process called 'vacuum' to remove deleted records from disk space. However, with Vantage's frequent data deletions and insertions, this vacuum process was constantly running, using up resources and slowing performance. The system struggled to keep indexes in memory due to constant changes, leading to slow response times. This led Vantage to seek alternatives that offered similar functionality but were more efficient.\n\nThe team at Vantage sought a solution similar to Postgres for a quick transition with minimal operational overhead. They decided to choose Redshift for its familiarity, as it's based on an older version of Postgres. However, [Redshift presented its own challenges](https://clickhouse.com/blog/redshift-vs-clickhouse-comparison). Although it could handle larger volumes of data, it struggled with  Vantage's constant deletes and updates and required data to always be inserted in sort order for  optimal performance. The team attempted to mitigate these issues by running vacuum sort operations frequently and partitioning tables. They also created a hybrid architecture with Redshift as their data warehouse and Postgres as a cache. However, this resulted in a limited user experience and the need to move billions of records daily between Redshift and Postgres. Conversely, ClickHouse’s ReplicatedMergeTree table engine allows row updates to be handled efficiently and transparently.\n\n![Vantage - Redshift.png](/uploads/Vantage_Redshift_cf31a64863.png)\n\nTo be able to present cost data to users, Vantage was generating tens of thousands of reports nightly, leading to a large amount of data being deleted and reinserted into Postgres. This resulted in high cloud costs, with Postgres costs surpassing those of Redshift due to the provision of IOPS and the numerous write operations. They could have scaled this further, but reached a cost limit they were unwilling to exceed. This resulted in numerous \"roll up\" tables with various data variations. McKim mentioned, \"We're inserting data into Redshift. It's unsorted. We have to go back and run this job, which ends up being very expensive, especially as your table gets very large.\"\n\n## Discovering ClickHouse Cloud as an Alternative\nAs Vantage started exploring alternatives, they met with the ClickHouse team at the AWS re:Invent conference. They were attracted to ClickHouse Cloud for its ease of use, low operational overhead, and comprehensive documentation.\n\n “ClickHouse has been great to work with. I think there's a bit of a learning curve when you first approach ClickHouse, but once you understand some of the intricacies of how it differs from traditional relational databases, and how the different engines work, it's actually pretty easy to move over to,” explained McKim. \n\nThe team embarked on a 60-day transition process, which mostly involved ensuring the quality and correctness of the data. McKim mentioned, \"The documentation is just far more comprehensive and technically deeper than anything you'll get from AWS on Redshift, which has just been super helpful because you can just understand how the system works.\"\n\n## Transitioning to ClickHouse and Tackling Data Ingestion Challenges\n\nWith ClickHouse, Vantage no longer needed to delete and reinsert data for their nightly report generation. Instead, they began versioning imports using the [ReplacingMergeTree](https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/replacingmergetree) engine and added an import version column that increments with each data import. This approach allowed them to reduce their operational overhead and cut costs while still maintaining high performance. McKim said, \"ClickHouse is just taking the existing data in the table and doing a merge automatically with any new data that is inserted, which is great as it saves us having to delete and update rows.\"\n\nIn contrast to Redshift, ClickHouse automatically sorts and merges data, which saves both time and resources. They also appreciate ClickHouse's comprehensive documentation, no downtime updates, and data storage in S3 which is cost-effective. They contrast this with their experiences with Redshift, which has forced updates incuring downtime, potential service interruptions, and seems less suited for real-time analytics.\n\n![Vantage ClickHouse Cloud benefits.png](/uploads/Vantage_Click_House_Cloud_benefits_d31c7c436c.png)\n\nSince making the switch to ClickHouse Cloud, Vantage has experienced significant cost savings and performance improvements. They have doubled the resources on their ClickHouse setup at a similar price to their Redshift setup. Additionally, the performance they see from ClickHouse is comparable to a well-indexed, pre-aggregated table in RDS Postgres, which is also cheaper than their previous Postgres setup. \n\n## Looking Forward to Future Opportunities with ClickHouse\nVantage is excited about the potential for reducing operational overhead and is enthusiastic about the rate of innovation they see from the ClickHouse team, as they continue to improve and expand their product. They also look forward to exploring new use cases and taking advantage of ClickHouse's capabilities to further enhance their platform and better serve their customers.\n\nVantage's journey from Redshift and Postgres to ClickHouse demonstrates the value of finding a database solution that better aligns with a company's specific needs. With ClickHouse Cloud, Vantage has found a more cost-effective, high-performance solution that has enabled them to grow and improve their platform. \n\n## More Details\n- This talk was given at the [ClickHouse Community Meetup](https://www.meetup.com/clickhouse-new-york-user-group/events/292517734/) in NYC on April 26, 2023\n- The presentation materials are available [on GitHub](https://github.com/ClickHouse/clickhouse-presentations/blob/master/meetup72/Vantage_%20Our%20Journey%20from%20Redshift%20to%20Clickhouse.pdf)","createdAt":"2023-07-12T15:14:44.778Z","updatedAt":"2026-01-21T12:57:28.197Z","publishedAt":"2023-07-12T15:25:56.173Z","slug":"nyc-meetup-report-vantages-journey-from-redshift-and-postgres-to-clickhouse","date":"2023-07-13","keywords":null,"StagingOnly":false,"ShowCloudCTAHeader":null,"ShowCloudCTAFooter":null,"reading_time":7,"theme":"Meetup Report","use_case":"Real-time Analytics","canonical_url":null,"table_contents_headers":null,"ListOnBlogs":null,"enableSidebarGlobalCta":null,"reading_time_override":null,"thumbnailPng":{"id":1571,"name":"Meetup Report Banner.png","alternativeText":null,"caption":null,"width":2400,"height":1260,"formats":{"large":{"ext":".png","url":"/uploads/large_Meetup_Report_Banner_71dcd5702e.png","hash":"large_Meetup_Report_Banner_71dcd5702e","mime":"image/png","name":"large_Meetup Report Banner.png","path":null,"size":74.25,"width":1000,"height":525},"small":{"ext":".png","url":"/uploads/small_Meetup_Report_Banner_71dcd5702e.png","hash":"small_Meetup_Report_Banner_71dcd5702e","mime":"image/png","name":"small_Meetup Report Banner.png","path":null,"size":33.03,"width":500,"height":263},"medium":{"ext":".png","url":"/uploads/medium_Meetup_Report_Banner_71dcd5702e.png","hash":"medium_Meetup_Report_Banner_71dcd5702e","mime":"image/png","name":"medium_Meetup Report Banner.png","path":null,"size":51.57,"width":750,"height":394},"thumbnail":{"ext":".png","url":"/uploads/thumbnail_Meetup_Report_Banner_71dcd5702e.png","hash":"thumbnail_Meetup_Report_Banner_71dcd5702e","mime":"image/png","name":"thumbnail_Meetup Report Banner.png","path":null,"size":15.74,"width":245,"height":129}},"hash":"Meetup_Report_Banner_71dcd5702e","ext":".png","mime":"image/png","size":28.09,"url":"/uploads/Meetup_Report_Banner_71dcd5702e.png","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-07-03T07:39:23.889Z","updatedAt":"2023-07-05T08:36:55.170Z"},"author":{"id":899,"name":"ClickHouse Editor","profileLink":null}},{"id":187,"category":"Engineering","title":"Adding Real Time Analytics to a Supabase Application With ClickHouse","shortDescription":"Read about how to add real time analytics powered by ClickHouse to your Supabase application with the Foreign data wrapper","content":"\u003ciframe width=\"768\" height=\"432\" src=\"https://www.youtube.com/embed/LDWEsw41Zko\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen\u003e\u003c/iframe\u003e\n\n## Introduction\n\nAt ClickHouse, we are often asked how ClickHouse compares to Postgres and for what workloads it should be used. With our friends at Supabase [introducing Foreign Data Wrappers](https://supabase.com/blog/postgres-foreign-data-wrappers-rust) (FDW) for their Postgres offering, we decided to use the opportunity to revisit this topic with a webinar early last week. As well as explaining the differences between an OLTP database, such as Postgres, and an OLAP database, such as ClickHouse, we explored when you should use each for an application. And what better way to convey these ideas than with a demo that uses both capabilities?\n\nIn this blog post, we show how we enriched an application built with Supabase with real-time analytics powered by ClickHouse and integrated using Supabase’s’ FDW. This demonstrates how users can query ClickHouse from a Supabase instance and thus integrate real-time analytics into an application without leaving the Supabase ecosystem and its familiar interfaces. We remind users of the [difference between OLAP and OLTP](https://clickhouse.com/resources/engineering/oltp-vs-olap) and when each is the most appropriate choice when building an application. Finally, we touch on some FDW best practices and some options for pushing transactional data to ClickHouse when analytics need to be updated.\n\nWe have made the code [available for our demo](https://github.com/ClickHouse/HouseClick). Please excuse any rough edges and use for inspiration only.\n\n\u003e Note: Supabase’s Clickhouse Wrapper is currently in Alpha and some functionality in this article might not be available for your Supabase project. If you need access, reach out to growth@supabase.com.Note: Supabase’s Clickhouse Wrapper is currently in Alpha and some functionality in this article might not be available for your Supabase project. If you need access, reach out to growth@supabase.com.\n\n## OLTP vs OLAP\n\nOLTP, or _online transactional processing_ databases, are designed to manage _transactional_ information. \n\nThe primary objective of these databases is to ensure that an engineer can submit a block of updates to the database and be sure that it will — in its entirety — either succeed or fail.\n\nTo demonstrate the utility of this, imagine you’re a bank, and you want to record a $10 wire transfer from one account (origin) to another (destination). Accomplishing this takes two steps:\n\n1. Deduct $10 from the origin’s account balance\n2. Add $10 to the destination’s account balance \n\nIt’s important that these two updates occur together or not at all. Otherwise, the bank may be left in a state where $10 is unaccounted for! (In the case where #1 is successful, and #2 fails).\n\nThese types of _transactional_ guarantees are the main focus of OLTP databases. \n\nGiven these requirements, OLTP databases typically hit performance limitations when used for analytical queries over large datasets.\n\nOLAP, or _online analytical processing_ databases, are designed to meet those needs — to manage _analytical_ workloads. \n\nThe primary objective of these databases is to ensure that engineers can efficiently query and aggregate over vast datasets. _Real-time_ OLAP systems like ClickHouse allow this analysis to happen as data is ingested in real-time.\n\n## When is each most appropriate?\n\nOLTP databases excel when queries aim to retrieve a specific set of rows, potentially accessing a higher number of columns, and when data is subject to frequent updates that must be executed in real-time. By optimizing for high-speed transactions and concurrency, OLTP databases permit data to be accessed and modified simultaneously without conflicts. These access patterns make OLTP databases ideal for storing the **data that maintains the application state** and enables user interactivity. Postgres’ ability to respond rapidly despite high query concurrency under these workloads has made it the OLTP database of choice for applications, powering a wide range of use cases from e-commerce and financial trading platforms to customer service systems.\n\nConversely, OLAP databases, such as ClickHouse, excel at **analytical queries** that access many rows but few columns. These queries typically summarize billions (if not trillions) of rows using GROUP BY operations and analytical functions over several very large tables. These workloads are typically associated with larger datasets where query times of less than 50ms are still required. In order to deliver this high performance, OLAP databases typically sacrifice certain functionality such as transactions, support for limited query concurrency, update support, and requiring users to perform inserts in batches.\n\nWhile ClickHouse can be categorized as an OLAP database, it also supports real-time analytical workloads, where query concurrency is typically much higher. This makes ClickHouse perfect for adding analytics to your application!\n\n## A real-world(ish) example \n\nTo help users understand these principles, we decided to build an application utilizing each database appropriately. For any good demo, we need a dataset relatable to a real-world use case. The UK house price dataset, while moderately sized at around 30 m rows, may be useful to an estate agency business listing its properties online. This dataset has a row for every house sold in the UK since 1990. What if we could use this dataset as the basis for generating houses for sale but expose the full dataset in the form of analytics to assist users in their decision-making process when viewing a property? Never wanting to miss the opportunity for a good pun, HouseClick was born…”the fastest place to buy and sell your home” obviously.\n\n![house_click.png](/uploads/house_click_25ac1ed3ce.png)\n\n## Choosing technologies\n\nAn estate agency business is not too dissimilar from an e-commerce site with respect to data access patterns - it needs to list products, provide rich functionality for searching, and the ability to retrieve specific products by id for detailed viewing. For this, an OLTP database is perfect. With some familiarity with Postgres and not waiting to host a database ourselves, Supabase was the perfect solution for our application data - specifically, our current properties for sale.\n\n[Supabase](https://supabase.com) offers a real-time database that allows developers to store and sync data across multiple devices in real time. Simply put an OSS Firebase alternative. It also provides various backend services, including a serverless platform for running functions and hosting static assets.\n\nWith a rich set of clients that don’t require the [user to write SQL](https://supabase.com) (SQL-injection concerns addressed), as well as row-level security to limit anonymous users to read access, this provided the perfect solution to storing our current list of around 1000 properties for sale.\n\nWith our historical data loaded in ClickHouse Cloud for analytics, we next simply need to choose a web framework. With a basic familiarity of React and not wanting to spend significant time researching possible stacks, I yielded to advice from those at ClickHouse who do web development for more than creating fake estate agency businesses - NextJS with Tailwinds seemed to be the general recommendation. With three days assigned, I needed to find some actual properties for sale…\n\n## Generating data\n\nWhile the historical house price dataset provides us with some basic information regarding the address, price, and date a house was sold, it lacked the information we needed to build a rich, engaging estate agency website - missing titles, descriptions, and images.\n\n```sql\nSELECT *\nFROM uk_price_paid\nLIMIT 1\nFORMAT Vertical\n\nRow 1:\n──────\nprice: \t1\ndate:  \t1998-06-22 00:00:00\npostcode1: CW11\npostcode2: 1GS\ntype:  \tdetached\nis_new:\t0\nduration:  leasehold\naddr1: \t15\naddr2:\nstreet:\tPENDA WAY\nlocality:\ntown:  \tSANDBACH\ndistrict:  CHESHIRE EAST\ncounty:\tCHESHIRE EAST\n\n1 row in set. Elapsed: 0.022 sec. Processed 57.34 thousand rows, 4.31 MB (2.64 million rows/s., 198.59 MB/s.)\n```\n\nSelecting 1000 random properties, we projected a 2023 valuation based on their original date of sale and price using the price increase for their property type in their respective postcode - adding a little variance to ensure some houses seemed better deals than others.\n\nUsing this price and the properties area, we tried to project a house size i.e. number of bedrooms, using some [very crude heuristics](https://github.com/ClickHouse/HouseClick/blob/865a31cf0c7f7b0568151dcbcb134a78a284db05/scripts/generate_data.py#L33-L67) - admittedly, this was far too simple and later produced some amusing results, especially when combined with images.\n\nFor descriptions, titles and a list of possible house features we turned to the Open AI’s [Text Completion API](https://platform.openai.com/docs/guides/completion) and ChatGPT-3 `text-davinci-003` model. This cost around $10 for all 1000 properties.\n\n![chat_gpt.png](/uploads/chat_gpt_b9fb3f3011.png)\n\nSatisfied with our AI-based estate agent, we just needed images. While AI-generated images were viable, using the [DALL-E model](https://openai.com/product/dall-e-2), they tended to produce fairly unengaging images.\n\n![ai_houses.png](/uploads/ai_houses_c80e41feca.png)\n\nArmed with our titles and descriptions, the [Bing Image API ](https://www.microsoft.com/en-usbing/apis/bing-image-search-api)generated more appealing images for a demo. Combined with rather optimistic pricing, this rather crude method admittedly led to some amusing results.\n\n![house_click_house.png](/uploads/house_click_house_fc55009fcb.png)\n\nNot needing to sell the properties and dreaming of buying a 24-bedroom house in Windsor for £460,000, we combined the above techniques into a single script and generated our 1000 properties as a CSV.\n\n## Building rich experiences easily with Supabase\n\nAside from taking away the hassle of deploying and managing Postgres, Supabase provides a number of features that notably accelerated development:\n\n* Allows users to apply access policies permitting only read access for users with an anonymous token. This meant for client-side rendered pages, such as search, we could safely query the database from the browser - avoiding needing to write server-side API endpoints.\n* A simple data loading API which allowed us to load our listings with zero code (we also wrote a [convenience script](https://github.com/ClickHouse/HouseClick/blob/main/scripts/import_data.py) but this got us started quickly).\n* Full-text search capabilities using [Postgres indexes](https://supabase.com/docs/guides/database/full-text-search) avoid the need for a dedicated search engine such as Elasticsearch.\n* A rich Javascript client that made formulating SQL queries easy using method chaining. This was particularly useful when combining filters and sorting in a simple search UI e.g.\n\n```javascript\nconst { data, error } = await supabase.from(table).select('id,type,price,town,district,postcode1,postcode2,duration,urls,description,title,rooms,sold,date').order('date', {ascending: false}).limit(4)\n```\n\n![clickhouse_search.png](/uploads/clickhouse_search_8e70dda48b.png)\n\n## Adding Analytics\n\nUnlike our current listings, our historical price data is based on real UK house sales. Loading this into ClickHouse takes only two commands, as [specified in our documentation](https://clickhouse.com/docs/en/getting-started/example-datasets/uk-price-paid).\n\nWith the dataset loaded, we need to choose some analytics that might be useful to a user buying a house. On viewing a specific property, maybe purchasers are interested in:\n\n* The historical prices for the area and how they compare to the national average\n* How much has the area's postcode increased over the last 30 yrs relative to the average\n* When are houses bought and sold in the area? \n* How does the area compare to the rest of the country, i.e., what percentile does it lie in the price distribution?\n\nThese are simple to formulate in ClickHouse SQL thanks to the support for [functions that make analytical queries](https://clickhouse.com/docs/en/sql-reference/aggregate-functions/reference) easy to write. The query below queries for the average house price for the postcode 'SL4' over the last 30 yrs, by month, as well as the average price for the whole country.\n\n```sql\nSELECT\n\ttoStartOfMonth(date) AS month,\n\tround(avgIf(price, postcode1 = 'SL4')) AS filter_price,\n\tround(avg(price)) AS avg\nFROM uk_price_paid\nGROUP BY month\nORDER BY month ASC\nLIMIT 10\n\n┌──────month─┬─filter_price─┬───avg─┐\n│ 1995-01-01 │   \t123855 │ 68381 │\n│ 1995-02-01 │   \t103594 │ 65646 │\n│ 1995-03-01 │   \t118140 │ 65750 │\n│ 1995-04-01 │   \t113352 │ 67835 │\n│ 1995-05-01 │   \t116996 │ 67079 │\n│ 1995-06-01 │   \t107411 │ 67990 │\n│ 1995-07-01 │   \t110651 │ 70312 │\n│ 1995-08-01 │   \t123354 │ 70601 │\n│ 1995-09-01 │   \t111195 │ 68368 │\n│ 1995-10-01 │   \t128282 │ 67573 │\n└────────────┴──────────────┴───────┘\n\n10 rows in set. Elapsed: 0.303 sec. Processed 28.11 million rows, 290.73 MB (92.90 million rows/s., 960.73 MB/s.)\n```\n\nAfter formulating a number of these queries, we needed a visualization method. With the [Clickhouse Javascript client](https://clickhouse.com/docs/en/integrations/language-clients/nodejs) supporting the return of results in JSONEachRow format, [Apache ECharts](https://echarts.apache.org) seemed ideal, given its [configuration utilizes simple JSON objects](https://echarts.apache.org/examples/en/index.html#chart-type-bar). With some simple map functions, we were able to achieve reasonable results with minimal effort. The above query translates to a bar and line.\n\n![price_over_time.png](/uploads/price_over_time_1a8c8ec568.png)\n\nAdding these to the view for a specific property provided an obvious way to introduce these analytics. As well as allowing the user to obtain an overview of the properties’ postcode, we allow the filter to be changed such that data is aggregated from the perspective of town and district.\n\n![house_click.gif](/uploads/house_click_300bd19deb.gif)\n\n## Foreign Data Wrappers - a single endpoint\n\n![initial_architecture_supabase_clickhouse.png](/uploads/initial_architecture_supabase_clickhouse_699d74d48f.png)\n\nInitially we added analytics to our application by querying ClickHouse directly using the JS client, to deliver the architecture shown above. This is fine; it's fast and works. However, suppose we aspired to communicate through a single interface and not burden our developers with having to maintain multiple connections and learn two libraries and syntaxes. To allow this, Supabase provides [Foreign Data Wrappers](https://supabase.com/blog/postgres-foreign-data-wrappers-rust) (FDW). These allow Postgres to connect to external systems such as ClickHouse, querying the data in place. \n\n![fdw_architecture_supabase_clickhouse.png](/uploads/fdw_architecture_supabase_clickhouse_f502c44b24.png)\n\nWhereas other similar technologies may aim to pull the datasets into the query engine to perform filtering and aggregations, FDWs emphasize relying on an extract-only methodology where the query is pushed down and aggregation and filter performed in the target data source. Only the results are then returned to Postgres for display. This approach has some distinct advantages with respect to ClickHouse. With billions, if not trillions, of rows in ClickHouse, pulling the source data into Postgres is infeasible. By pushing the query down and allowing ClickHouse to do what it does best (aggregate very large datasets quickly), the FDW can scale by minimizing transferred data while still exposing real-time analytics in an end-user application through a consistent interface where developers aren't required to learn a new tool or language client.\n\nOther possible benefits of this approach include:\n\n* Providing an interface aggregator similar to GraphQL engines but through a language, all developers are familiar with - SQL.\n* Offloading workloads which are inappropriate for Postgres, e.g., analytics to queries to specialized data stores such as ClickHouse or even APIs such as OpenAI.\n* By not moving the data, it is always in sync with the underlying data stores. Developers don’t need to worry about maintaining complex ETL pipelines.\n* Transactional/operational data can be joined with analytics data in ClickHouse, exposing new features such as in our HouseClick example.\n* Reduction of infrastructure to manage as well as savings in setup time and bandwidth.\n\nAdding a Foreign ClickHouse table to Supabase is trivial. Firstly we need to enable the foreign data wrapper for ClickHouse by installing the extension and specifying the handler and validator.\n\n```sql\ncreate extension if not exists wrappers;\ncreate foreign data wrapper clickhouse_wrapper\n handler click_house_fdw_handler\n validator click_house_fdw_validator;\n```\n\nOnce installed, we can create a connection to ClickHouse. Note that the below example passes the credentials in plain text. Supabase supports more secure [storage of credentials using pgsodium and Vault](https://supabase.github.io/wrappers/clickhouse/).\n\n```sql\ncreate server clickhouse_server\n  foreign data wrapper clickhouse_wrapper\n  options (\n\tconn_string 'tcp://default:\u003cpassword\u003e@\u003chost\u003e:9440/default?connection_timeout=30s\u0026ping_before_query=false\u0026secure=true'\n  );\n```\n\nIf using ClickHouse Cloud, note the password and host on cluster creation and use the secure port 9440.\n\n![clickhouse_cloud.png](/uploads/clickhouse_cloud_e47f0c42c1.png)\n\n```sql\ncreate foreign table people (\n  \u003cschema\u003e\n)\n  server clickhouse_server\n  options (\n\ttable '\u003cclickhouse_table\u003e'\n  );\n```\n\nBefore we do this for our HouseClick application, let's establish a few best practices when using the FDW with ClickHouse.\n\n### Best practices\n\nWherever possible, Supabase users should ensure query push-down occurs when using the ClickHouse FDW. This means that the FDW runs the query on ClickHouse, instead of pulling the dataset into Postgres and aggregating locally. This is essential for performance reasons, as ClickHouse can often perform the query far more efficiently than Postgres - even the transfer of data of hundreds of billions of rows is typically infeasible and would take hours. Push-down is also useful for security reasons, as ClickHouse can enforce access control. While the FDW supports limited push-down support as of the time of writing, users can ensure this occurs by creating parameterized views in ClickHouse and exposing these as foreign tables in Postgres via the wrapper.\n\n[Parameterized views](https://clickhouse.com/docs/en/sql-reference/statements/create/view#parameterized-view) are similar to normal views but can be created with parameters that are not resolved immediately but at query time. These views can be used with table functions, which specify the name of the view as the function name and the parameter values as its arguments. The primary concept here is to encapsulate the complexity of a query (and a specific visualization) within a view ClickHouse side and ensure any large complex processing is done at the source, thus guaranteeing push down. \n\nSuppose we have the following query, which computes the ratio of freehold to leasehold properties for a specific postcode (in this case, SL4). For non-UK readers, leasehold and freehold are simply different ownership types [distinguished by ownership of the underlying land.](https://www.halifax.co.uk/mortgages/help-and-advice/freehold-vs-leasehold.html)\n\n```sql\nSELECT\n\tduration AS name,\n\tcount() AS value\nFROM default.uk_price_paid\nWHERE postcode1 = 'SL4'\nGROUP BY duration\n\n┌─name──────┬─value─┐\n│ leasehold │  6469 │\n│ freehold  │ 15683 │\n└───────────┴───────┘\n\n2 rows in set. Elapsed: 0.114 sec. Processed 28.11 million rows, 75.52 MB (247.22 million rows/s., 664.11 MB/s.)\n```\n\nWe use this specific query to drive a pie chart visual.\n\n![pie_chart.png](/uploads/pie_chart_9c7b6ed5e0.png)\n\nGiven that our interface supports filtering by postcode, town, and district, we need a way to pass these to our view and underlying query so that only one value is ever passed. We do this by constructing an OR clause. When matching on a value, e.g., postcode, we pass invalid non-matching values for the other columns. Below we create the parameterized view `sold_by_duration` and illustrate using the view to obtain the same result as above.\n\n```sql\n\nCREATE VIEW sold_by_duration AS\nSELECT\n\tduration AS name,\n\tcount() AS value\nFROM default.uk_price_paid\nWHERE (postcode1 = {_postcode:String}) OR (district = {_district:String}) OR (town = {_town:String})\nGROUP BY duration\n\n\nSELECT *\nFROM sold_by_duration(_postcode = 'SL4', _district = 'X', _town = 'X')\n\n┌─name──────┬─value─┐\n│ leasehold │  6469 │\n│ freehold  │ 15683 │\n└───────────┴───────┘\n\n2 rows in set. Elapsed: 0.230 sec. Processed 28.11 million rows, 201.23 MB (122.00 million rows/s., 873.21 MB/s.)\n```\n\nNote that we incur a performance penalty here as the town and district fields have to be also matched. Future improvements may allow us to use these views more [succinctly and efficiently](https://github.com/ClickHouse/ClickHouse/issues/49661).\n\nConnecting this view to a foreign table in Supabase requires some DDL commands to Postgres. Below we create a foreign table, `sold_by_duration`, that queries a view of the same name in ClickHouse, using the connection created previously. Note how the table allows the parameters `postcode`, `district`, and `town` to be specified.\n\n```sql\n\ncreate foreign table sold_by_duration (\n  name text,\n  value bigint,\n  postcode text, -- parameter column, used for input parameter,\n  district text,\n  town text\n)\nserver clickhouse_server\n  options (\n\ttable '(select * from sold_by_duration(_postcode=${postcode1}, _district=${district}, _town=${town}))',\n\trowid_column 'name'\n);\n```\n\nFrom Postgres, we can now query this table using the `psql` client, applying the filters using a standard WHERE clause.\n\n```sql\n\npostgres=\u003e select name, value from sold_by_duration where postcode1='SL4' AND district='X' AND town='X';\n   name\t| value\n-----------+-------\n leasehold |  6469\n freehold  | 15683\n(2 rows)\n```\n\n### Using the FDW\n\nUtilizing a foreign table from the Supabase client is no different than using any other table, allowing us to query ClickHouse transparently. Prior to creating the foreign table, our piechart was powered by the following function using the Clickhouse JS client. Here `condition` is simply the filter being applied, e.g., `postcode1=SL4.`\n\n```javascript\nasync function soldByDuration(condition) {\n   const results = await clickhouse.query({\n       query: `SELECT duration as name,count() as value FROM uk_price_paid WHERE ${condition} GROUP BY duration`,\n       format: 'JSONEachRow',\n   })\n   return await results.json()\n}\n```\n\nWith the foreign table created, we can import and configure the [Supabase JS client](https://supabase.com/docs/reference/javascript/introduction) with the [anonymous public token](https://supabase.com/docs/learn/auth-deep-dive/auth-deep-dive-jwts). Our `soldbyDuration` function is replaced with a Supabase implementation - not the absence of any SQL.\n\n```javascript\nimport { createClient } from '@supabase/supabase-js'\n\nconst supabase = createClient('https://sfzygnnbtbttbtpiczck.supabase.co', '\u003canon key\u003e')\n\nconst filter_config = {\n   'postcode': {\n       column: 'postcode1'\n   },\n   'town': {\n       column: 'town'\n   },\n   'district': {\n       column: 'district'\n   },\n}\n\nasync function soldByDuration_fdw(filters) {\n   const default_value = 'X'\n   let query = supabase.from('sold_by_duration').select('name, value')\n   for (let k in filter_config) {\n       let filter = filters.filter(f =\u003e f.column == filter_config[k].column)\n       query = filter.length \u003e 0 ? query.eq(filter[0].column, filter[0].value): query.eq(filter_config[k].column, default_value)\n   }\n   const { error, data } = await query\n   return data\n}\n```\n\nOur results are returned in the same format, so our changes are minimal. The `filter_config` object simply provides a mapping between our filter names and columns.\n\n## Pushing data to ClickHouse\n\nSuppose that HouseClick sells a property. One of the benefits of using Postgres, our application data, is the ability to update rows transactionally. A property can be marked as sold with a simple update:\n\n```sql\nUPDATE uk_house_listings\nSET sold = True,\n   sold_date = '2023-05-01'\nWHERE id = '99';\n```\n\nHere we mark the property with id 99 as sold on the 1st of May.\n\nWith properties selling, we may wish to update our historical analytical data in ClickHouse periodically. We can achieve this in a number of ways:\n\n* The FDW for ClickHouse is bi-directional. We can push rows to ClickHouse with a simple `insert into select` statement. We could use the `sold_date` to identify recently sold properties. This query could then be periodically scheduled using [pg_cron](https://supabase.com/docs/guides/database/extensions/pgcron) to ensure our analytical data is kept current. Note this would require our ClickHouse table to have an identifying id column since the FDW requires a `rowid_column` in order for [updates to be supported](https://supabase.github.io/wrappers/clickhouse/).\n* Using the [postgresql table function](https://clickhouse.com/docs/en/sql-reference/table-functions/postgresql) in ClickHouse, we can pull rows from the Supabase instance. Below we utilize this to pull sold properties with a sold_date greater than or equal to the 1st of May, inserting these into our `uk_price_paid` table. This approach would require us to schedule our import periodically, e.g., using a cron job.\n\n```sql\nINSERT INTO uk_price_paid SELECT\n   price,\n   sold_date AS date,\n   postcode1,\n   postcode2,\n   type,\n   is_new,\n   duration,\n   addr1,\n   addr2,\n   street,\n   locality,\n   town,\n   district,\n   county\nFROM postgresql('db.sfzygnnbtbttbtpiczck.supabase.co', 'postgres', 'uk_house_listings', 'migration', 'clickhouse')\nWHERE (sold = true) AND (sold_date \u003e= '2023-05-01')\n```\n\nThis completes our architecture by introducing bi-directionality in the data flow between ClickHouse and Supabase.\n\n![final_architecture_clickhouse_supabase.png](/uploads/final_architecture_clickhouse_supabase_76d5ff11d8.png)\n\nFor further details on the postgresql table function see our [recent blog series](https://clickhouse.com/blog/migrating-data-between-clickhouse-postgres).\n\n## Conclusion \u0026 Next Steps\n\nIn this blog post, we've explored the difference between an OLTP and OLAP database, specifically Postgres and ClickHouse, and how the former can be used to power an application's state and transactional functionality. In contrast, the latter can be used to provide real-time analytics. In addition to showing how this might be exposed by querying ClickHouse directly, we've utilized Supabase's Foreign Data Wrapper functionality to expose ClickHouse-powered analytics through a single familiar interface before touching on how users might update their analytics data using subsets of transactional rows.\n","createdAt":"2023-05-08T15:42:36.674Z","updatedAt":"2026-01-21T12:56:57.703Z","publishedAt":"2023-05-15T13:34:23.237Z","slug":"adding-real-time-analytics-to-a-supabase-application","date":"2023-05-15","keywords":null,"StagingOnly":null,"ShowCloudCTAHeader":null,"ShowCloudCTAFooter":null,"reading_time":21,"theme":"Guide","use_case":"Real-time Analytics","canonical_url":null,"table_contents_headers":null,"ListOnBlogs":null,"enableSidebarGlobalCta":null,"reading_time_override":null,"thumbnailPng":{"id":1225,"name":"supa clickhouse.png","alternativeText":null,"caption":null,"width":1200,"height":630,"formats":{"large":{"ext":".png","url":"/uploads/large_supa_clickhouse_1115607080.png","hash":"large_supa_clickhouse_1115607080","mime":"image/png","name":"large_supa clickhouse.png","path":null,"size":39.46,"width":1000,"height":525},"small":{"ext":".png","url":"/uploads/small_supa_clickhouse_1115607080.png","hash":"small_supa_clickhouse_1115607080","mime":"image/png","name":"small_supa clickhouse.png","path":null,"size":15.95,"width":500,"height":263},"medium":{"ext":".png","url":"/uploads/medium_supa_clickhouse_1115607080.png","hash":"medium_supa_clickhouse_1115607080","mime":"image/png","name":"medium_supa clickhouse.png","path":null,"size":25.79,"width":750,"height":394},"thumbnail":{"ext":".png","url":"/uploads/thumbnail_supa_clickhouse_1115607080.png","hash":"thumbnail_supa_clickhouse_1115607080","mime":"image/png","name":"thumbnail_supa clickhouse.png","path":null,"size":6.36,"width":245,"height":129}},"hash":"supa_clickhouse_1115607080","ext":".png","mime":"image/png","size":6.17,"url":"/uploads/supa_clickhouse_1115607080.png","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2023-05-10T09:59:30.931Z","updatedAt":"2023-05-10T09:59:30.931Z"},"author":{"id":883,"name":"Dale McDiarmid","profileLink":null}},{"id":119,"category":"Engineering","title":"ClickHouse and PostgreSQL - a Match Made in Data Heaven - part 1","shortDescription":"Read about how PostgreSQL and ClickHouse complement each other and how data can be easily moved between them using native ClickHouse functions.","content":"\u003e While many of the approaches in this blog post remain valid, the content is from 2023. For the latest guidance on migrating data from Postgres to ClickHouse, we recommend exploring newer resources - primarily how ClickPipes, ClickHouse Cloud's managed data ingestion pipeline, now supports ingesting data into [ClickHouse from Postgres using CDC](https://clickhouse.com/docs/integrations/clickpipes/postgres).\n\n![clickhouse-postgresql.png](/uploads/large_clickhouse_postgresql_1d123677ea.png)\n\n## Introduction\n\nPostgreSQL and ClickHouse represent the best of class concerning open-source databases, each addressing different use cases with their respective strengths and weaknesses. Having recently enabled our PostgreSQL (and MySQL) integrations in ClickHouse Cloud, we thought we’d take the opportunity to remind users of how these powerful integrations can be used with ClickHouse. While we focus on Postgres, all functions have their equivalent MySQL versions and should be easily derived.\n\nIn the first part of this series, we look at the PostgreSQL function and table engine. A second post will explore the database engine and demonstrate how Postgres can be used in conjunction with ClickHouse dictionaries.\n\nIf you want to dive deeper into these examples, ClickHouse Cloud is a great starting point - spin up a cluster using a free trial, load the data, let us deal with the infrastructure, and get querying!\n\n**Interested in trying the Postgres integration in ClickHouse Cloud?[ Get started instantly](https://clickhouse.cloud/signUp?loc=blog\u0026ajs_aid=b44bb600-929d-4c35-9f15-21edd1872094) with $300 free credit for 30 days.**\n\nWe use a development service in ClickHouse Cloud – a production service could be used, either is fine. For our Postgres instance, we utilize [Supabase](https://supabase.com/) which offers a generous free tier sufficient for our examples.\n\nSupabase offers significantly more than just a Postgres database and is a full Firebase alternative with Authentication, instant APIs, Edge Functions, Realtime subscriptions, and Storage. If you want to build a real application using the data in this post, Supabase will accelerate its development and deployment.\n\n## Complementary\n\nPostgreSQL, also known as Postgres, is a free and open-source relational database management system focused on extensibility, SQL compliance, and ACID properties via transactions. As the world’s most [popular OSS OLTP (Online transaction processing) database](https://db-engines.com/en/ranking) , it is used for use cases where data is highly transactional and there is a need to support thousands of concurrent users.\n\nClickHouse is an open-source column-oriented OLAP (Online analytical processing) database for real-time analytical workloads. With a focus on supporting lightning-fast analytical queries, it typically serves use cases such as real-time analytics, observability, and data warehousing.\n\nA successful architectural pattern using ClickHouse in conjunction with PostgreSQL to power an analytics “speed layer” has recently emerged. In this paradigm, PostgreSQL is used as the transactional source of truth and serves the operational use case where row-based operations are dominant. Advanced analytical queries, however, are better served via ClickHouse leveraging its column-oriented model to answer complex aggregates on the millisecond scale. This [complementarity](https://thenewstack.io/two-sizes-fit-most-postgresql-and-clickhouse/) relationship benefits greatly from the tight integration that exists between the two OSS technologies.\n\n![postgres-clickhouse-integration.png](/uploads/postgres_clickhouse_integration_7fb994367a.png)\n\n\n## The business case \u0026 dataset\n\nScenario: we are running a property listing website serving thousands of users. Prices can be updated and/or rows deleted as properties are delisted or reduced in price. This represents a great use case for Postgres, which will hold our source of truth for the data. Our imaginary business would also like to perform analytics on this data, creating a need to move data between Postgres and ClickHouse.\n\nFor our examples, we use relatively small instances of Postgres and ClickHouse: the developer tier in ClickHouse Cloud (Up to 1 TB storage and 16 GB total memory) and the [free tier in Supabase](https://supabase.com/pricing). The latter limits the database size to 500 MB. Therefore, we have selected a dataset of moderate size that fits our business use case and these instance sizes: the [UK house price dataset](https://clickhouse.com/docs/en/getting-started/example-datasets/uk-price-paid). Used throughout our documentation, this largely fits these requirements with only 28m rows. Each row represents a house sale in the UK in the last 20 yrs, with fields representing the price, date, and location. A full description of the fields can be found [here](https://www.gov.uk/guidance/about-the-price-paid-data#explanations-of-column-headers-in-the-ppd).\n\nWe distribute this dataset as Postgres-compatible SQL, ready for insert, downloadable from [here](https://datasets-documentation.s3.eu-west-3.amazonaws.com/uk-house-prices/postgres/uk_prices.sql.tar.gz).\n\n## Loading the data\n\nOnce you’ve signed up to Supabase, create a new project under the free tier with an appropriately secure password and grab the database endpoint from the settings.\n\n![supabase-db-settings.png](/uploads/supabase_db_settings_7d78deb846.png)\n\nFor our examples, we execute all our queries using the `psql` client. Supabase also offers a web client for those seeking a life away from the terminal. Our Postgres schema is shown below. We also create a few indexes which our subsequent queries should intuitively be able to utilize.\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nCREATE TABLE uk_price_paid\n(\n   id integer primary key generated always as identity,\n   price INTEGER,\n   date Date,\n   postcode1 varchar(8),\n   postcode2 varchar(3),\n   type varchar(13),\n   is_new SMALLINT,\n   duration varchar(9),\n   addr1 varchar(100),\n   addr2 varchar(100),\n   street varchar(60),\n   locality varchar(35),\n   town varchar(35),\n   district varchar(40),\n   county varchar(35)\n)\n\npsql -c \"CREATE INDEX ON uk_price_paid (type)\"\npsql -c \"CREATE INDEX ON uk_price_paid (town)\"\npsql -c \"CREATE INDEX ON uk_price_paid (extract(year from date))\"\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\n![supabase-load.gif](/uploads/supabase_load_fbf2381660.gif)\n\n## Some basic analytical queries\n\nBefore loading our data in ClickHouse, let's remind ourselves why we might need our analytical workloads outside of Postgres. Note the timings of the following queries. The results presented are the fastest of five executions. We have also attempted to optimize these to exploit the indexes where possible but welcome further suggestions!\n\n### Average price per year for flats in the UK\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\npsql -c \"\\timing\" -c \"SELECT\n\textract(year from date) as year,\n\tround(avg(price)) AS price\nFROM uk_price_paid\nWHERE type = 'flat'\nGROUP BY year\nORDER BY year\"\n\n year | price\n------+--------\n 1995 |  59004\n 1996 |  63913\n…\n 2021 | 310626\n 2022 | 298977\n(28 rows)\n\nTime: 28535.465 ms (00:28.535)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nThis is slower than expected. The `EXPLAIN` [for this query](https://gist.github.com/gingerwizard/1488c3e9701e0ff4f952bfff9250e656), indicates that the type index is not utilized, resulting in a full table scan. The reason for this is query planner relies on tables statistics. The cardinality of the type column is very low - 5 values, meaning 6.3M rows have a `flat` value out of 34M  ~1/6th of the total dataset. Because `type='flat'` rows are distributed in all data blocks (around 24 rows per block), the probability of having `flat` value in any single block is very high (it’s 1/6th with 24 rows per block). The query planner therefore determines a parallel sequential scan will be more efficient than reading the index (and then searching for relevant rows in the data).\n\nMy colleague [Vadim Punski](https://github.com/vadimp) actually proposed a way to speed up this query considerably. We’ve posted the solution [here](https://gist.github.com/gingerwizard/429dc2faed3468c2016e5a069939b90a) but excluded as it represents a rather poor use of Postgres and will result in a large storage footprint. The changes to the table schema will also not complete on Supabase’s free tier due to the 120s query timeout.\n\n### Most expensive postcodes in a city\n\nFrom our above query we know that Postgres won’t use indexes if a linear scan is cheaper, due to a filter clause value existing in most blocks. If we filter by a less common city e.g. Bristol, the index can be exploited and the query performance improvement is dramatic.\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\npsql -c \"\\timing\" -c \"SELECT\n      postcode1,\n      round(avg(price)) AS price\nFROM uk_price_paid WHERE town='BRISTOL'\nGROUP BY postcode1\nORDER BY price DESC LIMIT 10\"\n\n postcode1 | price\n-----------+--------\n BS1   \t| 410726\n BS19  \t| 369000\n BS18  \t| 337000\n BS40  \t| 323854\n BS9   \t| 313248\n BS8   \t| 301595\n BS41  \t| 300802\n BS6   \t| 272332\n BS35  \t| 260563\n BS36  \t| 252943\n(10 rows)\n\nTime: 543.364 ms\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nThe [associated query plan](https://gist.github.com/gingerwizard/4c6681954976d0fd5f056d77488333ac) shows use of our index. If you change the city here (e.g. to London) Postgres may utilise a sequential scan, depending on the number of properties sold in the target city.\n\n### Postcodes in London with the largest percentage price change in the last 20 yrs\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\npsql -c \"\\timing\"  -c \"SELECT med_2002.postcode1, median_2002, median_2022, round(((median_2022 - median_2002)/median_2002) * 100) AS percent_change FROM (\n  SELECT postcode1, PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_2002 FROM uk_price_paid WHERE town = 'LONDON' AND extract(year from date) = '2002' GROUP BY postcode1\n\n) med_2002 INNER JOIN (\n  SELECT postcode1, PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_2022 FROM uk_price_paid WHERE town = 'LONDON' AND extract(year from date) = '2022' GROUP BY postcode1\n) med_2022 ON med_2002.postcode1=med_2022.postcode1 ORDER BY percent_change DESC LIMIT 10\"\n\n postcode1 | median_2002 | median_2022 | percent_change\n-----------+-------------+-------------+----------------\n EC3A  \t|  \t260000 |\t16000000 |       \t6054\n SW1A  \t|  \t525000 |\t17500000 |       \t3233\n EC2M  \t|  \t250000 |   4168317.5 |       \t1567\n EC3R  \t|  \t230000 | \t2840000 |       \t1135\n W1S   \t|  \t590000 | \t6410000 |        \t986\n WC2A  \t|  \t255000 | \t2560000 |        \t904\n W1K   \t|  \t550000 | \t5000000 |        \t809\n W1F   \t|  \t280000 | \t2032500 |        \t626\n WC1B  \t|  \t390000 | \t2205000 |        \t465\n W1J   \t|  \t497475 | \t2800000 |        \t463\n(10 rows)\n\nTime: 8903.676 ms (00:08.904)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nThis query is actually quite performant. This query performs a [bitmap scan](https://www.cybertec-postgresql.com/en/postgresql-indexing-index-scan-vs-bitmap-scan-vs-sequential-scan-basics/) on both the `town` and `extract(year from date)` indexes. This significantly reduces the amount of data needed to be read, [as shown by the query plan](https://gist.github.com/gingerwizard/97dba6dc9ace47fbd7b8e53bdf8d1887), which speeds up the query.\n\nAs ClickHouse experts, we welcome further improvements to these queries to speed them and alternatives to simply forcing index usage!\n\nWe’ll later perform these queries in our ClickHouse developer instance. This isn’t a fair benchmark due to differences in the underlying hardware and available resources. We could also exploit other PostgreSQL features to optimize these queries further, e.g., [CLUSTER](https://www.postgresql.org/docs/current/sql-cluster.html). However, we should see a dramatic improvement demonstrating why we might want to move this workload type to ClickHouse.\n\n## Querying Postgres from ClickHouse\n\nWe have a few ways to access data in Postgres with ClickHouse:\n\n* Utilise the [postgresql](https://clickhouse.com/docs/en/sql-reference/table-functions/postgresql) function. This creates a connection per query and streams into ClickHouse. Simple WHERE clauses are pushed down where possible (e.g. utilising a ClickHouse-specific function prevents pushdown) to identify the matching rows. Once the matching rows are returned, aggregations, JOINs, sorting, and LIMIT clauses are performed in ClickHouse.\n* Create a table in ClickHouse using the[ PostgreSQL table engine](https://clickhouse.com/docs/en/engines/table-engines/integrations/postgresql/#creating-a-table). This allows an entire Postgres table to be mirrored in ClickHouse. Implementation-wise, this is no different from the [postgresql](https://clickhouse.com/docs/en/sql-reference/table-functions/postgresql) function, i.e., the selection of rows is pushed down where possible, but it simplifies query syntax considerably - we can use the table like any other within ClickHouse.\n* Create a database using the [PostgreSQL database engine](https://clickhouse.com/docs/en/engines/database-engines/postgresql). In this case, we mirror the entire database and can utilize all of its respective tables. This also allows us to execute DDL commands to modify and drop columns in tables in the underlying PostgreSQL instance.\n\nThe first two of these are available in ClickHouse Cloud, with the latter due to be exposed soon. Let's demonstrate the above previous functions, re-running the queries from ClickHouse. Here the data remains in PostgreSQL, with the data streamed into ClickHouse for the period of the query execution only - it is not persisted in a local MergeTree table. This is predominantly useful for ad-hoc analysis and for joining small datasets to local tables. Note that our ClickHouse Cloud instance is in the same AWS region as our Supabase database, to minimize network latency and maximize bandwidth connectivity.\n\n![clickhouse-postgres-options.png](/uploads/clickhouse_postgres_options_217fcacd7b.png)\n\n### Average price per year for flats in the UK\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nSELECT\n\ttoYear(date) AS year,\n\tround(avg(price)) AS price\nFROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e')\nWHERE type = 'flat'\nGROUP BY year\nORDER BY year ASC\n\n\n┌─year─┬──price─┐\n│ 1995 │  59004 │\n│ 1996 │  63913 │\n...\n│ 2021 │ 310626 │\n│ 2022 │ 298977 │\n└──────┴────────┘\n\n28 rows in set. Elapsed: 26.408 sec. Processed 4.98 million rows, 109.59 MB (175.34 thousand rows/s., 3.86 MB/s.)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nThe above query again results in a full scan in Postgres, with the results streamed to ClickHouse where they are aggregated. This delivers comparable performance to the query being executed directly on Postgres.\n\n### Most expensive postcodes in a city\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nSELECT\n      postcode1,\n      round(avg(price)) AS price\nFROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e') WHERE town='BRISTOL' AND postcode1 != ''\nGROUP BY postcode1\nORDER BY price DESC LIMIT 10\n\n┌─postcode1─┬──price─┐\n│ BS1   \t│ 410726 │\n│ BS19  \t│ 369000 │\n│ BS18  \t│ 337000 │\n│ BS40  \t│ 323854 │\n│ BS9   \t│ 313248 │\n│ BS8   \t│ 301595 │\n│ BS41  \t│ 300802 │\n│ BS6   \t│ 272332 │\n│ BS35  \t│ 260563 │\n│ BS36  \t│ 252943 │\n└───────────┴────────┘\n\n10 rows in set. Elapsed: 2.362 sec. Processed 424.39 thousand rows, 15.11 MB (143.26 thousand rows/s., 5.10 MB/s.)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nThis time the town clause is pushed down to Postgres where the index is exploited, reducing the amount of data to return to ClickHouse. The performance is largely determined by the bandwidth and connectivity of the two databases. We experience some overhead, despite the same AWS region, but the performance remains comparable.\n\n### Postcodes in London with the largest percentage price change in the last 20 yrs\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nSELECT\n\tmed_2002.postcode1,\n\tmedian_2002,\n\tmedian_2022,\n\tround(((median_2022 - median_2002) / median_2002) * 100) AS percent_change\nFROM\n(\n\tSELECT\n    \tpostcode1,\n    \tmedian(price) AS median_2002\n\tFROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e')\n\tWHERE (town = 'LONDON') AND (toYear(date) = '2002')\n\tGROUP BY postcode1\n) AS med_2002\nINNER JOIN\n(\n\tSELECT\n    \tpostcode1,\n    \tmedian(price) AS median_2022\n\tFROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e')\n\tWHERE (town = 'LONDON') AND (toYear(date) = '2022')\n\tGROUP BY postcode1\n) AS med_2022 ON med_2002.postcode1 = med_2022.postcode1\nORDER BY percent_change DESC\nLIMIT 10\n\n┌─postcode1─┬─median_2002─┬─median_2022─┬─percent_change─┐\n│ EC3A  \t│  \t260000 │\t16000000 │       \t6054 │\n│ SW1A  \t│  \t525000 │\t17500000 │       \t3233 │\n│ EC2M  \t│  \t250000 │   4168317.5 │       \t1567 │\n│ EC3R  \t│  \t230000 │ \t2840000 │       \t1135 │\n│ W1S   \t│  \t590000 │ \t6410000 │        \t986 │\n│ WC2A  \t│  \t255000 │ \t2560000 │        \t904 │\n│ W1K   \t│  \t550000 │ \t5000000 │        \t809 │\n│ W1F   \t│  \t280000 │ \t2032500 │        \t626 │\n│ WC1B  \t│  \t390000 │ \t2205000 │        \t465 │\n│ W1J   \t│  \t497475 │ \t2800000 │        \t463 │\n└───────────┴─────────────┴─────────────┴────────────────┘\n\n10 rows in set. Elapsed: 59.859 sec. Processed 4.25 million rows, 157.75 MB (71.04 thousand rows/s., 2.64 MB/s.)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nThis query is appreciably slower than the direct Postgres execution. This can be largely attributed to the fact the `toYear(date)` is not pushed down to Postgres, where the `(extract(year from date))` index can be exploited. This query also streams the results from Postgres twice - once for each side of the join.\n\nWe can, however, rewrite this query to use ClickHouse’s conditional aggregate function [medianIf](https://clickhouse.com/docs/en/sql-reference/aggregate-functions/combinators/#-if). As well as being simpler and more intuitive, it is also faster by avoiding the join and double reading of the Postgres table.\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nSELECT\n\tpostcode1,\n\tmedianIf(price, toYear(date) = 2002) AS median_2002,\n\tmedianIf(price, toYear(date) = 2022) AS median_2022,\n\tround(((median_2022 - median_2002) / median_2002) * 100) AS percent_change\nFROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e')\nWHERE town = 'LONDON'\nGROUP BY postcode1\nORDER BY percent_change DESC\nLIMIT 10\n\n┌─postcode1─┬─median_2002─┬─median_2022─┬─percent_change─┐\n│ EC3A  \t│  \t260000 │\t16000000 │       \t6054 │\n│ SW1A  \t│  \t525000 │\t17500000 │       \t3233 │\n│ EC2M  \t│  \t250000 │   4168317.5 │       \t1567 │\n│ EC3R  \t│  \t230000 │ \t2840000 │       \t1135 │\n│ W1S   \t│  \t590000 │ \t6410000 │        \t986 │\n│ WC2A  \t│  \t255000 │ \t2560000 │        \t904 │\n│ W1K   \t│  \t550000 │ \t5000000 │        \t809 │\n│ W1F   \t│  \t280000 │ \t2032500 │        \t626 │\n│ WC1B  \t│  \t390000 │ \t2205000 │        \t465 │\n│ W1J   \t│  \t497475 │ \t2800000 │        \t463 │\n└───────────┴─────────────┴─────────────┴────────────────┘\n\n10 rows in set. Elapsed: 36.166 sec. Processed 2.13 million rows, 78.88 MB (58.79 thousand rows/s., 2.18 MB/s.)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nUtilizing a table engine simplifies this syntactically. The simplest means of creating this is using the `CREATE AS` syntax below. When ClickHouse creates the table locally, types in Postgres will be mapped to equivalent ClickHouse types - as shown by the subsequent `SHOW CREATE AS` statement. Note we use the setting `external_table_functions_use_nulls = 0`, to ensure Null values are represented as their default values (instead of `Null`). If set to 1 (the default), ClickHouse will create [Nullable](https://clickhouse.com/docs/en/sql-reference/data-types/nullable/) variants of each column.\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nCREATE TABLE uk_price_paid_postgresql AS postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e')\n\nSHOW CREATE TABLE uk_price_paid_postgresql\n\nCREATE TABLE default.uk_price_paid_postgresql\n(\n\t`id` Int32,\n\t`price` Int32,\n\t`date` Date,\n\t`postcode1` String,\n\t`postcode2` String,\n\t`type` String,\n\t`is_new` Int16,\n\t`duration` String,\n\t`addr1` String,\n\t`addr2` String,\n\t`street` String,\n\t`locality` String,\n\t`town` String,\n\t`district` String,\n\t`county` String\n) AS postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '[HIDDEN]')\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nThis makes our earlier query a little simpler, with the same results.\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nSELECT\n\tpostcode1,\n\tmedianIf(price, toYear(date) = 2002) AS median_2002,\n\tmedianIf(price, toYear(date) = 2022) AS median_2022,\n\tround(((median_2022 - median_2002) / median_2002) * 100) AS percent_change\nFROM uk_price_paid_postgresql\nWHERE town = 'LONDON'\nGROUP BY postcode1\nORDER BY percent_change DESC\nLIMIT 10\n\n┌─postcode1─┬─median_2002─┬─median_2022─┬─percent_change─┐\n│ EC3A  \t│  \t260000 │\t16000000 │       \t6054 │\n│ SW1A  \t│  \t525000 │\t17500000 │       \t3233 │\n│ EC2M  \t│  \t250000 │   4168317.5 │       \t1567 │\n│ EC3R  \t│  \t230000 │ \t2840000 │       \t1135 │\n│ W1S   \t│  \t590000 │ \t6410000 │        \t986 │\n│ WC2A  \t│  \t255000 │ \t2560000 │        \t904 │\n│ W1K   \t│  \t550000 │ \t5000000 │        \t809 │\n│ W1F   \t│  \t280000 │ \t2032500 │        \t626 │\n│ WC1B  \t│  \t390000 │ \t2205000 │        \t465 │\n│ W1J   \t│  \t497475 │ \t2800000 │        \t463 │\n└───────────┴─────────────┴─────────────┴────────────────┘\n\n10 rows in set. Elapsed: 28.531 sec. Processed 2.13 million rows, 78.88 MB (74.52 thousand rows/s., 2.76 MB/s.)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nWe could define our table types explicitly and avoid using the `SHOW CREATE AS`.\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nCREATE TABLE default.uk_price_paid_v2\n(\n\t`price` UInt32,\n\t`date` Date,\n\t`postcode1` String,\n\t`postcode2` String,\n\t`type` Enum8('other' = 0, 'terraced' = 1, 'semi-detached' = 2, 'detached' = 3, 'flat' = 4),\n\t`is_new` UInt8,\n\t`duration` Enum8('unknown' = 0, 'freehold' = 1, 'leasehold' = 2),\n\t`addr1` String,\n\t`addr2` String,\n\t`street` String,\n\t`locality` String,\n\t`town` String,\n\t`district` String,\n\t`county` String\n)\nENGINE = PostgreSQL('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e')\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nThere are a few takeaways concerning performance:\n\n* ClickHouse can push down filter clauses if they are simple i.e. =, !=, \u003e, \u003e=, \u0026lt;, \u0026lt;=, and IN, allowing indexes in Postgres to be potentially exploited. If they involve ClickHouse-specific functions (or if Postgres determines a full scan is the best execution method), a full table scan will be performed, and Postgres indexes will not be exploited. This can lead to large differences in performance depending on where the query is run due to the need to stream the entire dataset to ClickHouse. If bandwidth connectivity is not an issue, and Postgres would need to perform a full scan even if the query was executed directly, then differences in performance will be less appreciable.\n* If using the `postgres` function or table engine, be cognizant of the number of queries required from Postgres. In our earlier example, we minimized the use of the function to speed up queries. Balance this against being able to exploit Postgres indexes to minimize the data streamed to ClickHouse.\n\n## Postgres to ClickHouse\n\nUp to now, we’ve only pushed queries down to Postgres. While occasionally useful for ad-hoc analysis and querying small datasets, you will eventually want to exploit ClickHouse’s MergeTree table and its associated performance on analytical queries. Moving data between Postgres and ClickHouse is as simple as using the `INSERT INTO x SELECT FROM` syntax.\n\n![postgres-db-engine.png](/uploads/postgres_db_engine_026ea3f9f2.png)\n\nIn the example below, we create a table and attempt to insert the data from our Supabase-hosted Postgres instance:\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nCREATE TABLE default.uk_price_paid\n(\n   `price` UInt32,\n   `date` Date,\n   `postcode1` LowCardinality(String),\n   `postcode2` LowCardinality(String),\n   `type` Enum8('other' = 0, 'terraced' = 1, 'semi-detached' = 2, 'detached' = 3, 'flat' = 4),\n   `is_new` UInt8,\n   `duration` Enum8('unknown' = 0, 'freehold' = 1, 'leasehold' = 2),\n   `addr1` String,\n   `addr2` String,\n   `street` LowCardinality(String),\n   `locality` LowCardinality(String),\n   `town` LowCardinality(String),\n   `district` LowCardinality(String),\n   `county` LowCardinality(String)\n)\nENGINE = MergeTree\nORDER BY (type, town, postcode1, postcode2)\n\nINSERT INTO uk_price_paid_v2 SELECT * EXCEPT id\nFROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e')\n\n↘ Progress: 21.58 million rows, 3.99 GB (177.86 thousand rows/s., 32.89 MB/s.)                                                                                                                                                                                                                   \t(0.5 CPU, 39.00 MB RAM)\n0 rows in set. Elapsed: 121.361 sec. Processed 21.58 million rows, 3.99 GB (177.86 thousand rows/s., 32.89 MB/s.)\n\nReceived exception from server (version 22.11.1):\nCode: 1001. DB::Exception: Received from oxvdst5xzq.us-west-2.aws.clickhouse.cloud:9440. DB::Exception: pqxx::sql_error: Failure during '[END COPY]': ERROR:  canceling statement due to statement timeout\n. (STD_EXCEPTION)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nIn our example above, we attempted to pull all 28m rows from Supabase. Unfortunately, due to Supabase imposing [a global time limit on queries of 2 minutes](https://supabase.com/docs/guides/database/timeouts) this query doesn’t complete. To work around this, we filter on the type column to obtain subsets of the data - each of these queries can exploit the filter pushed down and complete in under 2 minutes.\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nINSERT INTO uk_price_paid SELECT * EXCEPT id FROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e') WHERE type = 'other'\n\nINSERT INTO uk_price_paid SELECT * EXCEPT id FROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e') WHERE type = 'detached'\n\nINSERT INTO uk_price_paid SELECT * EXCEPT id FROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e') WHERE type = 'flat'\n\nINSERT INTO uk_price_paid SELECT * EXCEPT id FROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e') WHERE type = 'terraced'\n\nINSERT INTO uk_price_paid SELECT * EXCEPT id FROM postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_price_paid', 'postgres', '\u003cpassword\u003e') WHERE type = 'semi-detached'\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nAs of the type of writing, overcoming these query limits requires the user to split their data on a column of appropriate cardinality. However, other services, or self-managed instances, may not impose this restriction.\n\nUsing our new MergeTree table, we can execute our earlier queries directly in ClickHouse.\n\n### The average price per year for flats in the UK\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nSELECT\n\ttoYear(date) AS year,\n\tround(avg(price)) AS price\nFROM uk_price_paid\nWHERE type = 'flat'\nGROUP BY year\nORDER BY year ASC\n\n┌─year─┬──price─┐\n│ 1995 │  59004 │\n│ 1996 │  63913 │\n│ 1997 │  72302 │\n│ 1998 │  80775 │\n│ 1999 │  93646 │\n...\n│ 2019 │ 300938 │\n│ 2020 │ 319547 │\n│ 2021 │ 310626 │\n│ 2022 │ 298977 │\n└──────┴────────┘\n\n28 rows in set. Elapsed: 0.079 sec. Processed 5.01 million rows, 35.07 MB (63.05 million rows/s., 441.37 MB/s.)\n\u003c/div\u003e\u003ca style='height: 32px; width: 32px; text-align: center; line-height: 1.3; position: absolute; font-size: 24px; top: 24px; right: 24px; color: #FFFFFF; background: rgba(0,0,0,0.8); border-radius: 8px;' href=\"https://sql.clickhouse.com?query_id=3CQY9DMYYK7PJSDRPGBJAE\" target=\"_blank\"\u003e✎\u003c/a\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\n### Most expensive postcodes in a city\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nSELECT\n\tpostcode1,\n\tround(avg(price)) AS price\nFROM uk_price_paid\nWHERE (town = 'BRISTOL') AND (postcode1 != '')\nGROUP BY postcode1\nORDER BY price DESC\nLIMIT 10\n\n┌─postcode1─┬──price─┐\n│ BS1   \t│ 410726 │\n│ BS19  \t│ 369000 │\n│ BS18  \t│ 337000 │\n│ BS40  \t│ 323854 │\n│ BS9   \t│ 313248 │\n│ BS8   \t│ 301595 │\n│ BS41  \t│ 300802 │\n│ BS6   \t│ 272332 │\n│ BS35  \t│ 260563 │\n│ BS36  \t│ 252943 │\n└───────────┴────────┘\n\n10 rows in set. Elapsed: 0.077 sec. Processed 27.69 million rows, 30.21 MB (358.86 million rows/s., 391.49 MB/s.)\n\u003c/div\u003e\n\u003ca style='height: 32px; width: 32px; text-align: center; line-height: 1.3; position: absolute; font-size: 24px; top: 24px; right: 24px; color: #FFFFFF; background: rgba(0,0,0,0.8); border-radius: 8px;' href=\"https://sql.clickhouse.com?query_id=VX9XNLHPDAU9BROIOJNFXH\" target=\"_blank\"\u003e✎\u003c/a\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\n### Postcodes in London with the largest percentage price change in the last 20 yrs\n\n\u003cpre style='background-color: #222222; border-radius: 8px; padding: 24px; color: #FFFFFF; display: flex; position: relative; white-space: pre-wrap;'\u003e\n\u003cdiv style='color: #FFFFFF; margin-top: -24px; max-width: 98%;'\u003e\nSELECT\n\tpostcode1,\n\tmedianIf(price, toYear(date) = 2002) AS median_2002,\n\tmedianIf(price, toYear(date) = 2022) AS median_2022,\n\tround(((median_2022 - median_2002) / median_2002) * 100) AS percent_change\nFROM uk_price_paid\nWHERE town = 'LONDON'\nGROUP BY postcode1\nORDER BY percent_change DESC\n\n┌─postcode1─┬─median_2002─┬─median_2022─┬─percent_change─┐\n│ EC3A  \t│  \t260000 │\t16000000 │       \t6054 │\n│ SW1A  \t│  \t525000 │\t17500000 │       \t3233 │\n│ EC2M  \t│  \t250000 │   4168317.5 │       \t1567 │\n│ EC3R  \t│  \t230000 │ \t2840000 │       \t1135 │\n│ W1S   \t│  \t590000 │ \t6410000 │        \t986 │\n\n191 rows in set. Elapsed: 0.062 sec. Processed 2.62 million rows, 19.45 MB (41.98 million rows/s., 311.48 MB/s.)\n\u003c/div\u003e\n\u003ca style='height: 32px; width: 32px; text-align: center; line-height: 1.3; position: absolute; font-size: 24px; top: 24px; right: 24px; color: #FFFFFF; background: rgba(0,0,0,0.8); border-radius: 8px;' href=\"https://sql.clickhouse.com?query_id=7PEVSKK5MBGK5PTEQ6FUOD\" target=\"_blank\"\u003e✎\u003c/a\u003e\n\u003c/pre\u003e\n\u003c/p\u003e\n\nThe difference here in query performance is dramatic. In the interests of transparency, there are reasons for this beyond simply “ClickHouse is faster on analytical queries”:\n\n* This is a developer instance in ClickHouse Cloud with 8GB of RAM and 2 cores. We don’t have visibility regarding the resources assigned to each Supabase instance, but this is likely more.\n* All queries were executed 5x with the minimum of these used. This ensures that we use both databases' “hot” performance and exploit any file system caches.\n* We have optimized our primary key for our ClickHouse table to minimize the number of rows scanned.\n\nDespite these differences, ClickHouse clearly excels on linear scans and analytical-type queries, especially when the primary index can be exploited - this is [reinforced by our more rigorous benchmarks](https://benchmark.clickhouse.com).\n\n## Conclusion\n\nIn the first part of this blog series, we have shown how ClickHouse and Postgres are complementary, demonstrating with examples how data can be moved effortlessly between them using the native ClickHouse functions and table engine. In the next part, we will show how Postgres can be used to power dictionaries which are automatically kept in sync and used to accelerate join queries.\n\nIn the meantime, if you want to learn more about out Postgres integration we have [free training course on data ingestion](https://learn.clickhouse.com/visitor_catalog_class/show/912833/) which covers these topics extensively.\n","createdAt":"2022-12-20T12:33:58.019Z","updatedAt":"2026-01-21T12:55:38.085Z","publishedAt":"2022-12-20T12:34:06.833Z","slug":"migrating-data-between-clickhouse-postgres","date":"2022-12-20","keywords":null,"StagingOnly":null,"ShowCloudCTAHeader":null,"ShowCloudCTAFooter":null,"reading_time":22,"theme":"Competitive Comparisons","use_case":"N/A","canonical_url":null,"table_contents_headers":null,"ListOnBlogs":null,"enableSidebarGlobalCta":null,"reading_time_override":null,"thumbnailPng":{"id":746,"name":"clickhouse-postgresql.png","alternativeText":null,"caption":null,"width":1576,"height":888,"formats":{"large":{"ext":".png","url":"/uploads/large_clickhouse_postgresql_1d123677ea.png","hash":"large_clickhouse_postgresql_1d123677ea","mime":"image/png","name":"large_clickhouse-postgresql.png","path":null,"size":74.42,"width":1000,"height":563},"small":{"ext":".png","url":"/uploads/small_clickhouse_postgresql_1d123677ea.png","hash":"small_clickhouse_postgresql_1d123677ea","mime":"image/png","name":"small_clickhouse-postgresql.png","path":null,"size":25.42,"width":500,"height":282},"medium":{"ext":".png","url":"/uploads/medium_clickhouse_postgresql_1d123677ea.png","hash":"medium_clickhouse_postgresql_1d123677ea","mime":"image/png","name":"medium_clickhouse-postgresql.png","path":null,"size":46.46,"width":750,"height":423},"thumbnail":{"ext":".png","url":"/uploads/thumbnail_clickhouse_postgresql_1d123677ea.png","hash":"thumbnail_clickhouse_postgresql_1d123677ea","mime":"image/png","name":"thumbnail_clickhouse-postgresql.png","path":null,"size":10.33,"width":245,"height":138}},"hash":"clickhouse_postgresql_1d123677ea","ext":".png","mime":"image/png","size":98.89,"url":"/uploads/clickhouse_postgresql_1d123677ea.png","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2022-12-20T12:29:25.423Z","updatedAt":"2022-12-20T12:29:25.423Z"},"author":{"id":839,"name":"Dale McDiarmid","profileLink":null}},{"id":136,"category":"Engineering","title":"ClickHouse and PostgreSQL - a Match Made in Data Heaven - part 2","shortDescription":"Read the the final part in our series on how Postgres and ClickHouse complement each other, this time focusing on dictionaries and reverse ETL.","content":"\u003e While many of the approaches in this blog post remain valid, the content is from 2023. For the latest guidance on migrating data from Postgres to ClickHouse, we recommend exploring newer resources - primarily how ClickPipes, ClickHouse Cloud's managed data ingestion pipeline, now supports ingesting data into [ClickHouse from Postgres using CDC](https://clickhouse.com/docs/integrations/clickpipes/postgres).\n\n\n![clickhouse-postgresql.png](/uploads/clickhouse_postgresql_1d123677ea.png)\n\n## Introduction\n\nThis post continues our series on the Postgres integrations available in ClickHouse. In our [previous post](https://clickhouse.com/blog/migrating-data-between-clickhouse-postgres), we explored the Postgres function and table engine, demonstrating how users can move their transactional data to ClickHouse from Postgres for analytical workloads. In this post, we show how Postgres data can also be used in conjunction with the popular ClickHouse dictionary feature to accelerate queries - specifically joins. Finally, we show how the Postgres table engine can be used to push the results of analytical queries back to Postgres from ClickHouse. This \"reverse ELT\" process can be used for cases where users need to display summarized data in an end-user application but wish to offload the heavy computation of these statistics to ClickHouse. \n\nIf you want to dive deeper into these examples and reproduce them, ClickHouse Cloud is a great starting point - [spin up a cluster and get $300 of free credit](https://clickhouse.cloud/signUp?loc=blog\u0026ajs_aid=b44bb600-929d-4c35-9f15-21edd1872094), load the data, let us deal with the infrastructure, and get querying! \n\nWe continue to use only a development instance in ClickHouse Cloud for the examples in this post. For our Postgres instance, we also continue with [Supabase](https://supabase.com/), which offers a generous free tier sufficient for our examples. We assume the user has loaded the UK house price dataset into ClickHouse as a step from the [previous blog post](https://clickhouse.com/blog/migrating-data-between-clickhouse-postgres). This dataset can also be loaded without using Postgres using the steps outlined [here](https://clickhouse.com/docs/en/getting-started/example-datasets/uk-price-paid/).\n\n## Powering Dictionaries with Postgres\n\nAs we've highlighted in [previous blog posts](https://clickhouse.com/blog/faster-queries-dictionaries-clickhouse), dictionaries can be used to accelerate ClickHouse queries, especially those involving joins. Consider the following example, where we aim to find the regions for the UK (based on ISO 3166-2) that have experienced the largest price change in the last 20 years. Note that ISO 3166-2 codes are different than postcodes and represent a larger regional area but, more importantly, are useful for visualizing this data in tools such as Superset. \n\nThe JOIN requires us to use a list of postcode to regional code mappings, which can be downloaded and loaded into a `codes` table, as shown below. With over 1 million rows, this takes about a minute to load into our Supabase free tier instance. Let's assume this data is only in Postgres for now, so we will join this in Postgres to answer the query.\n\nNote: our list of postcodes to iso 3166-2 codes were generated from the house price dataset and using a [listing of regional codes](https://gist.github.com/gingerwizard/07044995d259c5f82582da4d6f9cf3f8) present in our play.clickhouse.com environment. This dataset, while sufficient for our needs, is therefore not complete or exhaustive, covering only postcodes present in the house price dataset. The query used to generate our file can be found [here](https://gist.github.com/gingerwizard/b863d765e9df46994145982d7f7a6c82).\n\n\u003cpre class='code-with-play'\u003e\n\u003cdiv class='code'\u003e\nwget https://datasets-documentation.s3.amazonaws.com/uk-house-prices/postgres/uk_postcode_to_iso.sql\n\npsql -c \"CREATE TABLE uk_postcode_to_iso\n(\n        id serial,\n    \tpostcode varchar(8) primary key,\n    \tiso_code char(6)\n);\"\n\npsql -c \"CREATE INDEX ON uk_postcode_to_iso (iso_code);\"\npsql \u003c uk_postcode_to_iso.sql\n\npsql -c \"select count(*) from uk_postcode_to_iso;\"\n  count\n---------\n 1272836\n(1 row)\n\npsql -c \"\\timing\" -c \"SELECT iso_code, round(avg(((median_2022 - median_2002)/median_2002) * 100)) AS percent_change FROM (\n  SELECT postcode1 || ' ' || postcode2 AS postcode, PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_2002 FROM uk_price_paid WHERE extract(year from date) = '2002' GROUP BY postcode\n) med_2002 INNER JOIN (\n  SELECT postcode1 || ' ' || postcode2 AS postcode, PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_2022 FROM uk_price_paid WHERE extract(year from date) = '2022' GROUP BY postcode\n) med_2022 ON med_2002.postcode=med_2022.postcode INNER JOIN (\n\tSELECT iso_code, postcode FROM uk_postcode_to_iso\n) postcode_to_iso ON med_2022.postcode=postcode_to_iso.postcode GROUP BY iso_code ORDER BY percent_change DESC LIMIT 10;\"\n\nTiming is on.\n\niso_code | percent_change\n----------+----------------\n GB-TOF   |        \t403\n GB-KEC   |        \t380\n GB-MAN   |        \t360\n GB-SLF   |        \t330\n GB-BGW   |        \t321\n GB-HCK   |        \t313\n GB-MTY   |        \t306\n GB-AGY   |        \t302\n GB-RCT   |        \t293\n GB-BOL   |        \t292\n(10 rows)\n\nTime: 48523.927 ms (00:48.524)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003cbr /\u003e\n\nThe query here is quite complicated and [more expensive than the queries in our previous post](https://clickhouse.com/blog/migrating-data-between-clickhouse-postgres), which just computed the highest changing postcodes for London. There is no opportunity to exploit the town index, although we can utilize the `EXTRACT(year FROM date` index as [shown by an EXPLAIN](https://gist.github.com/gingerwizard/029bd291cbd028c292153f63dada0868).\n\nWe could also load this iso code data into a ClickHouse table and repeat the join, adjusting the syntax where required. Alternatively, we might be tempted to leave the mapping in Postgres as its subject to [reasonably frequent changes](https://www.centralmailing.co.uk/blog/royal-mail-is-celebrating-40-years-since-the-introduction-of-post-codes/). If performing the join in ClickHouse, this produces the following query. Note how we create a `uk_postcode_to_iso` using the [PostgreSQL table ](https://clickhouse.com/docs/en/engines/table-engines/integrations/postgresql)engine to simplify the query syntax vs. using the [postgres function](https://clickhouse.com/docs/en/sql-reference/table-functions/postgresql).\n\n![postgres_table_join.png](/uploads/postgres_table_join_5668fc2fb7.png)\n\n\u003cpre class='code-with-play'\u003e\n\u003cdiv class='code'\u003e\nCREATE TABLE uk_postcode_to_iso AS postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'uk_postcode_to_iso', 'postgres', '\u003cpassword\u003e')\n\nSELECT\n\tiso_code,\n\tround(avg(percent_change)) AS avg_percent_change\nFROM\n(\n\tSELECT\n    \tpostcode,\n    \tmedianIf(price, toYear(date) = 2002) AS median_2002,\n    \tmedianIf(price, toYear(date) = 2022) AS median_2022,\n    \t((median_2022 - median_2002) / median_2002) * 100 AS percent_change\n\tFROM uk_price_paid\n\tGROUP BY concat(postcode1, ' ', postcode2) AS postcode\n\tHAVING isNaN(percent_change) = 0\n) AS med_by_postcode\nINNER JOIN uk_postcode_to_iso ON uk_postcode_to_iso.postcode = med_by_postcode.postcode\nGROUP BY iso_code\nORDER BY avg_percent_change DESC\nLIMIT 10\n\n┌─iso_code─┬─avg_percent_change─┐\n│ GB-TOF   │            \t403 │\n│ GB-KEC   │            \t380 │\n│ GB-MAN   │            \t360 │\n│ GB-SLF   │            \t330 │\n│ GB-BGW   │            \t321 │\n│ GB-HCK   │            \t313 │\n│ GB-MTY   │            \t306 │\n│ GB-AGY   │            \t302 │\n│ GB-RCT   │            \t293 │\n│ GB-BOL   │            \t292 │\n└──────────┴────────────────────┘\n\n10 rows in set. Elapsed: 4.131 sec. Processed 29.01 million rows, 305.27 MB (7.02 million rows/s., 73.90 MB/s.)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003cbr /\u003e\n\nThis isn't delivering the performance we would like. Instead of creating a ClickHouse table for the mapping, we can create a PostgreSQL-backed dictionary as shown below:\n\n\u003cpre class='code-with-play'\u003e\n\u003cdiv class='code'\u003e\nCREATE DICTIONARY uk_postcode_to_iso_dict\n(\n`postcode` String,\n`iso_code` String\n)\nPRIMARY KEY postcode\nSOURCE(POSTGRESQL(\n   port 5432\n   host 'db.ebsmckuuiwnvyiniuvdt.supabase.co'\n   user 'postgres'\n   password '\u003cpassword\u003e'\n   db 'postgres'\n   table 'uk_postcode_to_iso'\n   invalidate_query 'SELECT max(id) as mid FROM uk_postcode_to_iso'\n))\nLIFETIME(300)\nLAYOUT(complex_key_hashed())\n\n//force loading of dictionary\nSELECT dictGet('uk_postcode_to_iso_dict', 'iso_code', 'BA5 1PD')\n\n┌─dictGet('uk_postcode_to_iso_dict', 'iso_code', 'BA5 1PD')─┐\n│ GB-SOM                                                \t│\n└───────────────────────────────────────────────────────────┘\n\n1 row in set. Elapsed: 0.885 sec.\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003cbr /\u003e\n\nThis dictionary will periodically update based on the LIFETIME clause, automatically syncing any changes. In this case, we also define an [`invalidate_query`](https://clickhouse.com/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts-dict-sources#postgresql) clause which controls when the dataset needs to be reloaded from the source by returning a single value. If this changes, the dictionary is reloaded - in this case, when the max id changes. In a production scenario, we would probably want a query capable of detecting updates via a modified time field.\n\n![postgres_dictionary.png](/uploads/postgres_dictionary_7319d09577.png)\n\nUsing this dictionary, we can now modify our query and exploit the fact that  this table is held locally in memory for fast lookups. Note how we can also avoid the join:\n\n\u003cpre class='code-with-play'\u003e\n\u003cdiv class='code'\u003e\nSELECT\n\tiso_code,\n\tround(avg(percent_change)) AS avg_percent_change\nFROM\n(\n\tSELECT\n    \tdictGet('uk_postcode_to_iso_dict', 'iso_code', postcode) AS iso_code,\n    \tmedianIf(price, toYear(date) = 2002) AS median_2002,\n    \tmedianIf(price, toYear(date) = 2022) AS median_2022,\n    \t((median_2022 - median_2002) / median_2002) * 100 AS percent_change\n\tFROM uk_price_paid\n\tGROUP BY concat(postcode1, ' ', postcode2) AS postcode\n\tHAVING isNaN(percent_change) = 0\n)\nGROUP BY iso_code\nORDER BY avg_percent_change DESC\nLIMIT 10\n\n┌─iso_code─┬─avg_percent_change─┐\n│ GB-TOF   │            \t403 │\n│ GB-KEC   │            \t380 │\n│ GB-MAN   │            \t360 │\n│ GB-SLF   │            \t330 │\n│ GB-BGW   │            \t321 │\n│ GB-HCK   │            \t313 │\n│ GB-MTY   │            \t306 │\n│ GB-AGY   │            \t302 │\n│ GB-RCT   │            \t293 │\n│ GB-BOL   │            \t292 │\n└──────────┴────────────────────┘\n\n10 rows in set. Elapsed: 0.444 sec. Processed 27.73 million rows, 319.84 MB (62.47 million rows/s., 720.45 MB/s.)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003cbr /\u003e\n\nThat's better. For those interested, this data is plottable in tools such as Superset, which can interpret these iso-codes - see [our previous blog post on Superset](https://clickhouse.com/blog/visualizing-data-with-superset) for a similar example.\n\n![uk_codes.png](/uploads/uk_codes_32da86b9b0.png)\n\n## Pushing Results to Postgres\n\nUp to now, we’ve demonstrated the value of moving data to ClickHouse from Postgres for analytical workloads. If we consider this as an ETL process, it is likely that at some point, we will want to reverse this workflow and load the results of our analysis back into Postgres. We can achieve this using the same [table engine](https://clickhouse.com/docs/en/engines/table-engines/integrations/postgresql#usage-example) we highlighted earlier in this series.\n\n![postgres_insert_select.png](/uploads/postgres_insert_select_d8dc6cb3c7.png)\n\nSuppose we wanted to push aggregate statistics back to Postgres for the sales during each month, summarized by postcode, type, whether the house is new, and if it's a freehold or leasehold. Our hypothetical site will display these statistics on every page of a listing to help its users understand the historical market conditions in an area. Additionally, they would like to be able to display these statistics over time. To lower the load* on their production Postgres instance, they offload this computation to ClickHouse and periodically push these results back to a summary table.\n\n\u003cblockquote style=\"font-size:14px\"\u003e\n  \u003cp\u003eIn reality, this isn't a particularly heavy query and could probably be scheduled in Postgres.\u003c/p\u003e\n\u003c/blockquote\u003e\n\nBelow we create a ClickHouse database backed by Postgres before creating a table and inserting the results of our analytical query.\n\n\u003cpre class='code-with-play'\u003e\n\u003cdiv class='code'\u003e\nCREATE TABLE summary_prices(\npostcode1 varchar(8),\n            \ttype varchar(13),\n            \tis_new SMALLINT,\n            \tduration varchar(9),\n            \tsold integer,\n            \tmonth Date,\n            \tavg_price integer,\n            \tquantile_prices integer[]);\n                \n// create Postgres engine table in ClickHouse\nCREATE TABLE summary_prices AS postgresql('db.zcxfcrchxescrtxsnxuc.supabase.co', 'postgres', 'summary_prices', 'postgres', '\u003cpassword\u003e')\n\n//check connectivity\nSELECT count()\nFROM summary_prices\n\n┌─count()─┐\n│       0 │\n└─────────┘\n\n1 row in set. Elapsed: 0.337 sec.\n\n// insert the result of our query to Postgres\nINSERT INTO summary_prices SELECT\n\tpostcode1,\n\ttype,\n\tis_new,\n\tduration,\n\tcount() AS sold,\n\tmonth,\n\tavg(price) AS avg_price,\n\tquantilesExactExclusive(0.25, 0.5, 0.75, 0.9, 0.95, 0.99)(price) AS quantile_prices\nFROM uk_price_paid\nWHERE postcode1 != ''\nGROUP BY\n\ttoStartOfMonth(date) AS month,\n\tpostcode1,\n\ttype,\n\tis_new,\n\tduration\nORDER BY\n\tpostcode1 ASC,\n\ttype ASC,\n\tis_new ASC,\n\tduration ASC,\n\tmonth ASC\n\n0 rows in set. Elapsed: 25.714 sec. Processed 27.69 million rows, 276.98 MB (775.43 thousand rows/s., 7.76 MB/s.)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003cbr /\u003e\n\nOur site now has a simple query to run to fetch the historical price statistics for an area and house of the same type.\n\n\u003cpre class='code-with-play'\u003e\n\u003cdiv class='code'\u003e\npostgres=\u003e SELECT postcode1, month, avg_price, quantile_prices FROM summary_prices WHERE postcode1='BA5' AND type='detached' AND is_new=0 and duration='freehold' LIMIT 10;\n postcode1 |   month    | avg_price |              quantile_prices\n-----------+------------+-----------+--------------------------------------------\n BA5       | 1995-01-01 |    108000 | {64000,100000,160000,160000,160000,160000}\n BA5       | 1995-02-01 |     95142 | {86500,100000,115000,130000,130000,130000}\n BA5       | 1995-03-01 |    138991 | {89487,95500,174750,354000,354000,354000}\n BA5       | 1995-04-01 |     91400 | {63750,69500,130000,165000,165000,165000}\n BA5       | 1995-05-01 |    110625 | {83500,94500,149750,170000,170000,170000}\n BA5       | 1995-06-01 |    124583 | {79375,118500,173750,185000,185000,185000}\n BA5       | 1995-07-01 |    126375 | {88250,95500,185375,272500,272500,272500}\n BA5       | 1995-08-01 |    104416 | {67500,95000,129750,200000,200000,200000}\n BA5       | 1995-09-01 |    103000 | {70000,97000,143500,146000,146000,146000}\n BA5       | 1995-10-01 |     90800 | {58375,72250,111250,213700,223000,223000}\n(10 rows)\n\u003c/div\u003e\n\u003c/pre\u003e\n\u003cbr /\u003e\n\n## Conclusion\n\nIn this series of posts, we have shown how ClickHouse and Postgres are complementary, demonstrating with examples of how data can be moved effortlessly between the two databases using the native ClickHouse functions and table engines. In this specific post, we have covered a Postgres-backed dictionary and how it can be used to accelerate joins for queries involving a frequently changing dataset. Finally, we have performed a “reverse ETL” operation, pushing the results of an analytical query back to Postgres for consumption from a possible user-facing application.\n","createdAt":"2023-01-26T12:08:37.576Z","updatedAt":"2026-01-21T12:55:59.785Z","publishedAt":"2023-01-26T12:09:10.219Z","slug":"migrating-data-between-clickhouse-postgres-part-2","date":"2023-01-26","keywords":null,"StagingOnly":null,"ShowCloudCTAHeader":null,"ShowCloudCTAFooter":null,"reading_time":10,"theme":"Competitive Comparisons","use_case":"N/A","canonical_url":null,"table_contents_headers":null,"ListOnBlogs":null,"enableSidebarGlobalCta":null,"reading_time_override":null,"thumbnailPng":{"id":746,"name":"clickhouse-postgresql.png","alternativeText":null,"caption":null,"width":1576,"height":888,"formats":{"large":{"ext":".png","url":"/uploads/large_clickhouse_postgresql_1d123677ea.png","hash":"large_clickhouse_postgresql_1d123677ea","mime":"image/png","name":"large_clickhouse-postgresql.png","path":null,"size":74.42,"width":1000,"height":563},"small":{"ext":".png","url":"/uploads/small_clickhouse_postgresql_1d123677ea.png","hash":"small_clickhouse_postgresql_1d123677ea","mime":"image/png","name":"small_clickhouse-postgresql.png","path":null,"size":25.42,"width":500,"height":282},"medium":{"ext":".png","url":"/uploads/medium_clickhouse_postgresql_1d123677ea.png","hash":"medium_clickhouse_postgresql_1d123677ea","mime":"image/png","name":"medium_clickhouse-postgresql.png","path":null,"size":46.46,"width":750,"height":423},"thumbnail":{"ext":".png","url":"/uploads/thumbnail_clickhouse_postgresql_1d123677ea.png","hash":"thumbnail_clickhouse_postgresql_1d123677ea","mime":"image/png","name":"thumbnail_clickhouse-postgresql.png","path":null,"size":10.33,"width":245,"height":138}},"hash":"clickhouse_postgresql_1d123677ea","ext":".png","mime":"image/png","size":98.89,"url":"/uploads/clickhouse_postgresql_1d123677ea.png","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2022-12-20T12:29:25.423Z","updatedAt":"2022-12-20T12:29:25.423Z"},"author":{"id":851,"name":"Dale McDiarmid","profileLink":null}}]}],"customContent":[]},{"id":12,"SectionTitle":"Related blogs","Category":null,"Footer":null,"Description":null,"RelatedBlogs":[{"id":10,"blog_posts":[{"id":317,"category":"User stories","title":"Prefect - Event-driven workflow orchestration powered by ClickHouse","shortDescription":"Prefect’s orchestration and observability platform helps developers build and understand their data pipelines and, crucially, react to them.","content":"Prefect’s orchestration and observability platform helps developers build and understand their data pipelines and, crucially, react to them. Providing a resilient and versatile product  guides their mission to continuously evolve, adapt, and stay relevant to developer needs. It’s no surprise they are enabling the move to an event-based architecture, as Sarah Krasnik Bedell, Director of Growth Marketing at Prefect explains: _“We want to be able to handle a wide variety of different data pipelines and code tasks. Ultimately, the goal is to enable whatever deployment and trigger patterns developers, data engineers, platform engineers, and software engineers need,”_ and this is why ClickHouse has become integral to Prefect.\n\n![Screenshot 2024-05-29 at 8.27.30 AM.png](/uploads/Screenshot_2024_05_29_at_8_27_30_AM_ff0dd81ad9.png)\n\n## Prefect - event-driven workflow automation at scale\n\nThe funny thing is, Prefect is not focused on pipeline success, but rather on dealing with failures. _“We want to expose errors in a way that is most productive to help our users react to failures,”_ says Bedell. The times when tracking is most important is when things fail, she continues: _“No one logs into an orchestration dashboard and says ‘Wow, my pipelines are great today’, and then continues looking at the dashboard and stays there, right?”_  Failure creates the urgency to observe and react — and that is Prefect’s focus.\n\nWhen users capture and process large amounts of data, workflow observability, flexible automation, and notifications become increasingly important. Enter Prefect Cloud, which builds on the strong foundation of Prefect’s open-source product to address these needs in a turnkey, enterprise-grade and secure way: _“With Prefect Cloud, we’re taking observability up a notch to enable people to observe and react to the health of any code that drives their business,”_ says Bedell.\n\nRather than observing why one particular run (an instance of workflow execution) failed or had a problem, Prefect Cloud is moving towards a much higher-level abstraction meant for team leaders. Bedell wants to deliver observability that can answer more complex questions with additional scope encompassing business impact: _“For example, we want to enable our customers to answer, ‘where are the biggest cost centers  in terms of moving data?’, or maybe ‘are these expensive machine learning pipelines optimized?’ It’s a much broader code base than just batch data pipelines and that's where the conversation around ClickHouse started.”_\n\nOn a consistent basis, Prefect Cloud runs over a million “flow runs” per day – a “flow” is the most fundamental concept in Prefect representing a container for workflow logic as-code. Bedell explains: _“Each of those flow runs could range from a few to hundreds of tasks. Then within each of those, breaking it up from the largest object to smallest object, each creates events, and those events could be state events, they could be artifacts created – it’s not one task, one object.”_   Having a multi-tenant architecture means that events from different customers are within the same database, all sliced out into partitions. Events are also customers’ log messages. So, when customers log data during the course of their flows those log messages are also events, as Staff Software Engineer, at Prefect, Chris Guidry explains: _“Our logs feature on Prefect Cloud is also backed by the same event stream, so volume is tied to a fundamental metric we watch – how many flow runs per day are people running. Any given flow might spawn 200+ events.  In February, Prefect had between 150 to 200 million events per day and the ambition is much greater.”_\n\n\n## Original data stack - Google BigQuery and PostgreSQL\n\nThe Prefect team started with the observability platform on Google BigQuery, a traditional cloud data warehouse, as a main datastore and a medium-sized PostgreSQL database instance in front as a hot data cache.  Success and growth soon meant an event stream of billions, and they were pushing at the edge of PostgreSQL capabilities, since this transactional database was not built to handle analytical workloads, _“All those events go to long-term storage in a BigQuery table. We had to scale it up several notches vertically and we were definitely pushing at the edge of what PostgreSQL and Cloud SQL could handle,”_ he continues.  \n\nAs Prefect started to explore the possibility of doing a higher level analysis over customers’ workflows, Guidry says there were already challenges around reliably pulling event streams and showing all the events that happen to an object or that happened during the course of a workflow running: _“As we started to talk about analyzing all the events over the many workflows that happened in a week, we quickly realized that it wasn’t going to work on our PostgreSQL because we just couldn’t query and aggregate over many things.”_  They needed to rethink the technology stack to match the new value they wanted to deliver to customers.\n\nPlus, as Guidry describes, building interactive, data-driven applications where answers are expected by users real-time meant costs were rising: _“Where your application or users might be querying that information hundreds of times a day or thousands of times a day. That's pretty expensive to query.”_ Rising costs were a direct result of technology / use case mismatch. Postgres database is great for handling transactional workloads, but does not use hardware resources efficiently, when answering analytical questions, because as a row-oriented database scans too much data when running aggregations on just a few columns. On the other hand, Google BigQuery was originally designed to handle data warehousing workloads – infrequent ad-hoc queries, and as a result, its pricing model based on the amount of data scanned is exorbitantly expensive for real-time analytical workloads, where queries are generated by the application and concurrency is high. \n\n## ClickHouse Cloud - Real-time analytics platform powering next-gen workflow observability \n\n![Screenshot 2024-05-29 at 8.27.37 AM.png](/uploads/Screenshot_2024_05_29_at_8_27_37_AM_5215288b9a.png)\n\nTo build the next-gen  workflow orchestration observability solution for their customers, Guidry says simply : _“We needed a new database.”_ They wanted to provide Prefect users with more comprehensive metrics and triggers and a more powerful way to ask new questions of this data: _“For us, ClickHouse’s strength is looking at massive volumes of time-oriented data, it’s very much made for event streams and we’re very happy with how ClickHouse approaches the challenge.” ClickHouse is now part of a portfolio of databases for Prefect, but added Guidry: “It’s a very important one because it's going to enable the observability features we’re already thinking about to evolve and deliver more value from Prefect Cloud.”_\n\nPrefect Cloud launched Metrics as one of the first ways to leverage ClickHouse for more advanced aggregations, a real step towards their observability vision: _“Failure is likely a symptom of a bigger problem that needs fixing. Does it happen every single day, at a specific time? We want our users to be able to fix errors at a larger scale,”_ explains Bedell.  While the team started small, with just a few cards that deliver metrics derived from looking over the past week of flow runs, Guidry points out: _“What we’ve done would not have been possible without ClickHouse, that’s quite an impact!”_\n\nFollowing Metrics, came Automations, Guidry explains it’s one of the earliest features put in place, where the big goal isn’t capturing information, but crucially enabling users to act on it and offering Prefect Cloud users a powerful feature set designed to create responsive systems within their workspace. The system can now respond to specific events by triggering subsequent actions, so users can better mitigate risks and maintain operational efficiency. For instance, should an uptick in late flow occurrences exceed a certain threshold, an automated alert to Slack can signal potential issues requiring attention. Explaining other scenarios Guidry says: _“Users can execute automated actions, such as database reboots, to promptly address potential database issues. If the failure rate surpasses a predetermined threshold, within a specific timeframe, the system can automatically generate new incidents with detailed information for swift resolution.”_  \n\n## Additional benefits - Simpler, more resilient data stack and cost savings \n\nIn addition to enabling Prefect to realize their vision of building a real-time data-driven application on top of ClickHouse, migrating from a BigQuery and PostgreSQL based analytical stack helped simplify operations and save costs. \n\nClickHouse allowed Prefect to consolidate multiple architectural components into one, simplifying their architecture and making it more reliable: _“ClickHouse has created resiliency in a completely new way with fewer systems to maintain, I think that's another reason why this work is so important.”_ Says Bedell. Prefect also has the tools to autonomously handle large-scale disruptions and unforeseen events, they’re reaping benefits from the platform's potential in creating resilience and adaptability\n\n\u003eClickHouse was critical functionality not cost-saving, yet ClickHouse has reduced the costs to less than $8,000 a month\n\nPrefect was spending around $12,000 a month on CloudSQL and BigQuery overrun, because they have customers whose queries are very complex or require accessing large datasets or historical data, which would then trigger the use of BigQuery. Prefect was exceeding their budget and usage limits, resulting in additional costs. The primary motivation for implementing ClickHouse was critical functionality not cost-saving, yet ClickHouse has reduced the costs to less than $8,000 a month. As Guidry concludes: _“We have saved costs, savings not to be sniffed at, but that was not the driving factor. This was a qualitative step. We just could not do the things we wanted until we had ClickHouse and that is why we’re so excited about it.”_\n\n## About Prefect\n\nPrefect is a versatile event-driven orchestration and workflow observability platform. Used for orchestrating data pipelines it simplifies the process of building, scheduling, and monitoring workflows. A Python-based framework means users can define complex workflows as code, making it easier to manage dependencies, handle errors, and scale workflows. Prefect is widely used in industries such as finance, healthcare, e-commerce, and more, where managing and processing large volumes of data efficiently is crucial. Prefect is continuously evolving and offers both a free, open-source Community Edition, a paid Enterprise Edition and Prefect Cloud offering with additional features and support.\n\n","createdAt":"2024-05-28T09:20:55.696Z","updatedAt":"2024-07-02T10:45:53.607Z","publishedAt":"2024-05-28T09:23:40.217Z","slug":"prefect-event-driven-workflow-orchestration-powered-by-clickhouse","date":"2024-05-30","keywords":null,"StagingOnly":false,"ShowCloudCTAHeader":false,"ShowCloudCTAFooter":false,"reading_time":10,"theme":"Customer Story","use_case":"Logs, Metrics, \u0026 Traces","canonical_url":null,"table_contents_headers":null,"ListOnBlogs":null,"enableSidebarGlobalCta":null,"reading_time_override":null,"thumbnailPng":{"id":2475,"name":"prefect-og.png","alternativeText":null,"caption":null,"width":2400,"height":1260,"formats":{"large":{"ext":".png","url":"/uploads/large_prefect_og_a43484ffbc.png","hash":"large_prefect_og_a43484ffbc","mime":"image/png","name":"large_prefect-og.png","path":null,"size":35.36,"width":1000,"height":525,"sizeInBytes":35362},"small":{"ext":".png","url":"/uploads/small_prefect_og_a43484ffbc.png","hash":"small_prefect_og_a43484ffbc","mime":"image/png","name":"small_prefect-og.png","path":null,"size":15.68,"width":500,"height":263,"sizeInBytes":15679},"medium":{"ext":".png","url":"/uploads/medium_prefect_og_a43484ffbc.png","hash":"medium_prefect_og_a43484ffbc","mime":"image/png","name":"medium_prefect-og.png","path":null,"size":24.66,"width":750,"height":394,"sizeInBytes":24660},"thumbnail":{"ext":".png","url":"/uploads/thumbnail_prefect_og_a43484ffbc.png","hash":"thumbnail_prefect_og_a43484ffbc","mime":"image/png","name":"thumbnail_prefect-og.png","path":null,"size":7.4,"width":245,"height":129,"sizeInBytes":7398}},"hash":"prefect_og_a43484ffbc","ext":".png","mime":"image/png","size":13.22,"url":"/uploads/prefect_og_a43484ffbc.png","previewUrl":null,"provider":"local","provider_metadata":null,"createdAt":"2024-05-28T09:21:04.841Z","updatedAt":"2024-05-28T09:21:04.841Z"},"author":{"id":317,"name":"Sarah Bedell \u0026 Chris Guidry, Prefect","profileLink":null}}]}],"customContent":[]},{"id":2,"SectionTitle":"Guides","Category":null,"Footer":null,"Description":null,"RelatedBlogs":[],"customContent":[{"id":2,"Title":"Connecting ClickHouse to Postgres","Description":null,"href":"https://clickhouse.com/docs/en/integrations/postgresql","Category":"Docs","Footer":null,"Image":null},{"id":3,"Title":"Using Postgres clients with ClickHouse","Description":null,"href":"https://clickhouse.com/docs/en/interfaces/postgresql","Category":"Docs","Footer":null,"Image":null}]}],"BigNumbers":[{"id":4,"Number":"1000x","Text":"Faster queries"},{"id":5,"Number":"-50%","Text":"Disk space"},{"id":6,"Number":"5x","Text":"Cost savings"}]},"seo":{"id":12,"title":"ClickHouse and PostgreSQL","keywords":null,"description":"Discover why our customers are relying on ClickHouse to power these analytics use cases while freeing Postgres to do what it does best.","schema":null,"canonicalUrl":null,"noindex":null,"nofollow":null,"robots":null,"path":"/comparison/postgresql","languages":["en","ja"],"lastModified":"2024-08-19T10:13:15.469Z"},"newsLetterData":{"id":1,"title":"Subscribe to our newsletter","description":"Stay informed on feature releases, product roadmap, support, and cloud offerings!","emailLabel":"Email address","submitButtonLabel":"Sign up","createdAt":"2022-07-07T18:50:33.015Z","updatedAt":"2022-11-16T00:10:25.666Z","publishedAt":"2022-07-07T18:50:34.016Z"},"platforms":[{"id":9,"name":"Linux, macOS, FreeBSD","instructions":"curl https://clickhouse.com/ | sh"}],"headerData":{"github":{"stars":45973,"contributors":2736,"prs":69135,"releases":737}}},"__N_SSG":true},"page":"/comparison/postgresql","query":{},"buildId":"zmUZJ4yILYdetQg3c5Mna","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>